{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97848159",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-22T15:03:54.544004Z",
     "iopub.status.busy": "2024-04-22T15:03:54.543620Z",
     "iopub.status.idle": "2024-04-22T15:03:59.827974Z",
     "shell.execute_reply": "2024-04-22T15:03:59.827022Z"
    },
    "papermill": {
     "duration": 5.293107,
     "end_time": "2024-04-22T15:03:59.830285",
     "exception": false,
     "start_time": "2024-04-22T15:03:54.537178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a5f8f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:03:59.842573Z",
     "iopub.status.busy": "2024-04-22T15:03:59.841947Z",
     "iopub.status.idle": "2024-04-22T15:03:59.846253Z",
     "shell.execute_reply": "2024-04-22T15:03:59.845431Z"
    },
    "papermill": {
     "duration": 0.012094,
     "end_time": "2024-04-22T15:03:59.848249",
     "exception": false,
     "start_time": "2024-04-22T15:03:59.836155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 27\n",
    "batch_size = 1\n",
    "vocab_size = 50_000\n",
    "max_seq_len = 4000\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a51e349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:03:59.859170Z",
     "iopub.status.busy": "2024-04-22T15:03:59.858587Z",
     "iopub.status.idle": "2024-04-22T15:03:59.865417Z",
     "shell.execute_reply": "2024-04-22T15:03:59.864601Z"
    },
    "papermill": {
     "duration": 0.014358,
     "end_time": "2024-04-22T15:03:59.867371",
     "exception": false,
     "start_time": "2024-04-22T15:03:59.853013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ecf20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:03:59.878056Z",
     "iopub.status.busy": "2024-04-22T15:03:59.877596Z",
     "iopub.status.idle": "2024-04-22T15:04:02.800588Z",
     "shell.execute_reply": "2024-04-22T15:04:02.799869Z"
    },
    "papermill": {
     "duration": 2.930579,
     "end_time": "2024-04-22T15:04:02.802875",
     "exception": false,
     "start_time": "2024-04-22T15:03:59.872296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')\n",
    "test = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5faa002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:02.814180Z",
     "iopub.status.busy": "2024-04-22T15:04:02.813587Z",
     "iopub.status.idle": "2024-04-22T15:04:36.682187Z",
     "shell.execute_reply": "2024-04-22T15:04:36.681200Z"
    },
    "papermill": {
     "duration": 33.876571,
     "end_time": "2024-04-22T15:04:36.684466",
     "exception": false,
     "start_time": "2024-04-22T15:04:02.807895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(corpus):\n",
    "    tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_lg\")\n",
    "\n",
    "    def tokenizer_fn(data_iterator):\n",
    "        for text in data_iterator:\n",
    "            yield tokenizer(text)\n",
    "\n",
    "    vocab = build_vocab_from_iterator(tokenizer_fn(corpus), specials=[\"<unk>\"], max_tokens=vocab_size)\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    return vocab, tokenizer\n",
    "\n",
    "corpus = list(train[\"full_text\"].values) + list(test[\"full_text\"].values)\n",
    "vocab, tokenizer = build_vocabulary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec24aa20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.696124Z",
     "iopub.status.busy": "2024-04-22T15:04:36.695581Z",
     "iopub.status.idle": "2024-04-22T15:04:36.704794Z",
     "shell.execute_reply": "2024-04-22T15:04:36.704013Z"
    },
    "papermill": {
     "duration": 0.016895,
     "end_time": "2024-04-22T15:04:36.706596",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.689701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(dataframe, vocab, is_test=False):\n",
    "    dataframe['tokens'] = dataframe['tokens'].apply(lambda x: x[:max_seq_len])\n",
    "    dataframe['seq_len'] = dataframe['tokens'].apply(lambda x: len(x))\n",
    "    dataframe[\"token_num\"] = dataframe[\"tokens\"].apply(lambda x: np.array(vocab(x), dtype=np.int64))\n",
    "    dataframe['seq_len'] = dataframe['tokens'].apply(lambda x: len(x))\n",
    "    percentiles = [i * 0.1 for i in range(10)] + [.95, .99, .995]\n",
    "    buckets = np.quantile(dataframe['seq_len'], percentiles)\n",
    "    bucket_labels = [i for i in range(len(buckets) - 1)]\n",
    "    dataframe['bucket'] = pd.cut(dataframe['seq_len'], bins=buckets, labels=bucket_labels)\n",
    "    dataframe[\"bucket\"] = dataframe[\"bucket\"].fillna(0)\n",
    "    dataframe[\"bucket\"] = dataframe[\"bucket\"].astype(int)\n",
    "    dataframe[\"seq_len\"] = dataframe[\"seq_len\"].astype(int)\n",
    "    if is_test:\n",
    "        return dataframe[['token_num', 'seq_len', 'bucket', 'document']]\n",
    "    return dataframe[['token_num', 'labels', \"seq_len\", \"bucket\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6a7f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.717022Z",
     "iopub.status.busy": "2024-04-22T15:04:36.716699Z",
     "iopub.status.idle": "2024-04-22T15:04:36.739893Z",
     "shell.execute_reply": "2024-04-22T15:04:36.739049Z"
    },
    "papermill": {
     "duration": 0.030675,
     "end_time": "2024-04-22T15:04:36.741943",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.711268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = tokenize_text(test, vocab, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971cffcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.752920Z",
     "iopub.status.busy": "2024-04-22T15:04:36.752200Z",
     "iopub.status.idle": "2024-04-22T15:04:36.757455Z",
     "shell.execute_reply": "2024-04-22T15:04:36.756740Z"
    },
    "papermill": {
     "duration": 0.012569,
     "end_time": "2024-04-22T15:04:36.759230",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.746661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_2_id = {\n",
    "    \"O\": 0,\n",
    "    \"B-NAME_STUDENT\": 1,\n",
    "    \"I-NAME_STUDENT\": 2,\n",
    "    \"B-URL_PERSONAL\": 3,\n",
    "    \"B-ID_NUM\": 4,\n",
    "    \"B-EMAIL\": 5,\n",
    "    \"I-STREET_ADDRESS\": 6,\n",
    "    \"I-PHONE_NUM\": 7,\n",
    "    \"B-USERNAME\": 8,\n",
    "    \"B-PHONE_NUM\": 9,\n",
    "    \"B-STREET_ADDRESS\": 10,\n",
    "    \"I-URL_PERSONAL\": 11,\n",
    "    \"I-ID_NUM\": 12\n",
    "}\n",
    "\n",
    "id_2_label = {v: k for k, v in label_2_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79dc35e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.770171Z",
     "iopub.status.busy": "2024-04-22T15:04:36.769932Z",
     "iopub.status.idle": "2024-04-22T15:04:36.784603Z",
     "shell.execute_reply": "2024-04-22T15:04:36.783870Z"
    },
    "papermill": {
     "duration": 0.022254,
     "end_time": "2024-04-22T15:04:36.786433",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.764179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_batch(dataframe, batch_size):\n",
    "    complete_buckets = []\n",
    "    buckets = [bucket_df for _, bucket_df in dataframe.groupby('bucket')]\n",
    "\n",
    "    for gr_id, bucket in enumerate(buckets):\n",
    "        l = len(bucket)\n",
    "        remainder = l % batch_size\n",
    "        integer = l // batch_size\n",
    "\n",
    "        if remainder != 0:\n",
    "            bucket = pd.concat([bucket, pd.concat([bucket.iloc[:1]] * (batch_size - remainder))], ignore_index=True)\n",
    "            integer += 1\n",
    "\n",
    "        batch_ids = []\n",
    "        for i in range(integer):\n",
    "            batch_ids.extend([f'{i}_bucket{gr_id}'] * batch_size)\n",
    "\n",
    "        bucket['batch_id'] = batch_ids\n",
    "        complete_buckets.append(bucket)\n",
    "    return pd.concat(complete_buckets, ignore_index=True)\n",
    "\n",
    "\n",
    "def shuffle_batches(dataframe):\n",
    "    batch_buckets = [df_new for _, df_new in dataframe.groupby('batch_id')]\n",
    "    random.shuffle(batch_buckets)\n",
    "    return pd.concat(batch_buckets).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def concater_collate(batch):\n",
    "    (xx, yy, lengths, buckets) = zip(*batch)\n",
    "    xx = torch.cat(xx, 0)\n",
    "    yy = torch.from_numpy(np.array(yy))\n",
    "    return xx, yy, list(lengths), list(buckets)\n",
    "\n",
    "def concater_collate_test(batch):\n",
    "    (xx, lengths, buckets, documents) = zip(*batch)\n",
    "    xx = torch.cat(xx, 0)\n",
    "    return xx, list(lengths), list(buckets), list(documents)\n",
    "\n",
    "\n",
    "class PIIDataset(Dataset):\n",
    "    def __init__(self, dataframe, batch_size, is_test=False):\n",
    "        dataframe = complete_batch(dataframe=dataframe, batch_size=batch_size)\n",
    "        dataframe = shuffle_batches(dataframe=dataframe)\n",
    "        self.is_test = is_test\n",
    "        if is_test:\n",
    "            self.dataframe = dataframe[['token_num', 'seq_len', 'bucket', 'document']]\n",
    "        else:\n",
    "            self.dataframe = dataframe[['token_num', 'labels', 'seq_len', 'bucket']]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            X, seq_len, bucket, document = self.dataframe.iloc[index, :]\n",
    "            X = torch.from_numpy(X)\n",
    "            return X, seq_len, bucket, document\n",
    "             \n",
    "        else:\n",
    "            X, Y, seq_len, bucket = self.dataframe.iloc[index, :]\n",
    "            Y = torch.from_numpy(np.array(Y))\n",
    "            padding = max_seq_len - len(Y)\n",
    "            Y = F.pad(Y, (0, padding), value=99)\n",
    "            X = torch.from_numpy(X)\n",
    "            return X, Y, seq_len, bucket\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e7d4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.796987Z",
     "iopub.status.busy": "2024-04-22T15:04:36.796692Z",
     "iopub.status.idle": "2024-04-22T15:04:36.813791Z",
     "shell.execute_reply": "2024-04-22T15:04:36.812924Z"
    },
    "papermill": {
     "duration": 0.024394,
     "end_time": "2024-04-22T15:04:36.815636",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.791242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = PIIDataset(test, batch_size, True)\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=concater_collate_test,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a394de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.826190Z",
     "iopub.status.busy": "2024-04-22T15:04:36.825918Z",
     "iopub.status.idle": "2024-04-22T15:04:36.846774Z",
     "shell.execute_reply": "2024-04-22T15:04:36.845924Z"
    },
    "papermill": {
     "duration": 0.028286,
     "end_time": "2024-04-22T15:04:36.848615",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.820329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RotateChord(nn.Module):\n",
    "    def __init__(self, n_tracks, track_size):\n",
    "        super(RotateChord, self).__init__()\n",
    "        self.n_tracks = n_tracks\n",
    "        self.track_size = track_size\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        ys = torch.split(\n",
    "            tensor=x,\n",
    "            split_size_or_sections=lengths,\n",
    "            dim=0\n",
    "        )\n",
    "\n",
    "        zs = []\n",
    "\n",
    "        for y in ys:\n",
    "            y = torch.split(\n",
    "                tensor=y,\n",
    "                split_size_or_sections=self.track_size,\n",
    "                dim=-1\n",
    "            )\n",
    "            z = [y[0]]\n",
    "            for i in range(1, len(y)):\n",
    "                offset = -2 ** (i - 1)\n",
    "                z.append(torch.roll(y[i], shifts=offset, dims=0))\n",
    "            z = torch.cat(z, -1)\n",
    "            zs.append(z)\n",
    "\n",
    "        z = torch.cat(zs, 0)\n",
    "        assert z.shape == x.shape, 'shape mismatch'\n",
    "        return z\n",
    "\n",
    "\n",
    "class ChordMixerBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            n_tracks,\n",
    "            track_size,\n",
    "            hidden_size,\n",
    "            mlp_dropout,\n",
    "            layer_dropout\n",
    "    ):\n",
    "        super(ChordMixerBlock, self).__init__()\n",
    "\n",
    "        self.mixer = MLP(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            embedding_size,\n",
    "            act_layer=nn.GELU,\n",
    "            drop=mlp_dropout\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(layer_dropout)\n",
    "\n",
    "        self.rotator = RotateChord(n_tracks, track_size)\n",
    "\n",
    "    def forward(self, data, lengths):\n",
    "        res_con = data\n",
    "        data = self.mixer(data)\n",
    "        data = self.dropout(data)\n",
    "        data = self.rotator(data, lengths)\n",
    "        data = data + res_con\n",
    "        return data\n",
    "\n",
    "\n",
    "class ChordMixer(nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_size, max_seq_len=max_seq_len, track_size=16, hidden_size=196, mlp_dropout=0.0, layer_dropout=0.0):\n",
    "        super(ChordMixer, self).__init__()\n",
    "        self.max_n_layers = math.ceil(np.log2(max_seq_len))\n",
    "        n_tracks = math.ceil(np.log2(max_seq_len))\n",
    "        embedding_size = int(n_tracks * track_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_size\n",
    "        )\n",
    "\n",
    "        self.chordmixer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ChordMixerBlock(\n",
    "                    embedding_size,\n",
    "                    n_tracks,\n",
    "                    track_size,\n",
    "                    hidden_size,\n",
    "                    mlp_dropout,\n",
    "                    layer_dropout\n",
    "                )\n",
    "                for _ in range(self.max_n_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.reshape = nn.Linear(embedding_size, max_seq_len * embedding_size)\n",
    "        self.final = nn.Linear(embedding_size, 13)\n",
    "\n",
    "    def forward(self, data, lengths):\n",
    "        n_layers = math.ceil(np.log2(lengths[0]))\n",
    "\n",
    "        data = self.embedding(data)\n",
    "        for layer in range(n_layers):\n",
    "            data = self.chordmixer_blocks[layer](data, lengths)\n",
    "\n",
    "        data = [torch.mean(t, dim=0) for t in torch.split(data, lengths)]\n",
    "        data = torch.stack(data)\n",
    "        \n",
    "        data = self.reshape(data)\n",
    "        data = data.view(data.size(0), self.max_seq_len, -1)\n",
    "        \n",
    "        data = self.final(data)\n",
    "        \n",
    "        return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ee5a135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:36.858936Z",
     "iopub.status.busy": "2024-04-22T15:04:36.858675Z",
     "iopub.status.idle": "2024-04-22T15:04:44.274010Z",
     "shell.execute_reply": "2024-04-22T15:04:44.272966Z"
    },
    "papermill": {
     "duration": 7.423097,
     "end_time": "2024-04-22T15:04:44.276389",
     "exception": false,
     "start_time": "2024-04-22T15:04:36.853292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/pii-detection-chordmixer/checkpoints/epoch_70_loss_5.039997501475992e-05.pt\"\n",
    "model = ChordMixer().to(device)\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for x, seq_len, bucket, document in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    \n",
    "    y_hat = model(x, seq_len)\n",
    "    y_pred = torch.argmax(y_hat, dim=2)\n",
    "    temp_preds = {\n",
    "        \"tokens\": x.cpu().numpy(),\n",
    "        \"document\": document,\n",
    "        \"labels\": y_pred.cpu().numpy()\n",
    "    }\n",
    "    predictions.append(temp_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665a9e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:44.287960Z",
     "iopub.status.busy": "2024-04-22T15:04:44.287421Z",
     "iopub.status.idle": "2024-04-22T15:04:44.418490Z",
     "shell.execute_reply": "2024-04-22T15:04:44.417756Z"
    },
    "papermill": {
     "duration": 0.139006,
     "end_time": "2024-04-22T15:04:44.420514",
     "exception": false,
     "start_time": "2024-04-22T15:04:44.281508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for pred in predictions:\n",
    "    documents = pred['document']\n",
    "    labels = pred['labels']\n",
    "    tokens = pred['tokens']\n",
    "    for i in range(batch_size):\n",
    "        document = documents[i]\n",
    "        for idx, label in enumerate(labels[i]):\n",
    "            if label != 0 and idx < len(tokens):\n",
    "                result.append({\n",
    "                    \"document\": document,\n",
    "                    \"token\": idx,\n",
    "                    \"word\": vocab.get_itos()[tokens[idx]],\n",
    "                    \"label\": id_2_label[label]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d63d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-22T15:04:44.431245Z",
     "iopub.status.busy": "2024-04-22T15:04:44.430974Z",
     "iopub.status.idle": "2024-04-22T15:04:44.458859Z",
     "shell.execute_reply": "2024-04-22T15:04:44.458004Z"
    },
    "papermill": {
     "duration": 0.035433,
     "end_time": "2024-04-22T15:04:44.460827",
     "exception": false,
     "start_time": "2024-04-22T15:04:44.425394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label\n",
       "0        0         7      9  B-NAME_STUDENT\n",
       "1        1         7     10  I-NAME_STUDENT\n",
       "2        2         7    482  B-NAME_STUDENT\n",
       "3        3         7    483  I-NAME_STUDENT\n",
       "4        4         7    741  B-NAME_STUDENT\n",
       "5        5         7    742  I-NAME_STUDENT\n",
       "6        6        10      0  B-NAME_STUDENT\n",
       "7        7        10      1  I-NAME_STUDENT\n",
       "8        8        10    464  B-NAME_STUDENT\n",
       "9        9        10    465  I-NAME_STUDENT\n",
       "10      10        16      4  B-NAME_STUDENT\n",
       "11      11        16      5  I-NAME_STUDENT\n",
       "12      12        20      5  B-NAME_STUDENT\n",
       "13      13        20      6  I-NAME_STUDENT\n",
       "14      14        56     12  B-NAME_STUDENT\n",
       "15      15        56     13  I-NAME_STUDENT\n",
       "16      16        86      6  B-NAME_STUDENT\n",
       "17      17        86      7  I-NAME_STUDENT\n",
       "18      18        93      0  B-NAME_STUDENT\n",
       "19      19        93      1  I-NAME_STUDENT\n",
       "20      20       104      8  B-NAME_STUDENT\n",
       "21      21       104      9  I-NAME_STUDENT\n",
       "22      22       112      5  B-NAME_STUDENT\n",
       "23      23       112      6  I-NAME_STUDENT\n",
       "24      24       123     32  B-NAME_STUDENT\n",
       "25      25       123     33  I-NAME_STUDENT"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "result_df = result_df.drop_duplicates(subset=[\"document\", \"token\", \"label\"])\n",
    "result_df = result_df.sort_values(by=['document', 'token']).reset_index(drop=True)\n",
    "result_df[\"row_id\"] = list(range(len(result_df)))\n",
    "result_df = result_df[[\"row_id\", \"document\", \"token\", \"label\"]]\n",
    "result_df = result_df.astype(\n",
    "    {\n",
    "        \"row_id\": \"int64\",\n",
    "        \"document\": \"int64\",\n",
    "        \"token\": \"int64\",\n",
    "        \"label\": \"string\",\n",
    "    }\n",
    ")\n",
    "result_df.to_csv(\"submission.csv\", index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3db58",
   "metadata": {
    "papermill": {
     "duration": 0.004909,
     "end_time": "2024-04-22T15:04:44.472122",
     "exception": false,
     "start_time": "2024-04-22T15:04:44.467213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4851466,
     "sourceId": 8191945,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 54.722146,
   "end_time": "2024-04-22T15:04:46.601369",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-22T15:03:51.879223",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
