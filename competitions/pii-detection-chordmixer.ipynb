{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a01d62",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:02.629883Z",
     "iopub.status.busy": "2024-04-20T17:57:02.629533Z",
     "iopub.status.idle": "2024-04-20T17:57:09.354719Z",
     "shell.execute_reply": "2024-04-20T17:57:09.353849Z"
    },
    "papermill": {
     "duration": 6.735265,
     "end_time": "2024-04-20T17:57:09.357097",
     "exception": false,
     "start_time": "2024-04-20T17:57:02.621832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac5a4ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:09.372361Z",
     "iopub.status.busy": "2024-04-20T17:57:09.371764Z",
     "iopub.status.idle": "2024-04-20T17:57:09.376145Z",
     "shell.execute_reply": "2024-04-20T17:57:09.375285Z"
    },
    "papermill": {
     "duration": 0.01459,
     "end_time": "2024-04-20T17:57:09.378022",
     "exception": false,
     "start_time": "2024-04-20T17:57:09.363432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 27\n",
    "batch_size = 1\n",
    "max_epochs = 10\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cefa0de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:09.390657Z",
     "iopub.status.busy": "2024-04-20T17:57:09.390385Z",
     "iopub.status.idle": "2024-04-20T17:57:09.396932Z",
     "shell.execute_reply": "2024-04-20T17:57:09.396273Z"
    },
    "papermill": {
     "duration": 0.014775,
     "end_time": "2024-04-20T17:57:09.398661",
     "exception": false,
     "start_time": "2024-04-20T17:57:09.383886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c6e644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:09.411246Z",
     "iopub.status.busy": "2024-04-20T17:57:09.410743Z",
     "iopub.status.idle": "2024-04-20T17:57:11.854237Z",
     "shell.execute_reply": "2024-04-20T17:57:11.853468Z"
    },
    "papermill": {
     "duration": 2.452388,
     "end_time": "2024-04-20T17:57:11.856738",
     "exception": false,
     "start_time": "2024-04-20T17:57:09.404350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')\n",
    "test = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')\n",
    "\n",
    "# train = train_ds.sample(frac=0.8, random_state=seed)\n",
    "# val = train_ds.drop(train.index)\n",
    "train = train_ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8323800c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:11.870997Z",
     "iopub.status.busy": "2024-04-20T17:57:11.870696Z",
     "iopub.status.idle": "2024-04-20T17:57:46.656921Z",
     "shell.execute_reply": "2024-04-20T17:57:46.655911Z"
    },
    "papermill": {
     "duration": 34.795666,
     "end_time": "2024-04-20T17:57:46.659149",
     "exception": false,
     "start_time": "2024-04-20T17:57:11.863483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6817/6817 [00:26<00:00, 259.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size: 53986\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(corpus):\n",
    "    tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_lg\")\n",
    "\n",
    "    def tokenizer_fn(data_iterator):\n",
    "        for text in tqdm(data_iterator):\n",
    "            yield tokenizer(text)\n",
    "\n",
    "    vocab = build_vocab_from_iterator(tokenizer_fn(corpus), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    return vocab, tokenizer\n",
    "\n",
    "corpus = list(train_ds[\"full_text\"].values) + list(test[\"full_text\"].values)\n",
    "vocab, tokenizer = build_vocabulary(corpus)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"\\nVocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55715ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:46.712080Z",
     "iopub.status.busy": "2024-04-20T17:57:46.711488Z",
     "iopub.status.idle": "2024-04-20T17:57:46.720070Z",
     "shell.execute_reply": "2024-04-20T17:57:46.719230Z"
    },
    "papermill": {
     "duration": 0.036489,
     "end_time": "2024-04-20T17:57:46.722026",
     "exception": false,
     "start_time": "2024-04-20T17:57:46.685537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(dataframe, vocab, is_test=False):\n",
    "    dataframe[\"token_num\"] = dataframe[\"tokens\"].apply(lambda x: np.array(vocab(x), dtype=np.int64))\n",
    "    dataframe['seq_len'] = dataframe['tokens'].apply(lambda x: len(x))\n",
    "    percentiles = [i * 0.1 for i in range(10)] + [.95, .99, .995]\n",
    "    buckets = np.quantile(dataframe['seq_len'], percentiles)\n",
    "    bucket_labels = [i for i in range(len(buckets) - 1)]\n",
    "    dataframe['bucket'] = pd.cut(dataframe['seq_len'], bins=buckets, labels=bucket_labels)\n",
    "    dataframe[\"bucket\"] = dataframe[\"bucket\"].fillna(0)\n",
    "    dataframe[\"bucket\"] = dataframe[\"bucket\"].astype(int)\n",
    "    dataframe[\"seq_len\"] = dataframe[\"seq_len\"].astype(int)\n",
    "    if is_test:\n",
    "        return dataframe[['token_num', 'seq_len', 'bucket', 'document']]\n",
    "    return dataframe[['token_num', 'labels', \"seq_len\", \"bucket\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04517977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:46.772758Z",
     "iopub.status.busy": "2024-04-20T17:57:46.772447Z",
     "iopub.status.idle": "2024-04-20T17:57:47.628259Z",
     "shell.execute_reply": "2024-04-20T17:57:47.627476Z"
    },
    "papermill": {
     "duration": 0.883852,
     "end_time": "2024-04-20T17:57:47.630664",
     "exception": false,
     "start_time": "2024-04-20T17:57:46.746812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tokenize_text(train, vocab, False)\n",
    "# val = tokenize_text(val, vocab, False)\n",
    "test = tokenize_text(test, vocab, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c5e457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:47.683819Z",
     "iopub.status.busy": "2024-04-20T17:57:47.683133Z",
     "iopub.status.idle": "2024-04-20T17:57:47.688677Z",
     "shell.execute_reply": "2024-04-20T17:57:47.687854Z"
    },
    "papermill": {
     "duration": 0.033518,
     "end_time": "2024-04-20T17:57:47.690533",
     "exception": false,
     "start_time": "2024-04-20T17:57:47.657015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_2_id = {\n",
    "    \"O\": 0,\n",
    "    \"B-NAME_STUDENT\": 1,\n",
    "    \"I-NAME_STUDENT\": 2,\n",
    "    \"B-URL_PERSONAL\": 3,\n",
    "    \"B-ID_NUM\": 4,\n",
    "    \"B-EMAIL\": 5,\n",
    "    \"I-STREET_ADDRESS\": 6,\n",
    "    \"I-PHONE_NUM\": 7,\n",
    "    \"B-USERNAME\": 8,\n",
    "    \"B-PHONE_NUM\": 9,\n",
    "    \"B-STREET_ADDRESS\": 10,\n",
    "    \"I-URL_PERSONAL\": 11,\n",
    "    \"I-ID_NUM\": 12\n",
    "}\n",
    "\n",
    "id_2_label = {v: k for k, v in label_2_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92edcdb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:47.741822Z",
     "iopub.status.busy": "2024-04-20T17:57:47.741446Z",
     "iopub.status.idle": "2024-04-20T17:57:48.121782Z",
     "shell.execute_reply": "2024-04-20T17:57:48.121000Z"
    },
    "papermill": {
     "duration": 0.40862,
     "end_time": "2024-04-20T17:57:48.124121",
     "exception": false,
     "start_time": "2024-04-20T17:57:47.715501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"labels\"] = train[\"labels\"].apply(lambda x: [label_2_id[l] for l in x])\n",
    "# val[\"labels\"] = val[\"labels\"].apply(lambda x: [label_2_id[l] for l in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b34583a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:48.179138Z",
     "iopub.status.busy": "2024-04-20T17:57:48.178801Z",
     "iopub.status.idle": "2024-04-20T17:57:48.200747Z",
     "shell.execute_reply": "2024-04-20T17:57:48.198462Z"
    },
    "papermill": {
     "duration": 0.054024,
     "end_time": "2024-04-20T17:57:48.203254",
     "exception": false,
     "start_time": "2024-04-20T17:57:48.149230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_batch(dataframe, batch_size):\n",
    "    complete_buckets = []\n",
    "    buckets = [bucket_df for _, bucket_df in dataframe.groupby('bucket')]\n",
    "\n",
    "    for gr_id, bucket in enumerate(buckets):\n",
    "        l = len(bucket)\n",
    "        remainder = l % batch_size\n",
    "        integer = l // batch_size\n",
    "\n",
    "        if remainder != 0:\n",
    "            bucket = pd.concat([bucket, pd.concat([bucket.iloc[:1]] * (batch_size - remainder))], ignore_index=True)\n",
    "            integer += 1\n",
    "\n",
    "        batch_ids = []\n",
    "        for i in range(integer):\n",
    "            batch_ids.extend([f'{i}_bucket{gr_id}'] * batch_size)\n",
    "\n",
    "        bucket['batch_id'] = batch_ids\n",
    "        complete_buckets.append(bucket)\n",
    "    return pd.concat(complete_buckets, ignore_index=True)\n",
    "\n",
    "\n",
    "def shuffle_batches(dataframe):\n",
    "    batch_buckets = [df_new for _, df_new in dataframe.groupby('batch_id')]\n",
    "    random.shuffle(batch_buckets)\n",
    "    return pd.concat(batch_buckets).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def concater_collate(batch):\n",
    "    (xx, yy, lengths, buckets) = zip(*batch)\n",
    "    xx = torch.cat(xx, 0)\n",
    "    yy = torch.from_numpy(np.array(yy))\n",
    "    return xx, yy, list(lengths), list(buckets)\n",
    "\n",
    "def concater_collate_test(batch):\n",
    "    (xx, lengths, buckets, documents) = zip(*batch)\n",
    "    xx = torch.cat(xx, 0)\n",
    "    return xx, list(lengths), list(buckets), list(documents)\n",
    "\n",
    "\n",
    "class PIIDataset(Dataset):\n",
    "    def __init__(self, dataframe, batch_size, is_test=False):\n",
    "        dataframe = complete_batch(dataframe=dataframe, batch_size=batch_size)\n",
    "        dataframe = shuffle_batches(dataframe=dataframe)\n",
    "        self.is_test = is_test\n",
    "        if is_test:\n",
    "            self.dataframe = dataframe[['token_num', 'seq_len', 'bucket', 'document']]\n",
    "        else:\n",
    "            self.dataframe = dataframe[['token_num', 'labels', 'seq_len', 'bucket']]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            X, seq_len, bucket, document = self.dataframe.iloc[index, :]\n",
    "            X = torch.from_numpy(X)\n",
    "            return X, seq_len, bucket, document\n",
    "             \n",
    "        else:\n",
    "            X, Y, seq_len, bucket = self.dataframe.iloc[index, :]\n",
    "            Y = torch.from_numpy(np.array(Y))\n",
    "            padding = 3298 - len(Y)\n",
    "            Y = F.pad(Y, (0, padding), value=99)\n",
    "            X = torch.from_numpy(X)\n",
    "            return X, Y, seq_len, bucket\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f60f1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:48.265689Z",
     "iopub.status.busy": "2024-04-20T17:57:48.265354Z",
     "iopub.status.idle": "2024-04-20T17:57:49.707837Z",
     "shell.execute_reply": "2024-04-20T17:57:49.706766Z"
    },
    "papermill": {
     "duration": 1.471869,
     "end_time": "2024-04-20T17:57:49.710354",
     "exception": false,
     "start_time": "2024-04-20T17:57:48.238485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PIIDataset(train, batch_size, False)\n",
    "# val_dataset = PIIDataset(val, batch_size, False)\n",
    "test_dataset = PIIDataset(test, batch_size, True)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=concater_collate,\n",
    "    drop_last=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# val_dataloader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False,\n",
    "#     collate_fn=concater_collate,\n",
    "#     drop_last=False,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=concater_collate_test,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abaf145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:49.765357Z",
     "iopub.status.busy": "2024-04-20T17:57:49.765017Z",
     "iopub.status.idle": "2024-04-20T17:57:49.795196Z",
     "shell.execute_reply": "2024-04-20T17:57:49.794312Z"
    },
    "papermill": {
     "duration": 0.059635,
     "end_time": "2024-04-20T17:57:49.797039",
     "exception": false,
     "start_time": "2024-04-20T17:57:49.737404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RotateChord(nn.Module):\n",
    "    def __init__(self, n_tracks, track_size):\n",
    "        super(RotateChord, self).__init__()\n",
    "        self.n_tracks = n_tracks\n",
    "        self.track_size = track_size\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        ys = torch.split(\n",
    "            tensor=x,\n",
    "            split_size_or_sections=lengths,\n",
    "            dim=0\n",
    "        )\n",
    "\n",
    "        zs = []\n",
    "\n",
    "        # roll sequences separately\n",
    "        for y in ys:\n",
    "            y = torch.split(\n",
    "                tensor=y,\n",
    "                split_size_or_sections=self.track_size,\n",
    "                dim=-1\n",
    "            )\n",
    "            z = [y[0]]\n",
    "            for i in range(1, len(y)):\n",
    "                offset = -2 ** (i - 1)\n",
    "                z.append(torch.roll(y[i], shifts=offset, dims=0))\n",
    "            z = torch.cat(z, -1)\n",
    "            zs.append(z)\n",
    "\n",
    "        z = torch.cat(zs, 0)\n",
    "        assert z.shape == x.shape, 'shape mismatch'\n",
    "        return z\n",
    "\n",
    "\n",
    "class ChordMixerBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            n_tracks,\n",
    "            track_size,\n",
    "            hidden_size,\n",
    "            mlp_dropout,\n",
    "            layer_dropout\n",
    "    ):\n",
    "        super(ChordMixerBlock, self).__init__()\n",
    "\n",
    "        self.mixer = MLP(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            embedding_size,\n",
    "            act_layer=nn.GELU,\n",
    "            drop=mlp_dropout\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(layer_dropout)\n",
    "\n",
    "        self.rotator = RotateChord(n_tracks, track_size)\n",
    "\n",
    "    def forward(self, data, lengths):\n",
    "        res_con = data\n",
    "        data = self.mixer(data)\n",
    "        data = self.dropout(data)\n",
    "        data = self.rotator(data, lengths)\n",
    "        data = data + res_con\n",
    "        return data\n",
    "\n",
    "\n",
    "class ChordMixer(nn.Module):\n",
    "    def __init__(self, vocab_size=53986, max_seq_len=3298, track_size=16, hidden_size=196, mlp_dropout=0.0, layer_dropout=0.0):\n",
    "        super(ChordMixer, self).__init__()\n",
    "        self.max_n_layers = math.ceil(np.log2(max_seq_len))\n",
    "        n_tracks = math.ceil(np.log2(max_seq_len))\n",
    "        embedding_size = int(n_tracks * track_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_size\n",
    "        )\n",
    "\n",
    "        self.chordmixer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ChordMixerBlock(\n",
    "                    embedding_size,\n",
    "                    n_tracks,\n",
    "                    track_size,\n",
    "                    hidden_size,\n",
    "                    mlp_dropout,\n",
    "                    layer_dropout\n",
    "                )\n",
    "                for _ in range(self.max_n_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.reshape = nn.Linear(embedding_size, max_seq_len * embedding_size)\n",
    "        self.final = nn.Linear(embedding_size, 13)\n",
    "\n",
    "    def forward(self, data, lengths):\n",
    "        n_layers = math.ceil(np.log2(lengths[0]))\n",
    "\n",
    "        data = self.embedding(data)\n",
    "        for layer in range(n_layers):\n",
    "            data = self.chordmixer_blocks[layer](data, lengths)\n",
    "\n",
    "        data = [torch.mean(t, dim=0) for t in torch.split(data, lengths)]\n",
    "        data = torch.stack(data)\n",
    "        \n",
    "        data = self.reshape(data)\n",
    "        data = data.view(data.size(0), self.max_seq_len, -1)\n",
    "        \n",
    "        data = self.final(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "#         self.val_dataloader = val_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train(self, current_epoch_nr):\n",
    "        self.model.train()\n",
    "\n",
    "        num_batches = len(self.train_dataloader)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        items_processed = 0\n",
    "        fbeta_score_total = 0.0\n",
    "\n",
    "        loop = tqdm(enumerate(self.train_dataloader), total=num_batches)\n",
    "        for idx, (x, y, seq_len, bucket) in loop:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_hat = self.model(x, seq_len)\n",
    "\n",
    "            y_hat_flat = y_hat.view(-1, y_hat.size(-1))\n",
    "            y_flat = y.view(-1)\n",
    "            \n",
    "            mask = y_flat.ne(99)\n",
    "            y_hat_flat_masked = y_hat_flat[mask]\n",
    "            y_flat_masked = y_flat[mask]\n",
    "\n",
    "            loss = self.criterion(y_hat_flat_masked, y_flat_masked)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            items_processed += y.size(0)\n",
    "            \n",
    "            y_pred = torch.argmax(y_hat_flat_masked, dim=1)\n",
    "            fbeta_score_total += fbeta_score(y_flat_masked.cpu().numpy(), y_pred.cpu().numpy(), beta=5, average='micro')\n",
    "            \n",
    "            loop.set_description(f'Epoch {current_epoch_nr + 1}')\n",
    "            loop.set_postfix(train_loss=round(running_loss / items_processed, 6), fbeta_score=fbeta_score_total / (idx + 1))\n",
    "            \n",
    "#     def validate(self, current_epoch_nr):\n",
    "#         self.model.eval()\n",
    "\n",
    "#         num_batches = len(self.val_dataloader)\n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         items_processed = 0\n",
    "#         fbeta_score_total = 0.0\n",
    "\n",
    "#         loop = tqdm(enumerate(self.val_dataloader), total=num_batches)\n",
    "#         for idx, (x, y, seq_len, bucket) in loop:\n",
    "#             x = x.to(device)\n",
    "#             y = y.to(device)\n",
    "            \n",
    "#             y_hat = self.model(x, seq_len)\n",
    "\n",
    "#             y_hat_flat = y_hat.view(-1, y_hat.size(-1))\n",
    "#             y_flat = y.view(-1)\n",
    "            \n",
    "#             mask = y_flat.ne(99)\n",
    "#             y_hat_flat_masked = y_hat_flat[mask]\n",
    "#             y_flat_masked = y_flat[mask]\n",
    "\n",
    "#             loss = self.criterion(y_hat_flat_masked, y_flat_masked)\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             items_processed += y.size(0)\n",
    "\n",
    "#             y_pred = torch.argmax(y_hat_flat_masked, dim=1)\n",
    "#             fbeta_score_total += fbeta_score(y_flat_masked.cpu().numpy(), y_pred.cpu().numpy(), beta=5, average='micro')\n",
    "            \n",
    "#             loop.set_description(f'Epoch {current_epoch_nr + 1}')\n",
    "#             loop.set_postfix(val_loss=round(running_loss / items_processed, 6), fbeta_score=fbeta_score_total / (idx + 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a510767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T17:57:49.848508Z",
     "iopub.status.busy": "2024-04-20T17:57:49.848207Z",
     "iopub.status.idle": "2024-04-20T18:43:17.243314Z",
     "shell.execute_reply": "2024-04-20T18:43:17.242225Z"
    },
    "papermill": {
     "duration": 2737.002365,
     "end_time": "2024-04-20T18:43:26.824390",
     "exception": false,
     "start_time": "2024-04-20T17:57:49.822025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6807/6807 [04:31<00:00, 25.10it/s, fbeta_score=0.999, train_loss=0.0079]\n",
      "Epoch 2: 100%|██████████| 6807/6807 [04:34<00:00, 24.79it/s, fbeta_score=0.999, train_loss=0.00432]\n",
      "Epoch 3: 100%|██████████| 6807/6807 [04:34<00:00, 24.78it/s, fbeta_score=0.999, train_loss=0.00399]\n",
      "Epoch 4: 100%|██████████| 6807/6807 [04:40<00:00, 24.30it/s, fbeta_score=0.999, train_loss=0.00356]\n",
      "Epoch 5: 100%|██████████| 6807/6807 [04:36<00:00, 24.63it/s, fbeta_score=0.999, train_loss=0.00331]\n",
      "Epoch 6: 100%|██████████| 6807/6807 [04:32<00:00, 24.94it/s, fbeta_score=0.999, train_loss=0.00326]\n",
      "Epoch 7: 100%|██████████| 6807/6807 [04:30<00:00, 25.20it/s, fbeta_score=0.999, train_loss=0.00288]\n",
      "Epoch 8: 100%|██████████| 6807/6807 [04:27<00:00, 25.48it/s, fbeta_score=0.999, train_loss=0.00261]\n",
      "Epoch 9: 100%|██████████| 6807/6807 [04:27<00:00, 25.45it/s, fbeta_score=0.999, train_loss=0.00236]\n",
      "Epoch 10: 100%|██████████| 6807/6807 [04:28<00:00, 25.32it/s, fbeta_score=1, train_loss=0.00204]\n"
     ]
    }
   ],
   "source": [
    "model = ChordMixer().to(device)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(lr=0.0003, params=model.parameters())\n",
    "\n",
    "trainer = Trainer(model, train_dataloader, criterion, optimizer)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    trainer.train(epoch)\n",
    "#     trainer.validate(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6b524a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:43:53.545052Z",
     "iopub.status.busy": "2024-04-20T18:43:53.543996Z",
     "iopub.status.idle": "2024-04-20T18:43:53.736830Z",
     "shell.execute_reply": "2024-04-20T18:43:53.735706Z"
    },
    "papermill": {
     "duration": 13.527398,
     "end_time": "2024-04-20T18:43:53.738855",
     "exception": false,
     "start_time": "2024-04-20T18:43:40.211457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 78.94it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "for idx, (x, seq_len, bucket, document) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    x = x.to(device)\n",
    "    \n",
    "    y_hat = model(x, seq_len)\n",
    "    y_pred = torch.argmax(y_hat, dim=2)\n",
    "    temp_preds = {\n",
    "        \"tokens\": x.cpu().numpy(),\n",
    "        \"document\": document,\n",
    "        \"labels\": y_pred.cpu().numpy()\n",
    "    }\n",
    "    predictions.append(temp_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d56ba59e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:44:20.377547Z",
     "iopub.status.busy": "2024-04-20T18:44:20.377165Z",
     "iopub.status.idle": "2024-04-20T18:44:20.480798Z",
     "shell.execute_reply": "2024-04-20T18:44:20.480038Z"
    },
    "papermill": {
     "duration": 13.539109,
     "end_time": "2024-04-20T18:44:20.482717",
     "exception": false,
     "start_time": "2024-04-20T18:44:06.943608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for pred in predictions:\n",
    "    documents = pred['document']\n",
    "    labels = pred['labels']\n",
    "    tokens = pred['tokens']\n",
    "    for i in range(batch_size):\n",
    "        document = documents[i]\n",
    "        for idx, label in enumerate(labels[i]):\n",
    "            if label != 0 and idx < len(tokens):\n",
    "                result.append({\n",
    "                    \"document\": document,\n",
    "                    \"token\": idx,\n",
    "                    \"word\": vocab.get_itos()[tokens[idx]],\n",
    "                    \"label\": id_2_label[label]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a372612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:44:46.735155Z",
     "iopub.status.busy": "2024-04-20T18:44:46.734805Z",
     "iopub.status.idle": "2024-04-20T18:44:46.745255Z",
     "shell.execute_reply": "2024-04-20T18:44:46.744389Z"
    },
    "papermill": {
     "duration": 13.173248,
     "end_time": "2024-04-20T18:44:46.747040",
     "exception": false,
     "start_time": "2024-04-20T18:44:33.573792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "result_df = result_df.sort_values(by=['document']).reset_index(drop=True)\n",
    "result_df[\"row_id\"] = result_df.index\n",
    "result_df = result_df[[\"row_id\", \"document\", \"token\", \"label\", \"word\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d84090a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:45:13.283315Z",
     "iopub.status.busy": "2024-04-20T18:45:13.282487Z",
     "iopub.status.idle": "2024-04-20T18:45:13.300543Z",
     "shell.execute_reply": "2024-04-20T18:45:13.299619Z"
    },
    "papermill": {
     "duration": 13.300159,
     "end_time": "2024-04-20T18:45:13.302702",
     "exception": false,
     "start_time": "2024-04-20T18:45:00.002543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>430</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>655</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>431</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>445</td>\n",
       "      <td>I-PHONE_NUM</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>318</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>319</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>656</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>B-ID_NUM</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>123</td>\n",
       "      <td>1435</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>altruist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>123</td>\n",
       "      <td>1291</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>appeared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>123</td>\n",
       "      <td>1434</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  document  token           label        word\n",
       "0        0         7    430  B-NAME_STUDENT           ”\n",
       "1        1         7    655  B-NAME_STUDENT          to\n",
       "2        2         7    431  I-NAME_STUDENT          is\n",
       "3        3         7    445     I-PHONE_NUM      person\n",
       "4        4         7    318  B-NAME_STUDENT           .\n",
       "5        5         7    319  I-NAME_STUDENT        \\n\\n\n",
       "6        6         7     21  B-NAME_STUDENT        help\n",
       "7        7         7    656  I-NAME_STUDENT           a\n",
       "8        8         7    741  B-NAME_STUDENT    Nathalie\n",
       "9        9         7    742  I-NAME_STUDENT       Sylla\n",
       "10      10        10      1  I-NAME_STUDENT     Estrada\n",
       "11      11        10      0  B-NAME_STUDENT       Diego\n",
       "12      12        20     24        B-ID_NUM     problem\n",
       "13      13        86      0  B-NAME_STUDENT      Cheese\n",
       "14      14        93      1  I-NAME_STUDENT  Villalobos\n",
       "15      15        93      0  B-NAME_STUDENT      Silvia\n",
       "16      16       123   1435  I-NAME_STUDENT    altruist\n",
       "17      17       123   1291  I-NAME_STUDENT    appeared\n",
       "18      18       123   1434  B-NAME_STUDENT         the"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863d2f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:45:39.937921Z",
     "iopub.status.busy": "2024-04-20T18:45:39.937051Z",
     "iopub.status.idle": "2024-04-20T18:45:39.944781Z",
     "shell.execute_reply": "2024-04-20T18:45:39.944026Z"
    },
    "papermill": {
     "duration": 13.353512,
     "end_time": "2024-04-20T18:45:39.946865",
     "exception": false,
     "start_time": "2024-04-20T18:45:26.593353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953b23a0",
   "metadata": {
    "papermill": {
     "duration": 13.299099,
     "end_time": "2024-04-20T18:46:06.731688",
     "exception": false,
     "start_time": "2024-04-20T18:45:53.432589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2963.711131,
   "end_time": "2024-04-20T18:46:23.474537",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-20T17:56:59.763406",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
