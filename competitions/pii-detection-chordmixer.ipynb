{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3cdf98",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-20T21:44:54.210713Z",
     "iopub.status.busy": "2024-04-20T21:44:54.210307Z",
     "iopub.status.idle": "2024-04-20T21:45:01.917184Z",
     "shell.execute_reply": "2024-04-20T21:45:01.916390Z"
    },
    "papermill": {
     "duration": 7.71809,
     "end_time": "2024-04-20T21:45:01.919538",
     "exception": false,
     "start_time": "2024-04-20T21:44:54.201448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e08548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:01.932861Z",
     "iopub.status.busy": "2024-04-20T21:45:01.932179Z",
     "iopub.status.idle": "2024-04-20T21:45:01.936399Z",
     "shell.execute_reply": "2024-04-20T21:45:01.935553Z"
    },
    "papermill": {
     "duration": 0.012445,
     "end_time": "2024-04-20T21:45:01.938145",
     "exception": false,
     "start_time": "2024-04-20T21:45:01.925700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 27\n",
    "batch_size = 15\n",
    "max_epochs = 1\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5b29ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:01.950922Z",
     "iopub.status.busy": "2024-04-20T21:45:01.950660Z",
     "iopub.status.idle": "2024-04-20T21:45:01.957769Z",
     "shell.execute_reply": "2024-04-20T21:45:01.957083Z"
    },
    "papermill": {
     "duration": 0.015808,
     "end_time": "2024-04-20T21:45:01.959654",
     "exception": false,
     "start_time": "2024-04-20T21:45:01.943846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40ccbba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:01.972305Z",
     "iopub.status.busy": "2024-04-20T21:45:01.972044Z",
     "iopub.status.idle": "2024-04-20T21:45:05.283651Z",
     "shell.execute_reply": "2024-04-20T21:45:05.282692Z"
    },
    "papermill": {
     "duration": 3.320701,
     "end_time": "2024-04-20T21:45:05.285987",
     "exception": false,
     "start_time": "2024-04-20T21:45:01.965286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')\n",
    "test = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/test.json')\n",
    "\n",
    "# train = train_ds.sample(frac=0.8, random_state=seed)\n",
    "# val = train_ds.drop(train.index)\n",
    "train = train_ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "502f5d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:05.299108Z",
     "iopub.status.busy": "2024-04-20T21:45:05.298431Z",
     "iopub.status.idle": "2024-04-20T21:45:39.991270Z",
     "shell.execute_reply": "2024-04-20T21:45:39.990221Z"
    },
    "papermill": {
     "duration": 34.701419,
     "end_time": "2024-04-20T21:45:39.993274",
     "exception": false,
     "start_time": "2024-04-20T21:45:05.291855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6817/6817 [00:25<00:00, 264.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size: 53986\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(corpus):\n",
    "    tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_lg\")\n",
    "\n",
    "    def tokenizer_fn(data_iterator):\n",
    "        for text in tqdm(data_iterator):\n",
    "            yield tokenizer(text)\n",
    "\n",
    "    vocab = build_vocab_from_iterator(tokenizer_fn(corpus), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    return vocab, tokenizer\n",
    "\n",
    "corpus = list(train_ds[\"full_text\"].values) + list(test[\"full_text\"].values)\n",
    "vocab, tokenizer = build_vocabulary(corpus)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"\\nVocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3402df89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:40.045283Z",
     "iopub.status.busy": "2024-04-20T21:45:40.044518Z",
     "iopub.status.idle": "2024-04-20T21:45:40.053212Z",
     "shell.execute_reply": "2024-04-20T21:45:40.052435Z"
    },
    "papermill": {
     "duration": 0.037076,
     "end_time": "2024-04-20T21:45:40.055009",
     "exception": false,
     "start_time": "2024-04-20T21:45:40.017933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(dataframe, vocab, is_test=False):\n",
    "    dataframe[\"token_num\"] = dataframe[\"tokens\"].apply(lambda x: np.array(vocab(x), dtype=np.int64))\n",
    "    dataframe['seq_len'] = dataframe['tokens'].apply(lambda x: len(x))\n",
    "    percentiles = [i * 0.1 for i in range(10)] + [.95, .99, .995]\n",
    "    buckets = np.quantile(dataframe['seq_len'], percentiles)\n",
    "    bucket_labels = [i for i in range(len(buckets) - 1)]\n",
    "    dataframe['bucket'] = pd.cut(dataframe['seq_len'], bins=buckets, labels=bucket_labels)\n",
    "    dataframe[\"bucket\"] = dataframe[\"bucket\"].fillna(0)\n",
    "    dataframe[\"bucket\"] = dataframe[\"bucket\"].astype(int)\n",
    "    dataframe[\"seq_len\"] = dataframe[\"seq_len\"].astype(int)\n",
    "    if is_test:\n",
    "        return dataframe[['token_num', 'seq_len', 'bucket', 'document']]\n",
    "    return dataframe[['token_num', 'labels', \"seq_len\", \"bucket\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229e0b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:40.105621Z",
     "iopub.status.busy": "2024-04-20T21:45:40.105335Z",
     "iopub.status.idle": "2024-04-20T21:45:40.973218Z",
     "shell.execute_reply": "2024-04-20T21:45:40.972433Z"
    },
    "papermill": {
     "duration": 0.895582,
     "end_time": "2024-04-20T21:45:40.975663",
     "exception": false,
     "start_time": "2024-04-20T21:45:40.080081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tokenize_text(train, vocab, False)\n",
    "# val = tokenize_text(val, vocab, False)\n",
    "test = tokenize_text(test, vocab, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475b9aeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:41.027358Z",
     "iopub.status.busy": "2024-04-20T21:45:41.026543Z",
     "iopub.status.idle": "2024-04-20T21:45:41.031953Z",
     "shell.execute_reply": "2024-04-20T21:45:41.031287Z"
    },
    "papermill": {
     "duration": 0.03298,
     "end_time": "2024-04-20T21:45:41.033781",
     "exception": false,
     "start_time": "2024-04-20T21:45:41.000801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_2_id = {\n",
    "    \"O\": 0,\n",
    "    \"B-NAME_STUDENT\": 1,\n",
    "    \"I-NAME_STUDENT\": 2,\n",
    "    \"B-URL_PERSONAL\": 3,\n",
    "    \"B-ID_NUM\": 4,\n",
    "    \"B-EMAIL\": 5,\n",
    "    \"I-STREET_ADDRESS\": 6,\n",
    "    \"I-PHONE_NUM\": 7,\n",
    "    \"B-USERNAME\": 8,\n",
    "    \"B-PHONE_NUM\": 9,\n",
    "    \"B-STREET_ADDRESS\": 10,\n",
    "    \"I-URL_PERSONAL\": 11,\n",
    "    \"I-ID_NUM\": 12\n",
    "}\n",
    "\n",
    "id_2_label = {v: k for k, v in label_2_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d46711da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:41.083429Z",
     "iopub.status.busy": "2024-04-20T21:45:41.082726Z",
     "iopub.status.idle": "2024-04-20T21:45:41.496021Z",
     "shell.execute_reply": "2024-04-20T21:45:41.494990Z"
    },
    "papermill": {
     "duration": 0.44039,
     "end_time": "2024-04-20T21:45:41.498412",
     "exception": false,
     "start_time": "2024-04-20T21:45:41.058022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"labels\"] = train[\"labels\"].apply(lambda x: [label_2_id[l] for l in x])\n",
    "# val[\"labels\"] = val[\"labels\"].apply(lambda x: [label_2_id[l] for l in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f812f9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:41.550538Z",
     "iopub.status.busy": "2024-04-20T21:45:41.550217Z",
     "iopub.status.idle": "2024-04-20T21:45:41.566220Z",
     "shell.execute_reply": "2024-04-20T21:45:41.565347Z"
    },
    "papermill": {
     "duration": 0.045266,
     "end_time": "2024-04-20T21:45:41.568123",
     "exception": false,
     "start_time": "2024-04-20T21:45:41.522857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete_batch(dataframe, batch_size):\n",
    "    complete_buckets = []\n",
    "    buckets = [bucket_df for _, bucket_df in dataframe.groupby('bucket')]\n",
    "\n",
    "    for gr_id, bucket in enumerate(buckets):\n",
    "        l = len(bucket)\n",
    "        remainder = l % batch_size\n",
    "        integer = l // batch_size\n",
    "\n",
    "        if remainder != 0:\n",
    "            bucket = pd.concat([bucket, pd.concat([bucket.iloc[:1]] * (batch_size - remainder))], ignore_index=True)\n",
    "            integer += 1\n",
    "\n",
    "        batch_ids = []\n",
    "        for i in range(integer):\n",
    "            batch_ids.extend([f'{i}_bucket{gr_id}'] * batch_size)\n",
    "\n",
    "        bucket['batch_id'] = batch_ids\n",
    "        complete_buckets.append(bucket)\n",
    "    return pd.concat(complete_buckets, ignore_index=True)\n",
    "\n",
    "\n",
    "def shuffle_batches(dataframe):\n",
    "    batch_buckets = [df_new for _, df_new in dataframe.groupby('batch_id')]\n",
    "    random.shuffle(batch_buckets)\n",
    "    return pd.concat(batch_buckets).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def concater_collate(batch):\n",
    "    (xx, yy, lengths, buckets) = zip(*batch)\n",
    "    xx = torch.cat(xx, 0)\n",
    "    yy = torch.from_numpy(np.array(yy))\n",
    "    return xx, yy, list(lengths), list(buckets)\n",
    "\n",
    "def concater_collate_test(batch):\n",
    "    (xx, lengths, buckets, documents) = zip(*batch)\n",
    "    xx = torch.cat(xx, 0)\n",
    "    return xx, list(lengths), list(buckets), list(documents)\n",
    "\n",
    "\n",
    "class PIIDataset(Dataset):\n",
    "    def __init__(self, dataframe, batch_size, is_test=False):\n",
    "        dataframe = complete_batch(dataframe=dataframe, batch_size=batch_size)\n",
    "        dataframe = shuffle_batches(dataframe=dataframe)\n",
    "        self.is_test = is_test\n",
    "        if is_test:\n",
    "            self.dataframe = dataframe[['token_num', 'seq_len', 'bucket', 'document']]\n",
    "        else:\n",
    "            self.dataframe = dataframe[['token_num', 'labels', 'seq_len', 'bucket']]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            X, seq_len, bucket, document = self.dataframe.iloc[index, :]\n",
    "            X = torch.from_numpy(X)\n",
    "            return X, seq_len, bucket, document\n",
    "             \n",
    "        else:\n",
    "            X, Y, seq_len, bucket = self.dataframe.iloc[index, :]\n",
    "            Y = torch.from_numpy(np.array(Y))\n",
    "            padding = 3298 - len(Y)\n",
    "            Y = F.pad(Y, (0, padding), value=99)\n",
    "            X = torch.from_numpy(X)\n",
    "            return X, Y, seq_len, bucket\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0776afc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:41.618272Z",
     "iopub.status.busy": "2024-04-20T21:45:41.617982Z",
     "iopub.status.idle": "2024-04-20T21:45:41.718465Z",
     "shell.execute_reply": "2024-04-20T21:45:41.717496Z"
    },
    "papermill": {
     "duration": 0.127948,
     "end_time": "2024-04-20T21:45:41.720704",
     "exception": false,
     "start_time": "2024-04-20T21:45:41.592756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PIIDataset(train, batch_size, False)\n",
    "# val_dataset = PIIDataset(val, batch_size, False)\n",
    "test_dataset = PIIDataset(test, batch_size, True)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=concater_collate,\n",
    "    drop_last=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# val_dataloader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False,\n",
    "#     collate_fn=concater_collate,\n",
    "#     drop_last=False,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=concater_collate_test,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3994c76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:41.770976Z",
     "iopub.status.busy": "2024-04-20T21:45:41.770713Z",
     "iopub.status.idle": "2024-04-20T21:45:41.797360Z",
     "shell.execute_reply": "2024-04-20T21:45:41.796622Z"
    },
    "papermill": {
     "duration": 0.053868,
     "end_time": "2024-04-20T21:45:41.799279",
     "exception": false,
     "start_time": "2024-04-20T21:45:41.745411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RotateChord(nn.Module):\n",
    "    def __init__(self, n_tracks, track_size):\n",
    "        super(RotateChord, self).__init__()\n",
    "        self.n_tracks = n_tracks\n",
    "        self.track_size = track_size\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        ys = torch.split(\n",
    "            tensor=x,\n",
    "            split_size_or_sections=lengths,\n",
    "            dim=0\n",
    "        )\n",
    "\n",
    "        zs = []\n",
    "\n",
    "        # roll sequences separately\n",
    "        for y in ys:\n",
    "            y = torch.split(\n",
    "                tensor=y,\n",
    "                split_size_or_sections=self.track_size,\n",
    "                dim=-1\n",
    "            )\n",
    "            z = [y[0]]\n",
    "            for i in range(1, len(y)):\n",
    "                offset = -2 ** (i - 1)\n",
    "                z.append(torch.roll(y[i], shifts=offset, dims=0))\n",
    "            z = torch.cat(z, -1)\n",
    "            zs.append(z)\n",
    "\n",
    "        z = torch.cat(zs, 0)\n",
    "        assert z.shape == x.shape, 'shape mismatch'\n",
    "        return z\n",
    "\n",
    "\n",
    "class ChordMixerBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_size,\n",
    "            n_tracks,\n",
    "            track_size,\n",
    "            hidden_size,\n",
    "            mlp_dropout,\n",
    "            layer_dropout\n",
    "    ):\n",
    "        super(ChordMixerBlock, self).__init__()\n",
    "\n",
    "        self.mixer = MLP(\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            embedding_size,\n",
    "            act_layer=nn.GELU,\n",
    "            drop=mlp_dropout\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(layer_dropout)\n",
    "\n",
    "        self.rotator = RotateChord(n_tracks, track_size)\n",
    "\n",
    "    def forward(self, data, lengths):\n",
    "        res_con = data\n",
    "        data = self.mixer(data)\n",
    "        data = self.dropout(data)\n",
    "        data = self.rotator(data, lengths)\n",
    "        data = data + res_con\n",
    "        return data\n",
    "\n",
    "\n",
    "class ChordMixer(nn.Module):\n",
    "    def __init__(self, vocab_size=53986, max_seq_len=3298, track_size=16, hidden_size=196, mlp_dropout=0.0, layer_dropout=0.0):\n",
    "        super(ChordMixer, self).__init__()\n",
    "        self.max_n_layers = math.ceil(np.log2(max_seq_len))\n",
    "        n_tracks = math.ceil(np.log2(max_seq_len))\n",
    "        embedding_size = int(n_tracks * track_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_size\n",
    "        )\n",
    "\n",
    "        self.chordmixer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                ChordMixerBlock(\n",
    "                    embedding_size,\n",
    "                    n_tracks,\n",
    "                    track_size,\n",
    "                    hidden_size,\n",
    "                    mlp_dropout,\n",
    "                    layer_dropout\n",
    "                )\n",
    "                for _ in range(self.max_n_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.reshape = nn.Linear(embedding_size, max_seq_len * embedding_size)\n",
    "        self.final = nn.Linear(embedding_size, 13)\n",
    "\n",
    "    def forward(self, data, lengths):\n",
    "        n_layers = math.ceil(np.log2(lengths[0]))\n",
    "\n",
    "        data = self.embedding(data)\n",
    "        for layer in range(n_layers):\n",
    "            data = self.chordmixer_blocks[layer](data, lengths)\n",
    "\n",
    "        data = [torch.mean(t, dim=0) for t in torch.split(data, lengths)]\n",
    "        data = torch.stack(data)\n",
    "        \n",
    "        data = self.reshape(data)\n",
    "        data = data.view(data.size(0), self.max_seq_len, -1)\n",
    "        \n",
    "        data = self.final(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader, criterion, optimizer):\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "#         self.val_dataloader = val_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def train(self, current_epoch_nr):\n",
    "        self.model.train()\n",
    "\n",
    "        num_batches = len(self.train_dataloader)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        items_processed = 0\n",
    "        fbeta_score_total = 0.0\n",
    "\n",
    "#         loop = tqdm(enumerate(self.train_dataloader), total=num_batches)\n",
    "        for idx, (x, y, seq_len, bucket) in enumerate(self.train_dataloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_hat = self.model(x, seq_len)\n",
    "\n",
    "            y_hat_flat = y_hat.view(-1, y_hat.size(-1))\n",
    "            y_flat = y.view(-1)\n",
    "            \n",
    "            mask = y_flat.ne(99)\n",
    "            y_hat_flat_masked = y_hat_flat[mask]\n",
    "            y_flat_masked = y_flat[mask]\n",
    "\n",
    "            loss = self.criterion(y_hat_flat_masked, y_flat_masked)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             items_processed += y.size(0)\n",
    "            \n",
    "#             y_pred = torch.argmax(y_hat_flat_masked, dim=1)\n",
    "#             fbeta_score_total += fbeta_score(y_flat_masked.cpu().numpy(), y_pred.cpu().numpy(), beta=5, average='micro')\n",
    "            \n",
    "#             loop.set_description(f'Epoch {current_epoch_nr + 1}')\n",
    "#             loop.set_postfix(train_loss=round(running_loss / items_processed, 6), fbeta_score=fbeta_score_total / (idx + 1))\n",
    "            \n",
    "#     def validate(self, current_epoch_nr):\n",
    "#         self.model.eval()\n",
    "\n",
    "#         num_batches = len(self.val_dataloader)\n",
    "\n",
    "#         running_loss = 0.0\n",
    "#         items_processed = 0\n",
    "#         fbeta_score_total = 0.0\n",
    "\n",
    "#         loop = tqdm(enumerate(self.val_dataloader), total=num_batches)\n",
    "#         for idx, (x, y, seq_len, bucket) in loop:\n",
    "#             x = x.to(device)\n",
    "#             y = y.to(device)\n",
    "            \n",
    "#             y_hat = self.model(x, seq_len)\n",
    "\n",
    "#             y_hat_flat = y_hat.view(-1, y_hat.size(-1))\n",
    "#             y_flat = y.view(-1)\n",
    "            \n",
    "#             mask = y_flat.ne(99)\n",
    "#             y_hat_flat_masked = y_hat_flat[mask]\n",
    "#             y_flat_masked = y_flat[mask]\n",
    "\n",
    "#             loss = self.criterion(y_hat_flat_masked, y_flat_masked)\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             items_processed += y.size(0)\n",
    "\n",
    "#             y_pred = torch.argmax(y_hat_flat_masked, dim=1)\n",
    "#             fbeta_score_total += fbeta_score(y_flat_masked.cpu().numpy(), y_pred.cpu().numpy(), beta=5, average='micro')\n",
    "            \n",
    "#             loop.set_description(f'Epoch {current_epoch_nr + 1}')\n",
    "#             loop.set_postfix(val_loss=round(running_loss / items_processed, 6), fbeta_score=fbeta_score_total / (idx + 1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "320f4d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:45:41.850491Z",
     "iopub.status.busy": "2024-04-20T21:45:41.850195Z",
     "iopub.status.idle": "2024-04-20T21:46:42.001685Z",
     "shell.execute_reply": "2024-04-20T21:46:42.000490Z"
    },
    "papermill": {
     "duration": 60.180279,
     "end_time": "2024-04-20T21:46:42.004133",
     "exception": false,
     "start_time": "2024-04-20T21:45:41.823854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n"
     ]
    }
   ],
   "source": [
    "model = ChordMixer().to(device)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(lr=0.0003, params=model.parameters())\n",
    "\n",
    "trainer = Trainer(model, train_dataloader, criterion, optimizer)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "    trainer.train(epoch)\n",
    "#     trainer.validate(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "840d7483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:46:42.056723Z",
     "iopub.status.busy": "2024-04-20T21:46:42.055464Z",
     "iopub.status.idle": "2024-04-20T21:46:42.673864Z",
     "shell.execute_reply": "2024-04-20T21:46:42.672770Z"
    },
    "papermill": {
     "duration": 0.646895,
     "end_time": "2024-04-20T21:46:42.676339",
     "exception": false,
     "start_time": "2024-04-20T21:46:42.029444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "for x, seq_len, bucket, document in test_dataloader:\n",
    "    x = x.to(device)\n",
    "    \n",
    "    y_hat = model(x, seq_len)\n",
    "    y_pred = torch.argmax(y_hat, dim=2)\n",
    "    temp_preds = {\n",
    "        \"tokens\": x.cpu().numpy(),\n",
    "        \"document\": document,\n",
    "        \"labels\": y_pred.cpu().numpy()\n",
    "    }\n",
    "    predictions.append(temp_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe9652f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:46:42.727046Z",
     "iopub.status.busy": "2024-04-20T21:46:42.726341Z",
     "iopub.status.idle": "2024-04-20T21:46:43.959618Z",
     "shell.execute_reply": "2024-04-20T21:46:43.958838Z"
    },
    "papermill": {
     "duration": 1.260913,
     "end_time": "2024-04-20T21:46:43.961919",
     "exception": false,
     "start_time": "2024-04-20T21:46:42.701006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for pred in predictions:\n",
    "    documents = pred['document']\n",
    "    labels = pred['labels']\n",
    "    tokens = pred['tokens']\n",
    "    for i in range(batch_size):\n",
    "        document = documents[i]\n",
    "        for idx, label in enumerate(labels[i]):\n",
    "            if label != 0 and idx < len(tokens):\n",
    "                result.append({\n",
    "                    \"document\": document,\n",
    "                    \"token\": idx,\n",
    "                    \"word\": vocab.get_itos()[tokens[idx]],\n",
    "                    \"label\": id_2_label[label]\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26e0a1a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:46:44.012393Z",
     "iopub.status.busy": "2024-04-20T21:46:44.011722Z",
     "iopub.status.idle": "2024-04-20T21:46:44.023192Z",
     "shell.execute_reply": "2024-04-20T21:46:44.022443Z"
    },
    "papermill": {
     "duration": 0.038717,
     "end_time": "2024-04-20T21:46:44.025380",
     "exception": false,
     "start_time": "2024-04-20T21:46:43.986663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result)\n",
    "result_df = result_df.sort_values(by=['document']).reset_index(drop=True)\n",
    "result_df[\"row_id\"] = result_df.index\n",
    "result_df = result_df[[\"row_id\", \"document\", \"token\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81737ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:46:44.082521Z",
     "iopub.status.busy": "2024-04-20T21:46:44.082187Z",
     "iopub.status.idle": "2024-04-20T21:46:44.100360Z",
     "shell.execute_reply": "2024-04-20T21:46:44.099352Z"
    },
    "papermill": {
     "duration": 0.048261,
     "end_time": "2024-04-20T21:46:44.102438",
     "exception": false,
     "start_time": "2024-04-20T21:46:44.054177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3288</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3289</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3288</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3289</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3288</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>265</td>\n",
       "      <td>123</td>\n",
       "      <td>3289</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>123</td>\n",
       "      <td>3288</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>123</td>\n",
       "      <td>3289</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>123</td>\n",
       "      <td>3288</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>269</td>\n",
       "      <td>123</td>\n",
       "      <td>3289</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  document  token           label\n",
       "0         0         7   3288  B-NAME_STUDENT\n",
       "1         1         7   3289  I-NAME_STUDENT\n",
       "2         2         7   3288  B-NAME_STUDENT\n",
       "3         3         7   3289  I-NAME_STUDENT\n",
       "4         4         7   3288  B-NAME_STUDENT\n",
       "..      ...       ...    ...             ...\n",
       "265     265       123   3289  I-NAME_STUDENT\n",
       "266     266       123   3288  B-NAME_STUDENT\n",
       "267     267       123   3289  I-NAME_STUDENT\n",
       "268     268       123   3288  B-NAME_STUDENT\n",
       "269     269       123   3289  I-NAME_STUDENT\n",
       "\n",
       "[270 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e839fed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T21:46:44.159706Z",
     "iopub.status.busy": "2024-04-20T21:46:44.158997Z",
     "iopub.status.idle": "2024-04-20T21:46:44.167321Z",
     "shell.execute_reply": "2024-04-20T21:46:44.166415Z"
    },
    "papermill": {
     "duration": 0.038924,
     "end_time": "2024-04-20T21:46:44.169347",
     "exception": false,
     "start_time": "2024-04-20T21:46:44.130423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 116.454397,
   "end_time": "2024-04-20T21:46:47.576256",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-20T21:44:51.121859",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
