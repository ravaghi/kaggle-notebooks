{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa2d18c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-10T00:06:50.482106Z",
     "iopub.status.busy": "2024-08-10T00:06:50.481729Z",
     "iopub.status.idle": "2024-08-10T00:07:28.212857Z",
     "shell.execute_reply": "2024-08-10T00:07:28.211673Z"
    },
    "papermill": {
     "duration": 37.738931,
     "end_time": "2024-08-10T00:07:28.215541",
     "exception": false,
     "start_time": "2024-08-10T00:06:50.476610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.13.1 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\r\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q autogluon.tabular\n",
    "!pip install -q ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d618a26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T00:07:28.223939Z",
     "iopub.status.busy": "2024-08-10T00:07:28.223278Z",
     "iopub.status.idle": "2024-08-10T00:07:30.983656Z",
     "shell.execute_reply": "2024-08-10T00:07:30.982875Z"
    },
    "papermill": {
     "duration": 2.766948,
     "end_time": "2024-08-10T00:07:30.985996",
     "exception": false,
     "start_time": "2024-08-10T00:07:28.219048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f05ecac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T00:07:30.994293Z",
     "iopub.status.busy": "2024-08-10T00:07:30.993324Z",
     "iopub.status.idle": "2024-08-10T00:07:30.997522Z",
     "shell.execute_reply": "2024-08-10T00:07:30.996677Z"
    },
    "papermill": {
     "duration": 0.010158,
     "end_time": "2024-08-10T00:07:30.999492",
     "exception": false,
     "start_time": "2024-08-10T00:07:30.989334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'class'\n",
    "TIME_LIMIT = 3600 * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2525bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T00:07:31.007198Z",
     "iopub.status.busy": "2024-08-10T00:07:31.006550Z",
     "iopub.status.idle": "2024-08-10T00:07:45.478773Z",
     "shell.execute_reply": "2024-08-10T00:07:45.477934Z"
    },
    "papermill": {
     "duration": 14.478421,
     "end_time": "2024-08-10T00:07:45.481087",
     "exception": false,
     "start_time": "2024-08-10T00:07:31.002666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv', index_col='id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b15348",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-10T00:07:45.490095Z",
     "iopub.status.busy": "2024-08-10T00:07:45.489334Z",
     "iopub.status.idle": "2024-08-10T00:07:45.497593Z",
     "shell.execute_reply": "2024-08-10T00:07:45.496700Z"
    },
    "papermill": {
     "duration": 0.014916,
     "end_time": "2024-08-10T00:07:45.499473",
     "exception": false,
     "start_time": "2024-08-10T00:07:45.484557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240810_000745\"\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=TARGET,\n",
    "    eval_metric='mcc',\n",
    "    problem_type='binary',\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12778780",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-10T00:07:45.507048Z",
     "iopub.status.busy": "2024-08-10T00:07:45.506777Z",
     "iopub.status.idle": "2024-08-10T09:08:32.220932Z",
     "shell.execute_reply": "2024-08-10T09:08:32.219995Z"
    },
    "papermill": {
     "duration": 32446.754438,
     "end_time": "2024-08-10T09:08:32.257220",
     "exception": false,
     "start_time": "2024-08-10T00:07:45.502782",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.01 GB / 31.36 GB (92.5%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 8100s of the 32400s of remaining time (25%).\n",
      "2024-08-10 00:07:46,318\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\t\tContext path: \"AutogluonModels/ag-20240810_000745/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 8099s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240810_000745/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    2770617\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31198.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2319.00 MB (7.4% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 7.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t29.6s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 108.34 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 34.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5375.42s of the 8065.12s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.9.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036556\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360503\n",
      "[3000]\tvalid_set's binary_logloss: 0.0359005\n",
      "[4000]\tvalid_set's binary_logloss: 0.0358706\n",
      "[5000]\tvalid_set's binary_logloss: 0.0359059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036018\n",
      "[2000]\tvalid_set's binary_logloss: 0.0355372\n",
      "[3000]\tvalid_set's binary_logloss: 0.035406\n",
      "[4000]\tvalid_set's binary_logloss: 0.0353681\n",
      "[5000]\tvalid_set's binary_logloss: 0.0353896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363292\n",
      "[2000]\tvalid_set's binary_logloss: 0.035842\n",
      "[3000]\tvalid_set's binary_logloss: 0.0357037\n",
      "[4000]\tvalid_set's binary_logloss: 0.0356976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363993\n",
      "[2000]\tvalid_set's binary_logloss: 0.0359928\n",
      "[3000]\tvalid_set's binary_logloss: 0.035889\n",
      "[4000]\tvalid_set's binary_logloss: 0.0358864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0370883\n",
      "[2000]\tvalid_set's binary_logloss: 0.0365764\n",
      "[3000]\tvalid_set's binary_logloss: 0.0364369\n",
      "[4000]\tvalid_set's binary_logloss: 0.0364195\n",
      "[5000]\tvalid_set's binary_logloss: 0.0364403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036098\n",
      "[2000]\tvalid_set's binary_logloss: 0.03565\n",
      "[3000]\tvalid_set's binary_logloss: 0.0355546\n",
      "[4000]\tvalid_set's binary_logloss: 0.0355323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0373678\n",
      "[2000]\tvalid_set's binary_logloss: 0.0368908\n",
      "[3000]\tvalid_set's binary_logloss: 0.0367597\n",
      "[4000]\tvalid_set's binary_logloss: 0.0367457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0365551\n",
      "[2000]\tvalid_set's binary_logloss: 0.0361498\n",
      "[3000]\tvalid_set's binary_logloss: 0.0360436\n",
      "[4000]\tvalid_set's binary_logloss: 0.0360516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t3135.53s\t = Training   runtime\n",
      "\t313.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1919.4s of the 4609.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0369487\n",
      "[2000]\tvalid_set's binary_logloss: 0.0366632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2588. Best iteration is:\n",
      "\t[2364]\tvalid_set's binary_logloss: 0.0366258\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363739\n",
      "[2000]\tvalid_set's binary_logloss: 0.0361102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367056\n",
      "[2000]\tvalid_set's binary_logloss: 0.0365047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0369764\n",
      "[2000]\tvalid_set's binary_logloss: 0.0367327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0373691\n",
      "[2000]\tvalid_set's binary_logloss: 0.0370626\n",
      "[3000]\tvalid_set's binary_logloss: 0.0370459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3047. Best iteration is:\n",
      "\t[2538]\tvalid_set's binary_logloss: 0.0370353\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036698\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0377742\n",
      "[2000]\tvalid_set's binary_logloss: 0.0374654\n",
      "[3000]\tvalid_set's binary_logloss: 0.0375202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0369065\n",
      "[2000]\tvalid_set's binary_logloss: 0.0366346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9844\t = Validation score   (mcc)\n",
      "\t1585.04s\t = Training   runtime\n",
      "\t167.68s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 163.29s of the 2852.99s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 52 due to low time. Expected time usage reduced from 924.0s -> 163.3s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 156.35s compared to 43.56s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 537.54s of the 2683.6s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.68, 'LightGBM_BAG_L1': 0.32}\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t6.3s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2676.8s of the 2676.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0366699\n",
      "[2000]\tvalid_set's binary_logloss: 0.0365658\n",
      "[3000]\tvalid_set's binary_logloss: 0.0365476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 3230. Best iteration is:\n",
      "\t[2551]\tvalid_set's binary_logloss: 0.0365394\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0360153\n",
      "[2000]\tvalid_set's binary_logloss: 0.0359304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0360256\n",
      "[2000]\tvalid_set's binary_logloss: 0.0359719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0357603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363892\n",
      "[2000]\tvalid_set's binary_logloss: 0.0362698\n",
      "[3000]\tvalid_set's binary_logloss: 0.036272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0347993\n",
      "[2000]\tvalid_set's binary_logloss: 0.0347698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t1695.29s\t = Training   runtime\n",
      "\t159.84s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 817.93s of the 817.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t205.09s\t = Training   runtime\n",
      "\t8.43s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 601.86s of the 601.73s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 163 due to low time. Expected time usage reduced from 1100.8s -> 601.9s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 335.07s compared to 184.59s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 2.16s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.391, 'LightGBMXT_BAG_L1': 0.304, 'LightGBMXT_BAG_L2': 0.217, 'LightGBM_BAG_L1': 0.087}\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t12.51s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8110.29s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 533.4 rows/s (346328 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240810_000745/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMXT_BAG_L1       0.985107   0.984724         mcc      330.788483     313.257994  3135.529890               330.788483              313.257994        3135.529890            1       True          1\n",
      "1    LightGBMXT_BAG_L2       0.985089   0.984733         mcc      693.066504     640.781074  6415.861490               177.267567              159.843704        1695.294131            2       True          4\n",
      "2  WeightedEnsemble_L3       0.985060   0.984794         mcc      703.068033     649.577143  6633.463264                 0.010086                0.369093          12.512624            3       True          6\n",
      "3      LightGBM_BAG_L2       0.985025   0.984655         mcc      525.790380     489.364346  4925.656510                 9.991443                8.426975         205.089150            2       True          5\n",
      "4  WeightedEnsemble_L2       0.984973   0.984768         mcc      515.805358     481.302239  4726.870940                 0.006421                0.364868           6.303580            2       True          3\n",
      "5      LightGBM_BAG_L1       0.984606   0.984383         mcc      185.010454     167.679376  1585.037470               185.010454              167.679376        1585.037470            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t8827s\t = DyStack   runtime |\t23573s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 23573s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240810_000745\"\n",
      "Train Data Rows:    3116945\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29903.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2608.77 MB (8.7% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 8.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t33.1s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 121.88 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 36.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 15687.2s of the 23536.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0360838\n",
      "[2000]\tvalid_set's binary_logloss: 0.0355525\n",
      "[3000]\tvalid_set's binary_logloss: 0.0354172\n",
      "[4000]\tvalid_set's binary_logloss: 0.0353819\n",
      "[5000]\tvalid_set's binary_logloss: 0.0353866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367957\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363909\n",
      "[3000]\tvalid_set's binary_logloss: 0.0362863\n",
      "[4000]\tvalid_set's binary_logloss: 0.0362763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363934\n",
      "[2000]\tvalid_set's binary_logloss: 0.0358496\n",
      "[3000]\tvalid_set's binary_logloss: 0.0356836\n",
      "[4000]\tvalid_set's binary_logloss: 0.0356166\n",
      "[5000]\tvalid_set's binary_logloss: 0.0356077\n",
      "[6000]\tvalid_set's binary_logloss: 0.0356487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364757\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360428\n",
      "[3000]\tvalid_set's binary_logloss: 0.0359237\n",
      "[4000]\tvalid_set's binary_logloss: 0.0358791\n",
      "[5000]\tvalid_set's binary_logloss: 0.0358943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367197\n",
      "[2000]\tvalid_set's binary_logloss: 0.0362516\n",
      "[3000]\tvalid_set's binary_logloss: 0.036124\n",
      "[4000]\tvalid_set's binary_logloss: 0.0360909\n",
      "[5000]\tvalid_set's binary_logloss: 0.0361155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036793\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363421\n",
      "[3000]\tvalid_set's binary_logloss: 0.036223\n",
      "[4000]\tvalid_set's binary_logloss: 0.0362037\n",
      "[5000]\tvalid_set's binary_logloss: 0.0362082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0360944\n",
      "[2000]\tvalid_set's binary_logloss: 0.0356689\n",
      "[3000]\tvalid_set's binary_logloss: 0.0355907\n",
      "[4000]\tvalid_set's binary_logloss: 0.0355643\n",
      "[5000]\tvalid_set's binary_logloss: 0.0355816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363841\n",
      "[2000]\tvalid_set's binary_logloss: 0.0358792\n",
      "[3000]\tvalid_set's binary_logloss: 0.0357593\n",
      "[4000]\tvalid_set's binary_logloss: 0.0357382\n",
      "[5000]\tvalid_set's binary_logloss: 0.0357548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t3949.93s\t = Training   runtime\n",
      "\t392.85s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 11339.26s of the 19188.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364125\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360985\n",
      "[3000]\tvalid_set's binary_logloss: 0.0360757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0372269\n",
      "[2000]\tvalid_set's binary_logloss: 0.0369097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367363\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363792\n",
      "[3000]\tvalid_set's binary_logloss: 0.0363795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0369043\n",
      "[2000]\tvalid_set's binary_logloss: 0.0365939\n",
      "[3000]\tvalid_set's binary_logloss: 0.0366406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.037082\n",
      "[2000]\tvalid_set's binary_logloss: 0.0367851\n",
      "[3000]\tvalid_set's binary_logloss: 0.0367917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0372377\n",
      "[2000]\tvalid_set's binary_logloss: 0.0368388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0366232\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0366959\n",
      "[2000]\tvalid_set's binary_logloss: 0.036344\n",
      "[3000]\tvalid_set's binary_logloss: 0.0363464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9844\t = Validation score   (mcc)\n",
      "\t2091.44s\t = Training   runtime\n",
      "\t210.69s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 9033.13s of the 16882.59s of remaining time.\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t1116.55s\t = Training   runtime\n",
      "\t111.38s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 7802.77s of the 15652.23s of remaining time.\n",
      "\t0.9842\t = Validation score   (mcc)\n",
      "\t1165.03s\t = Training   runtime\n",
      "\t115.9s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 6519.43s of the 14368.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.9538\t = Validation score   (mcc)\n",
      "\t786.0s\t = Training   runtime\n",
      "\t6.96s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 5723.69s of the 13573.16s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t658.61s\t = Training   runtime\n",
      "\t115.93s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4946.61s of the 12796.07s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t675.62s\t = Training   runtime\n",
      "\t115.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4153.02s of the 12002.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9843\t = Validation score   (mcc)\n",
      "\t3740.19s\t = Training   runtime\n",
      "\t32.79s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 374.54s of the 8224.0s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9775\t = Validation score   (mcc)\n",
      "\t342.63s\t = Training   runtime\n",
      "\t21.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 8.15s of the 7857.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1568.72s of the 7828.78s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'RandomForestEntr_BAG_L1': 0.333, 'RandomForestGini_BAG_L1': 0.167}\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t27.87s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 7800.25s of the 7799.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0356037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0361095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0361843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0352928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0357052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0354481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t917.51s\t = Training   runtime\n",
      "\t114.86s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 6762.0s of the 6761.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] Check failed: (best_split_info.left_count) > (0) at /usr/local/src/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 846 .\n",
      "\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t273.26s\t = Training   runtime\n",
      "\t11.59s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 6471.73s of the 6471.36s of remaining time.\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t1852.18s\t = Training   runtime\n",
      "\t105.19s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 4510.62s of the 4510.26s of remaining time.\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t2273.22s\t = Training   runtime\n",
      "\t128.0s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 2105.72s of the 2105.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t291.81s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1806.79s of the 1806.42s of remaining time.\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t690.81s\t = Training   runtime\n",
      "\t100.85s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1011.48s of the 1011.11s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 577.4s compared to 504.06s of available time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 198.37s of the 198.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 185.2s of the 184.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L2.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 139.27s of the 138.9s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 101.91s of the 101.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] Check failed: (best_split_info.left_count) > (0) at /usr/local/src/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 846 .\n",
      "\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tRan out of time, early stopping on iteration 11. Best iteration is:\n",
      "\t[11]\tvalid_set's binary_logloss: 0.446704\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L2.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 85.96s of the 85.6s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tWarning: Exception caused CatBoost_r177_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t/src/catboost/catboost/private/libs/options/json_helper.h:41: Can't parse parameter \"iterations\" with value: -1\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 308, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 313, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 349, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, num_cpus=num_cpus, num_gpus=num_gpus, **kwargs_fold)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 232, in _fit\n",
      "    self.model.fit(X, **fit_final_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 5220, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2385, in _fit\n",
      "    train_params = self._prepare_train_params(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/catboost/core.py\", line 2311, in _prepare_train_params\n",
      "    _check_train_params(params)\n",
      "  File \"_catboost.pyx\", line 6393, in _catboost._check_train_params\n",
      "  File \"_catboost.pyx\", line 6415, in _catboost._check_train_params\n",
      "_catboost.CatBoostError: /src/catboost/catboost/private/libs/options/json_helper.h:41: Can't parse parameter \"iterations\" with value: -1\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 66.72s of the 66.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L2.\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 29.46s of the 29.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_logloss: 0.676961\n",
      "\tTime limit exceeded... Skipping LightGBM_r131_BAG_L2.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 19.19s of the 18.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_r191_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 780.03s of the 1.15s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.304, 'RandomForestEntr_BAG_L1': 0.174, 'RandomForestGini_BAG_L2': 0.13, 'ExtraTreesGini_BAG_L2': 0.13, 'ExtraTreesGini_BAG_L1': 0.087, 'RandomForestEntr_BAG_L2': 0.087, 'RandomForestGini_BAG_L1': 0.043, 'ExtraTreesEntr_BAG_L1': 0.043}\n",
      "\t0.985\t = Validation score   (mcc)\n",
      "\t46.84s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23619.85s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 510.1 rows/s (389619 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240810_000745\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7e48e0612ec0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data=train,\n",
    "    time_limit=TIME_LIMIT,\n",
    "    presets='best_quality',\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={\n",
    "        'num_gpus': 1, \n",
    "        'stopping_metric': 'log_loss'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8705122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T09:08:32.346576Z",
     "iopub.status.busy": "2024-08-10T09:08:32.346167Z",
     "iopub.status.idle": "2024-08-10T09:08:32.373940Z",
     "shell.execute_reply": "2024-08-10T09:08:32.373015Z"
    },
    "papermill": {
     "duration": 0.074696,
     "end_time": "2024-08-10T09:08:32.375898",
     "exception": false,
     "start_time": "2024-08-10T09:08:32.301202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.984967</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1457.858990</td>\n",
       "      <td>19389.048696</td>\n",
       "      <td>0.422010</td>\n",
       "      <td>46.839151</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.984943</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1251.404838</td>\n",
       "      <td>16799.219616</td>\n",
       "      <td>127.995049</td>\n",
       "      <td>2273.216541</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.984930</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1228.595217</td>\n",
       "      <td>16378.181249</td>\n",
       "      <td>105.185427</td>\n",
       "      <td>1852.178174</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1224.256504</td>\n",
       "      <td>15216.814830</td>\n",
       "      <td>100.846714</td>\n",
       "      <td>690.811755</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.984876</td>\n",
       "      <td>mcc</td>\n",
       "      <td>620.560148</td>\n",
       "      <td>6259.379137</td>\n",
       "      <td>0.431666</td>\n",
       "      <td>27.874635</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.984823</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1134.997052</td>\n",
       "      <td>14799.266748</td>\n",
       "      <td>11.587262</td>\n",
       "      <td>273.263673</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.984814</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1238.274307</td>\n",
       "      <td>15443.510182</td>\n",
       "      <td>114.864517</td>\n",
       "      <td>917.507107</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.984806</td>\n",
       "      <td>mcc</td>\n",
       "      <td>392.851485</td>\n",
       "      <td>3949.928865</td>\n",
       "      <td>392.851485</td>\n",
       "      <td>3949.928865</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.984753</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1124.834754</td>\n",
       "      <td>14817.817162</td>\n",
       "      <td>1.424964</td>\n",
       "      <td>291.814087</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.984437</td>\n",
       "      <td>mcc</td>\n",
       "      <td>210.686094</td>\n",
       "      <td>2091.443896</td>\n",
       "      <td>210.686094</td>\n",
       "      <td>2091.443896</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.984330</td>\n",
       "      <td>mcc</td>\n",
       "      <td>32.794307</td>\n",
       "      <td>3740.190838</td>\n",
       "      <td>32.794307</td>\n",
       "      <td>3740.190838</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.984167</td>\n",
       "      <td>mcc</td>\n",
       "      <td>115.901911</td>\n",
       "      <td>1165.027421</td>\n",
       "      <td>115.901911</td>\n",
       "      <td>1165.027421</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.984124</td>\n",
       "      <td>mcc</td>\n",
       "      <td>111.375086</td>\n",
       "      <td>1116.548216</td>\n",
       "      <td>111.375086</td>\n",
       "      <td>1116.548216</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.983462</td>\n",
       "      <td>mcc</td>\n",
       "      <td>115.560091</td>\n",
       "      <td>675.618053</td>\n",
       "      <td>115.560091</td>\n",
       "      <td>675.618053</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>mcc</td>\n",
       "      <td>115.928277</td>\n",
       "      <td>658.614139</td>\n",
       "      <td>115.928277</td>\n",
       "      <td>658.614139</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.977475</td>\n",
       "      <td>mcc</td>\n",
       "      <td>21.356280</td>\n",
       "      <td>342.633986</td>\n",
       "      <td>21.356280</td>\n",
       "      <td>342.633986</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.953821</td>\n",
       "      <td>mcc</td>\n",
       "      <td>6.956258</td>\n",
       "      <td>785.997661</td>\n",
       "      <td>6.956258</td>\n",
       "      <td>785.997661</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.984967         mcc    1457.858990   \n",
       "1   RandomForestEntr_BAG_L2   0.984943         mcc    1251.404838   \n",
       "2   RandomForestGini_BAG_L2   0.984930         mcc    1228.595217   \n",
       "3     ExtraTreesGini_BAG_L2   0.984917         mcc    1224.256504   \n",
       "4       WeightedEnsemble_L2   0.984876         mcc     620.560148   \n",
       "5           LightGBM_BAG_L2   0.984823         mcc    1134.997052   \n",
       "6         LightGBMXT_BAG_L2   0.984814         mcc    1238.274307   \n",
       "7         LightGBMXT_BAG_L1   0.984806         mcc     392.851485   \n",
       "8           CatBoost_BAG_L2   0.984753         mcc    1124.834754   \n",
       "9           LightGBM_BAG_L1   0.984437         mcc     210.686094   \n",
       "10   NeuralNetFastAI_BAG_L1   0.984330         mcc      32.794307   \n",
       "11  RandomForestEntr_BAG_L1   0.984167         mcc     115.901911   \n",
       "12  RandomForestGini_BAG_L1   0.984124         mcc     111.375086   \n",
       "13    ExtraTreesEntr_BAG_L1   0.983462         mcc     115.560091   \n",
       "14    ExtraTreesGini_BAG_L1   0.983457         mcc     115.928277   \n",
       "15           XGBoost_BAG_L1   0.977475         mcc      21.356280   \n",
       "16          CatBoost_BAG_L1   0.953821         mcc       6.956258   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   19389.048696                0.422010          46.839151            3   \n",
       "1   16799.219616              127.995049        2273.216541            2   \n",
       "2   16378.181249              105.185427        1852.178174            2   \n",
       "3   15216.814830              100.846714         690.811755            2   \n",
       "4    6259.379137                0.431666          27.874635            2   \n",
       "5   14799.266748               11.587262         273.263673            2   \n",
       "6   15443.510182              114.864517         917.507107            2   \n",
       "7    3949.928865              392.851485        3949.928865            1   \n",
       "8   14817.817162                1.424964         291.814087            2   \n",
       "9    2091.443896              210.686094        2091.443896            1   \n",
       "10   3740.190838               32.794307        3740.190838            1   \n",
       "11   1165.027421              115.901911        1165.027421            1   \n",
       "12   1116.548216              111.375086        1116.548216            1   \n",
       "13    675.618053              115.560091         675.618053            1   \n",
       "14    658.614139              115.928277         658.614139            1   \n",
       "15    342.633986               21.356280         342.633986            1   \n",
       "16    785.997661                6.956258         785.997661            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         17  \n",
       "1        True         14  \n",
       "2        True         13  \n",
       "3        True         16  \n",
       "4        True         10  \n",
       "5        True         12  \n",
       "6        True         11  \n",
       "7        True          1  \n",
       "8        True         15  \n",
       "9        True          2  \n",
       "10       True          8  \n",
       "11       True          4  \n",
       "12       True          3  \n",
       "13       True          7  \n",
       "14       True          6  \n",
       "15       True          9  \n",
       "16       True          5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ed967a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T09:08:32.466877Z",
     "iopub.status.busy": "2024-08-10T09:08:32.466368Z",
     "iopub.status.idle": "2024-08-10T10:51:21.631575Z",
     "shell.execute_reply": "2024-08-10T10:51:21.630659Z"
    },
    "papermill": {
     "duration": 6169.21391,
     "end_time": "2024-08-10T10:51:21.634485",
     "exception": false,
     "start_time": "2024-08-10T09:08:32.420575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preds = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3827b57a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:51:21.725627Z",
     "iopub.status.busy": "2024-08-10T10:51:21.725237Z",
     "iopub.status.idle": "2024-08-10T10:51:24.686636Z",
     "shell.execute_reply": "2024-08-10T10:51:24.685344Z"
    },
    "papermill": {
     "duration": 3.009192,
     "end_time": "2024-08-10T10:51:24.689003",
     "exception": false,
     "start_time": "2024-08-10T10:51:21.679811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3116947</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3116948</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3116949</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id class\n",
       "0  3116945     e\n",
       "1  3116946     p\n",
       "2  3116947     p\n",
       "3  3116948     p\n",
       "4  3116949     e"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv')\n",
    "sub[TARGET] = test_preds.values\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c92848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T10:51:24.782104Z",
     "iopub.status.busy": "2024-08-10T10:51:24.781216Z",
     "iopub.status.idle": "2024-08-10T10:51:25.674825Z",
     "shell.execute_reply": "2024-08-10T10:51:25.673971Z"
    },
    "papermill": {
     "duration": 0.942088,
     "end_time": "2024-08-10T10:51:25.677297",
     "exception": false,
     "start_time": "2024-08-10T10:51:24.735209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"AutogluonModels\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38681.38022,
   "end_time": "2024-08-10T10:51:29.124995",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-10T00:06:47.744775",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
