{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15e2ada",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-07T08:23:31.853679Z",
     "iopub.status.busy": "2024-08-07T08:23:31.853315Z",
     "iopub.status.idle": "2024-08-07T08:24:09.894998Z",
     "shell.execute_reply": "2024-08-07T08:24:09.893643Z"
    },
    "papermill": {
     "duration": 38.0495,
     "end_time": "2024-08-07T08:24:09.898096",
     "exception": false,
     "start_time": "2024-08-07T08:23:31.848596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.13.1 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\r\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q autogluon.tabular\n",
    "!pip install -q ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da754b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T08:24:09.908433Z",
     "iopub.status.busy": "2024-08-07T08:24:09.908118Z",
     "iopub.status.idle": "2024-08-07T08:24:12.790087Z",
     "shell.execute_reply": "2024-08-07T08:24:12.789230Z"
    },
    "papermill": {
     "duration": 2.889475,
     "end_time": "2024-08-07T08:24:12.792329",
     "exception": false,
     "start_time": "2024-08-07T08:24:09.902854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd0f366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T08:24:12.800183Z",
     "iopub.status.busy": "2024-08-07T08:24:12.799710Z",
     "iopub.status.idle": "2024-08-07T08:24:12.803762Z",
     "shell.execute_reply": "2024-08-07T08:24:12.802938Z"
    },
    "papermill": {
     "duration": 0.009948,
     "end_time": "2024-08-07T08:24:12.805633",
     "exception": false,
     "start_time": "2024-08-07T08:24:12.795685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 6\n",
    "TARGET = 'class'\n",
    "TIME_LIMIT = 3600 * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f807c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T08:24:12.812936Z",
     "iopub.status.busy": "2024-08-07T08:24:12.812678Z",
     "iopub.status.idle": "2024-08-07T08:24:28.277418Z",
     "shell.execute_reply": "2024-08-07T08:24:28.276649Z"
    },
    "papermill": {
     "duration": 15.471165,
     "end_time": "2024-08-07T08:24:28.280003",
     "exception": false,
     "start_time": "2024-08-07T08:24:12.808838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv', index_col='id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv', index_col='id')\n",
    "\n",
    "train[TARGET] = train[TARGET].map({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ecb0cfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T08:24:28.288274Z",
     "iopub.status.busy": "2024-08-07T08:24:28.287990Z",
     "iopub.status.idle": "2024-08-07T08:24:28.292200Z",
     "shell.execute_reply": "2024-08-07T08:24:28.291375Z"
    },
    "papermill": {
     "duration": 0.010186,
     "end_time": "2024-08-07T08:24:28.294012",
     "exception": false,
     "start_time": "2024-08-07T08:24:28.283826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = TabularDataset(train)\n",
    "test = TabularDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f8a532",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-07T08:24:28.301528Z",
     "iopub.status.busy": "2024-08-07T08:24:28.301241Z",
     "iopub.status.idle": "2024-08-07T08:24:28.307269Z",
     "shell.execute_reply": "2024-08-07T08:24:28.306289Z"
    },
    "papermill": {
     "duration": 0.012214,
     "end_time": "2024-08-07T08:24:28.309426",
     "exception": false,
     "start_time": "2024-08-07T08:24:28.297212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240807_082428\"\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=TARGET,\n",
    "    eval_metric='mcc',\n",
    "    problem_type='binary',\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227e4139",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-07T08:24:28.317853Z",
     "iopub.status.busy": "2024-08-07T08:24:28.317549Z",
     "iopub.status.idle": "2024-08-07T17:25:11.921684Z",
     "shell.execute_reply": "2024-08-07T17:25:11.920512Z"
    },
    "papermill": {
     "duration": 32443.611124,
     "end_time": "2024-08-07T17:25:11.924296",
     "exception": false,
     "start_time": "2024-08-07T08:24:28.313172",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       28.99 GB / 31.36 GB (92.4%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 8100s of the 32400s of remaining time (25%).\n",
      "2024-08-07 08:24:29,139\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\t\tContext path: \"AutogluonModels/ag-20240807_082428/ds_sub_fit/sub_fit_ho\"\n",
      "Running DyStack sub-fit ...\n",
      "Beginning AutoGluon training ... Time limit = 8099s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240807_082428/ds_sub_fit/sub_fit_ho\"\n",
      "Train Data Rows:    2770617\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31155.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2319.00 MB (7.4% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 7.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t29.8s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 108.34 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 31.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5377.26s of the 8067.89s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.9.0 detected. 2.10.0 <= ray < 2.11.0 is required. You can use pip to install certain version of ray `pip install ray==2.10.0` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0365408\tvalid_set's mcc: 0.984256\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360287\tvalid_set's mcc: 0.984495\n",
      "[3000]\tvalid_set's binary_logloss: 0.0359007\tvalid_set's mcc: 0.984617\n",
      "[4000]\tvalid_set's binary_logloss: 0.03589\tvalid_set's mcc: 0.984593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4263. Best iteration is:\n",
      "\t[3422]\tvalid_set's binary_logloss: 0.0358817\tvalid_set's mcc: 0.984652\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036018\tvalid_set's mcc: 0.984525\n",
      "[2000]\tvalid_set's binary_logloss: 0.0355372\tvalid_set's mcc: 0.984775\n",
      "[3000]\tvalid_set's binary_logloss: 0.035406\tvalid_set's mcc: 0.98488\n",
      "[4000]\tvalid_set's binary_logloss: 0.0353681\tvalid_set's mcc: 0.984944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4480. Best iteration is:\n",
      "\t[4097]\tvalid_set's binary_logloss: 0.0353654\tvalid_set's mcc: 0.984974\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0362646\tvalid_set's mcc: 0.984489\n",
      "[2000]\tvalid_set's binary_logloss: 0.035784\tvalid_set's mcc: 0.98485\n",
      "[3000]\tvalid_set's binary_logloss: 0.0356654\tvalid_set's mcc: 0.98499\n",
      "[4000]\tvalid_set's binary_logloss: 0.0356479\tvalid_set's mcc: 0.98506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 4577. Best iteration is:\n",
      "\t[4024]\tvalid_set's binary_logloss: 0.0356497\tvalid_set's mcc: 0.985077\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363993\tvalid_set's mcc: 0.98432\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360055\tvalid_set's mcc: 0.984559\n",
      "[3000]\tvalid_set's binary_logloss: 0.0359099\tvalid_set's mcc: 0.984611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0370816\tvalid_set's mcc: 0.983918\n",
      "[2000]\tvalid_set's binary_logloss: 0.0365701\tvalid_set's mcc: 0.984198\n",
      "[3000]\tvalid_set's binary_logloss: 0.0364066\tvalid_set's mcc: 0.984296\n",
      "[4000]\tvalid_set's binary_logloss: 0.0363732\tvalid_set's mcc: 0.984302\n",
      "[5000]\tvalid_set's binary_logloss: 0.0364001\tvalid_set's mcc: 0.984366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5280. Best iteration is:\n",
      "\t[5008]\tvalid_set's binary_logloss: 0.036401\tvalid_set's mcc: 0.984372\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0361041\tvalid_set's mcc: 0.984566\n",
      "[2000]\tvalid_set's binary_logloss: 0.0356614\tvalid_set's mcc: 0.984852\n",
      "[3000]\tvalid_set's binary_logloss: 0.0355732\tvalid_set's mcc: 0.984933\n",
      "[4000]\tvalid_set's binary_logloss: 0.0355707\tvalid_set's mcc: 0.984928\n",
      "[5000]\tvalid_set's binary_logloss: 0.0356113\tvalid_set's mcc: 0.984928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 5366. Best iteration is:\n",
      "\t[4911]\tvalid_set's binary_logloss: 0.0356069\tvalid_set's mcc: 0.984963\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0373678\tvalid_set's mcc: 0.984197\n",
      "[2000]\tvalid_set's binary_logloss: 0.0368701\tvalid_set's mcc: 0.98446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0365551\tvalid_set's mcc: 0.984501\n",
      "[2000]\tvalid_set's binary_logloss: 0.036134\tvalid_set's mcc: 0.984705\n",
      "[3000]\tvalid_set's binary_logloss: 0.0360522\tvalid_set's mcc: 0.984804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t4122.03s\t = Training   runtime\n",
      "\t302.54s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 945.62s of the 3636.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 638. Best iteration is:\n",
      "\t[633]\tvalid_set's binary_logloss: 0.0374802\tvalid_set's mcc: 0.983603\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 667. Best iteration is:\n",
      "\t[663]\tvalid_set's binary_logloss: 0.0369504\tvalid_set's mcc: 0.983703\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 677. Best iteration is:\n",
      "\t[677]\tvalid_set's binary_logloss: 0.0370245\tvalid_set's mcc: 0.984156\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 697. Best iteration is:\n",
      "\t[672]\tvalid_set's binary_logloss: 0.0373608\tvalid_set's mcc: 0.983807\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 742. Best iteration is:\n",
      "\t[740]\tvalid_set's binary_logloss: 0.0376997\tvalid_set's mcc: 0.983551\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 752. Best iteration is:\n",
      "\t[745]\tvalid_set's binary_logloss: 0.0370178\tvalid_set's mcc: 0.984118\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 820. Best iteration is:\n",
      "\t[820]\tvalid_set's binary_logloss: 0.0379561\tvalid_set's mcc: 0.983616\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tRan out of time, early stopping on iteration 976. Best iteration is:\n",
      "\t[975]\tvalid_set's binary_logloss: 0.0369125\tvalid_set's mcc: 0.984286\n",
      "\t0.9839\t = Validation score   (mcc)\n",
      "\t852.08s\t = Training   runtime\n",
      "\t72.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 18.84s of the 2709.47s of remaining time.\n",
      "\tWarning: Model is expected to require 909.9s to train, which exceeds the maximum time limit of 18.8s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5.68s of the 2696.31s of remaining time.\n",
      "\tWarning: Model is expected to require 970.7s to train, which exceeds the maximum time limit of 5.7s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 537.73s of the 2682.3s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t6.28s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2675.53s of the 2675.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364322\tvalid_set's mcc: 0.984572\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363314\tvalid_set's mcc: 0.984665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tRan out of time, early stopping on iteration 2435. Best iteration is:\n",
      "\t[2435]\tvalid_set's binary_logloss: 0.036327\tvalid_set's mcc: 0.984688\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0360011\tvalid_set's mcc: 0.984651\n",
      "[2000]\tvalid_set's binary_logloss: 0.0358858\tvalid_set's mcc: 0.984709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0361202\tvalid_set's mcc: 0.984758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0357346\tvalid_set's mcc: 0.984966\n",
      "[2000]\tvalid_set's binary_logloss: 0.0356296\tvalid_set's mcc: 0.985018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364999\tvalid_set's mcc: 0.984564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0349202\tvalid_set's mcc: 0.984984\n",
      "[2000]\tvalid_set's binary_logloss: 0.0347802\tvalid_set's mcc: 0.985182\n",
      "[3000]\tvalid_set's binary_logloss: 0.0347653\tvalid_set's mcc: 0.985189\n",
      "[4000]\tvalid_set's binary_logloss: 0.0347835\tvalid_set's mcc: 0.985217\n",
      "[5000]\tvalid_set's binary_logloss: 0.0348288\tvalid_set's mcc: 0.985229\n",
      "[6000]\tvalid_set's binary_logloss: 0.0348789\tvalid_set's mcc: 0.985217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9843\t = Validation score   (mcc)\n",
      "\t2128.07s\t = Training   runtime\n",
      "\t139.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 404.61s of the 404.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "[LightGBM] [Fatal] Check failed: (best_split_info.left_count) > (0) at /usr/local/src/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 846 .\n",
      "\n",
      "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t96.76s\t = Training   runtime\n",
      "\t1.72s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 303.71s of the 303.59s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 85 due to low time. Expected time usage reduced from 1068.0s -> 303.7s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 220.83s compared to 75.0s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -17.91s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.667, 'LightGBMXT_BAG_L2': 0.267, 'LightGBM_BAG_L2': 0.067}\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t12.12s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8129.9s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 671.5 rows/s (346328 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240807_082428/ds_sub_fit/sub_fit_ho\")\n",
      "Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMXT_BAG_L2       0.985141   0.984301         mcc      551.694902     513.992248  7102.179033               153.363045              139.376101        2128.069110            2       True          4\n",
      "1    LightGBMXT_BAG_L1       0.985084   0.984754         mcc      317.031080     302.536122  4122.027963               317.031080              302.536122        4122.027963            1       True          1\n",
      "2  WeightedEnsemble_L2       0.985084   0.984754         mcc      317.035769     302.898747  4128.306308                 0.004689                0.362624           6.278345            2       True          3\n",
      "3  WeightedEnsemble_L3       0.985078   0.984755         mcc      553.404255     516.076838  7211.058923                 0.007958                0.360917          12.115753            3       True          6\n",
      "4      LightGBM_BAG_L2       0.985065   0.984668         mcc      400.033252     376.339821  5070.874060                 1.701395                1.723673          96.764137            2       True          5\n",
      "5      LightGBM_BAG_L1       0.984059   0.983855         mcc       81.300777      72.080025   852.081960                81.300777               72.080025         852.081960            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t8692s\t = DyStack   runtime |\t23708s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 23708s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240807_082428\"\n",
      "Train Data Rows:    3116945\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30210.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2608.77 MB (8.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 8.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t31.9s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 121.88 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 33.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 23674.36s of the 23674.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036076\tvalid_set's mcc: 0.984505\n",
      "[2000]\tvalid_set's binary_logloss: 0.0355626\tvalid_set's mcc: 0.984955\n",
      "[3000]\tvalid_set's binary_logloss: 0.03542\tvalid_set's mcc: 0.984956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367957\tvalid_set's mcc: 0.98451\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363909\tvalid_set's mcc: 0.984733\n",
      "[3000]\tvalid_set's binary_logloss: 0.0362769\tvalid_set's mcc: 0.984815\n",
      "[4000]\tvalid_set's binary_logloss: 0.0362539\tvalid_set's mcc: 0.984888\n",
      "[5000]\tvalid_set's binary_logloss: 0.0362831\tvalid_set's mcc: 0.984856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363934\tvalid_set's mcc: 0.984152\n",
      "[2000]\tvalid_set's binary_logloss: 0.0358532\tvalid_set's mcc: 0.984446\n",
      "[3000]\tvalid_set's binary_logloss: 0.0357271\tvalid_set's mcc: 0.984602\n",
      "[4000]\tvalid_set's binary_logloss: 0.035666\tvalid_set's mcc: 0.984664\n",
      "[5000]\tvalid_set's binary_logloss: 0.0356648\tvalid_set's mcc: 0.984773\n",
      "[6000]\tvalid_set's binary_logloss: 0.0356982\tvalid_set's mcc: 0.984762\n",
      "[7000]\tvalid_set's binary_logloss: 0.0357307\tvalid_set's mcc: 0.984736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364757\tvalid_set's mcc: 0.98457\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360407\tvalid_set's mcc: 0.984793\n",
      "[3000]\tvalid_set's binary_logloss: 0.0359056\tvalid_set's mcc: 0.98485\n",
      "[4000]\tvalid_set's binary_logloss: 0.0358777\tvalid_set's mcc: 0.984809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367415\tvalid_set's mcc: 0.984174\n",
      "[2000]\tvalid_set's binary_logloss: 0.036245\tvalid_set's mcc: 0.984495\n",
      "[3000]\tvalid_set's binary_logloss: 0.0361281\tvalid_set's mcc: 0.984521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.036804\tvalid_set's mcc: 0.984323\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363419\tvalid_set's mcc: 0.984577\n",
      "[3000]\tvalid_set's binary_logloss: 0.0362056\tvalid_set's mcc: 0.984702\n",
      "[4000]\tvalid_set's binary_logloss: 0.0361631\tvalid_set's mcc: 0.984743\n",
      "[5000]\tvalid_set's binary_logloss: 0.0361709\tvalid_set's mcc: 0.984795\n",
      "[6000]\tvalid_set's binary_logloss: 0.0362004\tvalid_set's mcc: 0.9848\n",
      "[7000]\tvalid_set's binary_logloss: 0.036273\tvalid_set's mcc: 0.9848\n",
      "[8000]\tvalid_set's binary_logloss: 0.0363349\tvalid_set's mcc: 0.984779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0361244\tvalid_set's mcc: 0.984504\n",
      "[2000]\tvalid_set's binary_logloss: 0.0356842\tvalid_set's mcc: 0.984711\n",
      "[3000]\tvalid_set's binary_logloss: 0.0356037\tvalid_set's mcc: 0.984778\n",
      "[4000]\tvalid_set's binary_logloss: 0.0355857\tvalid_set's mcc: 0.984809\n",
      "[5000]\tvalid_set's binary_logloss: 0.0356213\tvalid_set's mcc: 0.98485\n",
      "[6000]\tvalid_set's binary_logloss: 0.0356753\tvalid_set's mcc: 0.984861\n",
      "[7000]\tvalid_set's binary_logloss: 0.0357381\tvalid_set's mcc: 0.984886\n",
      "[8000]\tvalid_set's binary_logloss: 0.0358052\tvalid_set's mcc: 0.984923\n",
      "[9000]\tvalid_set's binary_logloss: 0.0358875\tvalid_set's mcc: 0.984871\n",
      "[10000]\tvalid_set's binary_logloss: 0.0359803\tvalid_set's mcc: 0.984902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0363944\tvalid_set's mcc: 0.984421\n",
      "[2000]\tvalid_set's binary_logloss: 0.0358824\tvalid_set's mcc: 0.984711\n",
      "[3000]\tvalid_set's binary_logloss: 0.035754\tvalid_set's mcc: 0.984773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t6076.81s\t = Training   runtime\n",
      "\t404.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 17188.04s of the 17188.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0364254\tvalid_set's mcc: 0.984257\n",
      "[2000]\tvalid_set's binary_logloss: 0.0360827\tvalid_set's mcc: 0.984697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0372271\tvalid_set's mcc: 0.984225\n",
      "[2000]\tvalid_set's binary_logloss: 0.036905\tvalid_set's mcc: 0.984473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367363\tvalid_set's mcc: 0.983774\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363791\tvalid_set's mcc: 0.984173\n",
      "[3000]\tvalid_set's binary_logloss: 0.0363838\tvalid_set's mcc: 0.984323\n",
      "[4000]\tvalid_set's binary_logloss: 0.0364622\tvalid_set's mcc: 0.984348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0369026\tvalid_set's mcc: 0.984342\n",
      "[2000]\tvalid_set's binary_logloss: 0.0365925\tvalid_set's mcc: 0.984528\n",
      "[3000]\tvalid_set's binary_logloss: 0.0366544\tvalid_set's mcc: 0.984554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.037082\tvalid_set's mcc: 0.98395\n",
      "[2000]\tvalid_set's binary_logloss: 0.0368215\tvalid_set's mcc: 0.984209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0372377\tvalid_set's mcc: 0.983971\n",
      "[2000]\tvalid_set's binary_logloss: 0.0368387\tvalid_set's mcc: 0.984364\n",
      "[3000]\tvalid_set's binary_logloss: 0.0368422\tvalid_set's mcc: 0.984427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0366232\tvalid_set's mcc: 0.983996\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363205\tvalid_set's mcc: 0.984297\n",
      "[3000]\tvalid_set's binary_logloss: 0.0363716\tvalid_set's mcc: 0.984338\n",
      "[4000]\tvalid_set's binary_logloss: 0.0364662\tvalid_set's mcc: 0.984353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's binary_logloss: 0.0367025\tvalid_set's mcc: 0.984162\n",
      "[2000]\tvalid_set's binary_logloss: 0.0363889\tvalid_set's mcc: 0.984348\n",
      "[3000]\tvalid_set's binary_logloss: 0.0363567\tvalid_set's mcc: 0.984499\n",
      "[4000]\tvalid_set's binary_logloss: 0.0364453\tvalid_set's mcc: 0.984514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9845\t = Validation score   (mcc)\n",
      "\t3563.1s\t = Training   runtime\n",
      "\t231.13s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 13389.84s of the 13389.82s of remaining time.\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t1073.91s\t = Training   runtime\n",
      "\t104.99s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 12208.69s of the 12208.67s of remaining time.\n",
      "\t0.9842\t = Validation score   (mcc)\n",
      "\t1127.8s\t = Training   runtime\n",
      "\t116.63s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 10961.95s of the 10961.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.9682\t = Validation score   (mcc)\n",
      "\t1373.33s\t = Training   runtime\n",
      "\t11.95s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 9573.85s of the 9573.84s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t620.02s\t = Training   runtime\n",
      "\t106.66s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 8844.71s of the 8844.7s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t658.71s\t = Training   runtime\n",
      "\t114.78s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8068.82s of the 8068.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "\t0.9845\t = Validation score   (mcc)\n",
      "\t7408.71s\t = Training   runtime\n",
      "\t32.4s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 619.1s of the 619.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.9838\t = Validation score   (mcc)\n",
      "\t574.84s\t = Training   runtime\n",
      "\t23.65s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 18.08s of the 18.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 2367.44s of the -12.47s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.556, 'RandomForestEntr_BAG_L1': 0.222, 'LightGBM_BAG_L1': 0.111, 'RandomForestGini_BAG_L1': 0.111}\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t30.07s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23751.37s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 587.4 rows/s (389619 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240807_082428\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7fec513f1cf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data=train,\n",
    "    time_limit=TIME_LIMIT,\n",
    "    presets='best_quality',\n",
    "    save_space=True,\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={\n",
    "        'num_gpus': 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13fdba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T17:25:12.006930Z",
     "iopub.status.busy": "2024-08-07T17:25:12.005562Z",
     "iopub.status.idle": "2024-08-07T18:58:57.484850Z",
     "shell.execute_reply": "2024-08-07T18:58:57.483648Z"
    },
    "papermill": {
     "duration": 5625.524338,
     "end_time": "2024-08-07T18:58:57.487881",
     "exception": false,
     "start_time": "2024-08-07T17:25:11.963543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred_probs = predictor.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98637b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:58:57.566838Z",
     "iopub.status.busy": "2024-08-07T18:58:57.566494Z",
     "iopub.status.idle": "2024-08-07T18:59:00.603310Z",
     "shell.execute_reply": "2024-08-07T18:59:00.602370Z"
    },
    "papermill": {
     "duration": 3.076147,
     "end_time": "2024-08-07T18:59:00.605475",
     "exception": false,
     "start_time": "2024-08-07T18:58:57.529328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3116947</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3116948</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3116949</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id class\n",
       "0  3116945     e\n",
       "1  3116946     p\n",
       "2  3116947     p\n",
       "3  3116948     p\n",
       "4  3116949     e"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv')\n",
    "sub[TARGET] = np.argmax(test_pred_probs, axis=1)\n",
    "sub[TARGET] = sub[TARGET].map({0: 'e', 1: 'p'})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "023d9711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:59:00.676977Z",
     "iopub.status.busy": "2024-08-07T18:59:00.676638Z",
     "iopub.status.idle": "2024-08-07T18:59:01.142598Z",
     "shell.execute_reply": "2024-08-07T18:59:01.141589Z"
    },
    "papermill": {
     "duration": 0.503918,
     "end_time": "2024-08-07T18:59:01.144987",
     "exception": false,
     "start_time": "2024-08-07T18:59:00.641069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"AutogluonModels\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38135.304916,
   "end_time": "2024-08-07T18:59:04.374312",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-07T08:23:29.069396",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
