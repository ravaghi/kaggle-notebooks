{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05f9307",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-06T22:19:54.228279Z",
     "iopub.status.busy": "2024-08-06T22:19:54.227888Z",
     "iopub.status.idle": "2024-08-06T22:20:42.189172Z",
     "shell.execute_reply": "2024-08-06T22:20:42.187961Z"
    },
    "papermill": {
     "duration": 47.96874,
     "end_time": "2024-08-06T22:20:42.191699",
     "exception": false,
     "start_time": "2024-08-06T22:19:54.222959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.13.1 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\r\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\r\n",
      "spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q autogluon.tabular\n",
    "!pip install -q ray==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1e9ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T22:20:42.199744Z",
     "iopub.status.busy": "2024-08-06T22:20:42.199438Z",
     "iopub.status.idle": "2024-08-06T22:20:45.067421Z",
     "shell.execute_reply": "2024-08-06T22:20:45.066549Z"
    },
    "papermill": {
     "duration": 2.87454,
     "end_time": "2024-08-06T22:20:45.069739",
     "exception": false,
     "start_time": "2024-08-06T22:20:42.195199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b98a44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T22:20:45.077999Z",
     "iopub.status.busy": "2024-08-06T22:20:45.077225Z",
     "iopub.status.idle": "2024-08-06T22:20:45.081665Z",
     "shell.execute_reply": "2024-08-06T22:20:45.080774Z"
    },
    "papermill": {
     "duration": 0.010467,
     "end_time": "2024-08-06T22:20:45.083581",
     "exception": false,
     "start_time": "2024-08-06T22:20:45.073114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 6\n",
    "TARGET = 'class'\n",
    "TIME_LIMIT = 3600 * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f94141cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T22:20:45.090749Z",
     "iopub.status.busy": "2024-08-06T22:20:45.090484Z",
     "iopub.status.idle": "2024-08-06T22:21:00.521403Z",
     "shell.execute_reply": "2024-08-06T22:21:00.520588Z"
    },
    "papermill": {
     "duration": 15.437041,
     "end_time": "2024-08-06T22:21:00.523726",
     "exception": false,
     "start_time": "2024-08-06T22:20:45.086685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv', index_col='id')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv', index_col='id')\n",
    "\n",
    "train[TARGET] = train[TARGET].map({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d20243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T22:21:00.531586Z",
     "iopub.status.busy": "2024-08-06T22:21:00.531300Z",
     "iopub.status.idle": "2024-08-06T22:21:00.535631Z",
     "shell.execute_reply": "2024-08-06T22:21:00.534804Z"
    },
    "papermill": {
     "duration": 0.010361,
     "end_time": "2024-08-06T22:21:00.537591",
     "exception": false,
     "start_time": "2024-08-06T22:21:00.527230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = TabularDataset(train)\n",
    "test = TabularDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc88ca1",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-06T22:21:00.545201Z",
     "iopub.status.busy": "2024-08-06T22:21:00.544866Z",
     "iopub.status.idle": "2024-08-06T22:21:00.550797Z",
     "shell.execute_reply": "2024-08-06T22:21:00.549957Z"
    },
    "papermill": {
     "duration": 0.011958,
     "end_time": "2024-08-06T22:21:00.552772",
     "exception": false,
     "start_time": "2024-08-06T22:21:00.540814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240806_222100\"\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=TARGET,\n",
    "    eval_metric='mcc',\n",
    "    problem_type='binary',\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b43927f",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-06T22:21:00.560929Z",
     "iopub.status.busy": "2024-08-06T22:21:00.560319Z",
     "iopub.status.idle": "2024-08-07T07:21:49.579104Z",
     "shell.execute_reply": "2024-08-07T07:21:49.578056Z"
    },
    "papermill": {
     "duration": 32449.02518,
     "end_time": "2024-08-07T07:21:49.581332",
     "exception": false,
     "start_time": "2024-08-06T22:21:00.556152",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       28.93 GB / 31.36 GB (92.2%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 8100s of the 32400s of remaining time (25%).\n",
      "2024-08-06 22:21:00,998\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-08-06 22:21:03,868\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels/ag-20240806_222100/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Beginning AutoGluon training ... Time limit = 8095s\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240806_222100/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Train Data Rows:    2770617\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Train Data Columns: 20\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Label Column:       class\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tAvailable Memory:                    29245.85 MB\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tTrain Data (Original)  Memory Usage: 2319.00 MB (7.9% of available memory)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tWarning: Data size prior to feature transformation consumes 7.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t39.5s = Fit runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t20 features in original data used to generate 20 features in processed data.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tTrain Data (Processed) Memory Usage: 108.34 MB (0.4% of available memory)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Data preprocessing and feature engineering runtime = 42.32s ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting 108 L1 models ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5367.25s of the 8052.88s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.22%)\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m 1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=591)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365347\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0360119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=591)\u001b[0m \tRan out of time, early stopping on iteration 2284. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=591)\u001b[0m \t[2283]\tvalid_set's binary_logloss: 0.0359452\n",
      "\u001b[36m(_ray_fit pid=632)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=632)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.036018\n",
      "\u001b[36m(_ray_fit pid=632)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0355372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=632)\u001b[0m \tRan out of time, early stopping on iteration 2355. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=632)\u001b[0m \t[2346]\tvalid_set's binary_logloss: 0.0354833\n",
      "\u001b[36m(_ray_fit pid=673)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=673)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0363115\n",
      "\u001b[36m(_ray_fit pid=673)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0358569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=673)\u001b[0m \tRan out of time, early stopping on iteration 2359. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=673)\u001b[0m \t[2356]\tvalid_set's binary_logloss: 0.0357866\n",
      "\u001b[36m(_ray_fit pid=714)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=714)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0363993\n",
      "\u001b[36m(_ray_fit pid=714)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0359928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=714)\u001b[0m \tRan out of time, early stopping on iteration 2331. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=714)\u001b[0m \t[2330]\tvalid_set's binary_logloss: 0.0359482\n",
      "\u001b[36m(_ray_fit pid=755)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=755)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0370816\n",
      "\u001b[36m(_ray_fit pid=755)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0365701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=755)\u001b[0m \tRan out of time, early stopping on iteration 2346. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=755)\u001b[0m \t[2344]\tvalid_set's binary_logloss: 0.0364857\n",
      "\u001b[36m(_ray_fit pid=796)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=796)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0360996\n",
      "\u001b[36m(_ray_fit pid=796)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0356736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=796)\u001b[0m \tRan out of time, early stopping on iteration 2332. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=796)\u001b[0m \t[2331]\tvalid_set's binary_logloss: 0.035629\n",
      "\u001b[36m(_ray_fit pid=837)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=837)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0373678\n",
      "\u001b[36m(_ray_fit pid=837)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0368908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=837)\u001b[0m \tRan out of time, early stopping on iteration 2307. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=837)\u001b[0m \t[2307]\tvalid_set's binary_logloss: 0.0368355\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365551\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0361498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=878)\u001b[0m \tRan out of time, early stopping on iteration 2319. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=878)\u001b[0m \t[2319]\tvalid_set's binary_logloss: 0.0361107\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.9847\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t4963.49s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t719.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 305.99s of the 2991.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.26%)\n",
      "\u001b[36m(_ray_fit pid=1147)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1147)\u001b[0m \tRan out of time, early stopping on iteration 68. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1147)\u001b[0m \t[68]\tvalid_set's binary_logloss: 0.103075\n",
      "\u001b[36m(_ray_fit pid=1188)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1188)\u001b[0m \tRan out of time, early stopping on iteration 68. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1188)\u001b[0m \t[68]\tvalid_set's binary_logloss: 0.102851\n",
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m \tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1229)\u001b[0m \t[69]\tvalid_set's binary_logloss: 0.101006\n",
      "\u001b[36m(_ray_fit pid=1271)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1271)\u001b[0m \tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1271)\u001b[0m \t[69]\tvalid_set's binary_logloss: 0.101545\n",
      "\u001b[36m(_ray_fit pid=1312)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1312)\u001b[0m \tRan out of time, early stopping on iteration 70. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1312)\u001b[0m \t[70]\tvalid_set's binary_logloss: 0.0992248\n",
      "\u001b[36m(_ray_fit pid=1353)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1353)\u001b[0m \tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1353)\u001b[0m \t[69]\tvalid_set's binary_logloss: 0.100019\n",
      "\u001b[36m(_ray_fit pid=1394)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1394)\u001b[0m \tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1394)\u001b[0m \t[69]\tvalid_set's binary_logloss: 0.101977\n",
      "\u001b[36m(_ray_fit pid=1435)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1435)\u001b[0m \tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1435)\u001b[0m \t[69]\tvalid_set's binary_logloss: 0.0998219\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.9708\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t296.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t18.5s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3.36s of the 2688.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tWarning: Model is expected to require 941.8s to train, which exceeds the maximum time limit of 3.4s, skipping model...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 536.73s of the 2675.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.9847\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t6.96s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting 108 L2 models ...\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2667.62s of the 2667.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.82%)\n",
      "\u001b[36m(_ray_fit pid=1717)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1717)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0368917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1717)\u001b[0m \tRan out of time, early stopping on iteration 1101. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1717)\u001b[0m \t[1099]\tvalid_set's binary_logloss: 0.0368465\n",
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0364785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m \tRan out of time, early stopping on iteration 1081. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m \t[1075]\tvalid_set's binary_logloss: 0.0364401\n",
      "\u001b[36m(_ray_fit pid=1799)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1799)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0361556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1799)\u001b[0m \tRan out of time, early stopping on iteration 1033. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1799)\u001b[0m \t[1030]\tvalid_set's binary_logloss: 0.0361346\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0370783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m \tRan out of time, early stopping on iteration 1102. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1840)\u001b[0m \t[1102]\tvalid_set's binary_logloss: 0.0370228\n",
      "\u001b[36m(_ray_fit pid=1881)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1881)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0363016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1881)\u001b[0m \tRan out of time, early stopping on iteration 1106. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1881)\u001b[0m \t[1106]\tvalid_set's binary_logloss: 0.0362517\n",
      "\u001b[36m(_ray_fit pid=1922)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1922)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0359621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1922)\u001b[0m \tRan out of time, early stopping on iteration 1108. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1922)\u001b[0m \t[1107]\tvalid_set's binary_logloss: 0.0359392\n",
      "\u001b[36m(_ray_fit pid=1963)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1963)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1963)\u001b[0m \tRan out of time, early stopping on iteration 1098. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1963)\u001b[0m \t[1064]\tvalid_set's binary_logloss: 0.0365652\n",
      "\u001b[36m(_ray_fit pid=2004)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2004)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0350067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2004)\u001b[0m \tRan out of time, early stopping on iteration 1055. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2004)\u001b[0m \t[1051]\tvalid_set's binary_logloss: 0.0349864\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.9846\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t2452.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t316.98s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 173.09s of the 172.93s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.82%)\n",
      "\u001b[36m(_ray_fit pid=2279)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2279)\u001b[0m \tRan out of time, early stopping on iteration 44. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2279)\u001b[0m \t[44]\tvalid_set's binary_logloss: 0.079895\n",
      "\u001b[36m(_ray_fit pid=2320)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2320)\u001b[0m \tRan out of time, early stopping on iteration 47. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2320)\u001b[0m \t[47]\tvalid_set's binary_logloss: 0.072618\n",
      "\u001b[36m(_ray_fit pid=2361)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2361)\u001b[0m \tRan out of time, early stopping on iteration 44. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2361)\u001b[0m \t[44]\tvalid_set's binary_logloss: 0.0796222\n",
      "\u001b[36m(_ray_fit pid=2402)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2402)\u001b[0m \tRan out of time, early stopping on iteration 46. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2402)\u001b[0m \t[46]\tvalid_set's binary_logloss: 0.0752087\n",
      "\u001b[36m(_ray_fit pid=2443)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2443)\u001b[0m \tRan out of time, early stopping on iteration 47. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2443)\u001b[0m \t[47]\tvalid_set's binary_logloss: 0.0724924\n",
      "\u001b[36m(_ray_fit pid=2484)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2484)\u001b[0m \tRan out of time, early stopping on iteration 47. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2484)\u001b[0m \t[47]\tvalid_set's binary_logloss: 0.0723163\n",
      "\u001b[36m(_ray_fit pid=2525)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2525)\u001b[0m \tRan out of time, early stopping on iteration 47. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2525)\u001b[0m \t[47]\tvalid_set's binary_logloss: 0.0726616\n",
      "\u001b[36m(_ray_fit pid=2566)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2566)\u001b[0m \tRan out of time, early stopping on iteration 48. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2566)\u001b[0m \t[48]\tvalid_set's binary_logloss: 0.0697502\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.9845\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t179.11s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t5.63s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -12.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.917, 'LightGBMXT_BAG_L2': 0.083}\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.9847\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t11.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m \t0.47s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m AutoGluon training complete, total runtime = 8120.08s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 328.3 rows/s (346328 batch size)\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240806_222100/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=174)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBM_BAG_L2       0.985048   0.984519         mcc      221.130708     743.345983  5438.965714                 2.674469                5.629052         179.107656            2       True          5\n",
      "1    LightGBMXT_BAG_L1       0.984996   0.984664         mcc      211.813191     719.220545  4963.489239               211.813191              719.220545        4963.489239            1       True          1\n",
      "2  WeightedEnsemble_L2       0.984996   0.984664         mcc      211.817647     719.676240  4970.447076                 0.004456                0.455695           6.957837            2       True          3\n",
      "3  WeightedEnsemble_L3       0.984979   0.984682         mcc      316.026006    1055.161793  7724.421408                 0.006300                0.465808          11.969461            3       True          6\n",
      "4    LightGBMXT_BAG_L2       0.984833   0.984567         mcc      316.019706    1054.695985  7712.451947                97.563468              316.979054        2452.593889            2       True          4\n",
      "5      LightGBM_BAG_L1       0.971834   0.970838         mcc        6.643047      18.496386   296.368820                 6.643047               18.496386         296.368820            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t8461s\t = DyStack   runtime |\t23939s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 23939s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240806_222100\"\n",
      "Train Data Rows:    3116945\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30825.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2608.77 MB (8.5% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 8.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t33.5s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 121.88 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 35.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 23903.72s of the 23903.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.42%)\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t11268.07s\t = Training   runtime\n",
      "\t1349.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 12469.47s of the 12469.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.43%)\n",
      "\t0.9844\t = Validation score   (mcc)\n",
      "\t5873.83s\t = Training   runtime\n",
      "\t658.11s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 6489.22s of the 6489.2s of remaining time.\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t1196.75s\t = Training   runtime\n",
      "\t116.33s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5173.55s of the 5173.53s of remaining time.\n",
      "\t0.9842\t = Validation score   (mcc)\n",
      "\t1196.52s\t = Training   runtime\n",
      "\t125.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 3849.36s of the 3849.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.56%)\n",
      "\t0.8202\t = Validation score   (mcc)\n",
      "\t300.87s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3544.28s of the 3544.26s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t707.76s\t = Training   runtime\n",
      "\t121.52s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2712.32s of the 2712.3s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t726.62s\t = Training   runtime\n",
      "\t124.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1858.44s of the 1858.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=6.07%)\n",
      "\t0.9837\t = Validation score   (mcc)\n",
      "\t945.86s\t = Training   runtime\n",
      "\t36.38s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 904.04s of the 904.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=4.74%)\n",
      "\t0.9845\t = Validation score   (mcc)\n",
      "\t682.22s\t = Training   runtime\n",
      "\t35.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 213.38s of the 213.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.36%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 178.32s of the 178.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=3.68%)\n",
      "\t0.973\t = Validation score   (mcc)\n",
      "\t189.14s\t = Training   runtime\n",
      "\t8.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 2390.37s of the -16.3s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.444, 'RandomForestGini_BAG_L1': 0.222, 'RandomForestEntr_BAG_L1': 0.222, 'XGBoost_BAG_L1': 0.056, 'LightGBMLarge_BAG_L1': 0.056}\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t31.27s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23987.42s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 273.7 rows/s (389619 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240806_222100\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f0d04bb1ff0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(\n",
    "    train_data=train,\n",
    "    time_limit=TIME_LIMIT,\n",
    "    presets='best_quality',\n",
    "    save_space=True,\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={\n",
    "        'num_gpus': 1, \n",
    "        'stopping_metric': 'log_loss'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a76893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T07:21:49.633589Z",
     "iopub.status.busy": "2024-08-07T07:21:49.631651Z",
     "iopub.status.idle": "2024-08-07T08:16:57.114253Z",
     "shell.execute_reply": "2024-08-07T08:16:57.112987Z"
    },
    "papermill": {
     "duration": 3307.511903,
     "end_time": "2024-08-07T08:16:57.117270",
     "exception": false,
     "start_time": "2024-08-07T07:21:49.605367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred_probs = predictor.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5a5051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T08:16:57.167369Z",
     "iopub.status.busy": "2024-08-07T08:16:57.166729Z",
     "iopub.status.idle": "2024-08-07T08:17:00.249223Z",
     "shell.execute_reply": "2024-08-07T08:17:00.248260Z"
    },
    "papermill": {
     "duration": 3.110066,
     "end_time": "2024-08-07T08:17:00.251697",
     "exception": false,
     "start_time": "2024-08-07T08:16:57.141631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3116947</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3116948</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3116949</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id class\n",
       "0  3116945     e\n",
       "1  3116946     p\n",
       "2  3116947     p\n",
       "3  3116948     p\n",
       "4  3116949     e"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv')\n",
    "sub[TARGET] = np.argmax(test_pred_probs, axis=1)\n",
    "sub[TARGET] = sub[TARGET].map({0: 'e', 1: 'p'})\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e3545d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T08:17:00.302418Z",
     "iopub.status.busy": "2024-08-07T08:17:00.301975Z",
     "iopub.status.idle": "2024-08-07T08:17:00.771668Z",
     "shell.execute_reply": "2024-08-07T08:17:00.770585Z"
    },
    "papermill": {
     "duration": 0.497888,
     "end_time": "2024-08-07T08:17:00.774078",
     "exception": false,
     "start_time": "2024-08-07T08:17:00.276190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"AutogluonModels\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35834.728475,
   "end_time": "2024-08-07T08:17:06.093364",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-06T22:19:51.364889",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
