{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64aeeddc",
   "metadata": {
    "papermill": {
     "duration": 0.005044,
     "end_time": "2024-11-02T08:34:41.778989",
     "exception": false,
     "start_time": "2024-11-02T08:34:41.773945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b685070",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-02T08:34:41.791339Z",
     "iopub.status.busy": "2024-11-02T08:34:41.790873Z",
     "iopub.status.idle": "2024-11-02T08:35:37.585440Z",
     "shell.execute_reply": "2024-11-02T08:35:37.583925Z"
    },
    "papermill": {
     "duration": 55.804831,
     "end_time": "2024-11-02T08:35:37.588947",
     "exception": false,
     "start_time": "2024-11-02T08:34:41.784116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "aiobotocore 2.15.1 requires botocore<1.35.24,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.3 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tsfresh 0.20.3 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q autogluon.tabular ray==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743a43da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T08:35:37.600728Z",
     "iopub.status.busy": "2024-11-02T08:35:37.600225Z",
     "iopub.status.idle": "2024-11-02T08:35:41.555138Z",
     "shell.execute_reply": "2024-11-02T08:35:41.553734Z"
    },
    "papermill": {
     "duration": 3.964438,
     "end_time": "2024-11-02T08:35:41.558199",
     "exception": false,
     "start_time": "2024-11-02T08:35:37.593761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shutil\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aba4891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T08:35:41.573707Z",
     "iopub.status.busy": "2024-11-02T08:35:41.572963Z",
     "iopub.status.idle": "2024-11-02T08:35:41.583735Z",
     "shell.execute_reply": "2024-11-02T08:35:41.581772Z"
    },
    "papermill": {
     "duration": 0.022468,
     "end_time": "2024-11-02T08:35:41.586628",
     "exception": false,
     "start_time": "2024-11-02T08:35:41.564160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    train_path = '/kaggle/input/playground-series-s4e11/train.csv'\n",
    "    test_path = '/kaggle/input/playground-series-s4e11/test.csv'\n",
    "    sample_sub_path = '/kaggle/input/playground-series-s4e11/sample_submission.csv'\n",
    "    original_data_path = '/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv'\n",
    "    \n",
    "    target = 'Depression'\n",
    "    time_limit = 3600 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ddf69",
   "metadata": {
    "papermill": {
     "duration": 0.006307,
     "end_time": "2024-11-02T08:35:41.598294",
     "exception": false,
     "start_time": "2024-11-02T08:35:41.591987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265f19b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T08:35:41.614278Z",
     "iopub.status.busy": "2024-11-02T08:35:41.613011Z",
     "iopub.status.idle": "2024-11-02T08:35:42.971960Z",
     "shell.execute_reply": "2024-11-02T08:35:42.970545Z"
    },
    "papermill": {
     "duration": 1.370623,
     "end_time": "2024-11-02T08:35:42.975147",
     "exception": false,
     "start_time": "2024-11-02T08:35:41.604524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(CFG.train_path, index_col='id')\n",
    "test = pd.read_csv(CFG.test_path, index_col='id')\n",
    "\n",
    "original = pd.read_csv(CFG.original_data_path)\n",
    "original[CFG.target] = original[CFG.target].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa5d8a",
   "metadata": {
    "papermill": {
     "duration": 0.004625,
     "end_time": "2024-11-02T08:35:42.984852",
     "exception": false,
     "start_time": "2024-11-02T08:35:42.980227",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fitting the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd069bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T08:35:42.996933Z",
     "iopub.status.busy": "2024-11-02T08:35:42.996382Z",
     "iopub.status.idle": "2024-11-02T08:35:43.006049Z",
     "shell.execute_reply": "2024-11-02T08:35:43.004557Z"
    },
    "papermill": {
     "duration": 0.018728,
     "end_time": "2024-11-02T08:35:43.008798",
     "exception": false,
     "start_time": "2024-11-02T08:35:42.990070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241102_083542\"\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    problem_type='binary',\n",
    "    eval_metric='accuracy',\n",
    "    label=CFG.target,\n",
    "    verbosity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f2ce27",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-11-02T08:35:43.023343Z",
     "iopub.status.busy": "2024-11-02T08:35:43.022595Z",
     "iopub.status.idle": "2024-11-02T18:37:54.125651Z",
     "shell.execute_reply": "2024-11-02T18:37:54.124370Z"
    },
    "papermill": {
     "duration": 36131.11685,
     "end_time": "2024-11-02T18:37:54.130772",
     "exception": false,
     "start_time": "2024-11-02T08:35:43.013922",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predictor not fit prior to pseudolabeling. Fitting now...\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       30.24 GB / 31.36 GB (96.4%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 4500s of the 18000s of remaining time (25%).\n",
      "2024-11-02 08:35:43,533\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-11-02 08:35:47,706\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels/ag-20241102_083542/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Beginning AutoGluon training ... Time limit = 4494s\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20241102_083542/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Train Data Rows:    125066\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Train Data Columns: 18\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Label Column:       Depression\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tAvailable Memory:                    30573.48 MB\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tTrain Data (Original)  Memory Usage: 83.58 MB (0.3% of available memory)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t('float', [])  :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t('object', []) : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t1.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t18 features in original data used to generate 18 features in processed data.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tTrain Data (Processed) Memory Usage: 8.95 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Data preprocessing and feature engineering runtime = 1.41s ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting 110 L1 models ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2994.08s of the 4492.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9092\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t1.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t1.29s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2987.76s of the 4485.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9025\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t1.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2985.95s of the 4484.1s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t66.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 2916.82s of the 4414.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.939\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t67.24s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2846.68s of the 4344.82s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9361\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t29.74s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t4.96s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2810.83s of the 4308.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9362\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t28.07s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t4.75s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 2777.08s of the 4275.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.24%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.94\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t532.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2241.46s of the 3739.6s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9355\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t19.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t5.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2214.81s of the 3712.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9355\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t19.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t5.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2188.51s of the 3686.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.37%)\n",
      "\u001b[36m(_ray_fit pid=1513)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_ray_fit pid=1513)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1513)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1562)\u001b[0m No improvement since epoch 1: early stopping\n",
      "\u001b[36m(_ray_fit pid=1562)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1562)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1611)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=1611)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1611)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1660)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_ray_fit pid=1660)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1660)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1709)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_ray_fit pid=1709)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1709)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1758)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1807)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[36m(_ray_fit pid=1807)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1807)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=1856)\u001b[0m No improvement since epoch 2: early stopping\n",
      "\u001b[36m(_ray_fit pid=1856)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=1856)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9387\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t1448.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t3.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 737.23s of the 2235.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.31%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9396\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t312.57s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.85s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 421.8s of the 1919.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.20%)\n",
      "\u001b[36m(_ray_fit pid=2253)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2253)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2253)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2297)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2297)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2297)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2341)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 12)\n",
      "\u001b[36m(_ray_fit pid=2341)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2341)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2385)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2429)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2429)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2429)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2473)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2473)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2473)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2517)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2517)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2517)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=2561)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 11)\n",
      "\u001b[36m(_ray_fit pid=2561)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=2561)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9384\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t357.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.97s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 61.21s of the 1559.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.27%)\n",
      "\u001b[36m(_ray_fit pid=2611)\u001b[0m \tRan out of time, early stopping on iteration 103. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2611)\u001b[0m \t[97]\tvalid_set's binary_error: 0.0636433\n",
      "\u001b[36m(_ray_fit pid=2652)\u001b[0m \tRan out of time, early stopping on iteration 88. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2652)\u001b[0m \t[86]\tvalid_set's binary_error: 0.0628118\n",
      "\u001b[36m(_ray_fit pid=2695)\u001b[0m \tRan out of time, early stopping on iteration 106. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2695)\u001b[0m \t[92]\tvalid_set's binary_error: 0.0593616\n",
      "\u001b[36m(_ray_fit pid=2737)\u001b[0m \tRan out of time, early stopping on iteration 112. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2737)\u001b[0m \t[111]\tvalid_set's binary_error: 0.0651187\n",
      "\u001b[36m(_ray_fit pid=2779)\u001b[0m \tRan out of time, early stopping on iteration 86. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2779)\u001b[0m \t[83]\tvalid_set's binary_error: 0.0626239\n",
      "\u001b[36m(_ray_fit pid=2821)\u001b[0m \tRan out of time, early stopping on iteration 99. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2821)\u001b[0m \t[97]\tvalid_set's binary_error: 0.0615365\n",
      "\u001b[36m(_ray_fit pid=2863)\u001b[0m \tRan out of time, early stopping on iteration 97. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2863)\u001b[0m \t[79]\tvalid_set's binary_error: 0.0604491\n",
      "\u001b[36m(_ray_fit pid=2905)\u001b[0m \tRan out of time, early stopping on iteration 85. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2905)\u001b[0m \t[81]\tvalid_set's binary_error: 0.0614086\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9379\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t77.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1478.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.94\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t4.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting 108 L2 models ...\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1474.09s of the 1473.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.37%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t58.32s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 1412.75s of the 1412.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.37%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.94\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t53.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1355.91s of the 1355.8s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t66.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t6.32s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1281.42s of the 1281.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9399\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t69.19s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t6.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1204.86s of the 1204.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.39%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9405\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t93.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.12s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1108.48s of the 1108.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9394\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t26.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t7.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1072.82s of the 1072.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t26.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t6.78s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1037.92s of the 1037.81s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.60%)\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 13)\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4122)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4171)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4171)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4220)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4220)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4269)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4269)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4318)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4318)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4367)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4416)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4416)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_ray_fit pid=4465)\u001b[0m /opt/conda/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4465)\u001b[0m   state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9401\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t785.09s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t3.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 249.55s of the 249.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.51%)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9404\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t153.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.75s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 92.48s of the 92.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.33%)\n",
      "\u001b[36m(_ray_fit pid=4874)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\u001b[36m(_ray_fit pid=4874)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4874)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=4918)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\u001b[36m(_ray_fit pid=4918)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4918)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=4962)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\u001b[36m(_ray_fit pid=4962)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=4962)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=5006)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\u001b[36m(_ray_fit pid=5006)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5006)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=5050)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\u001b[36m(_ray_fit pid=5050)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5050)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=5094)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5094)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=5138)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\n",
      "\u001b[36m(_ray_fit pid=5138)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5138)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_ray_fit pid=5182)\u001b[0m /opt/conda/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_ray_fit pid=5182)\u001b[0m   self.model = torch.load(net_filename)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9385\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t113.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t1.48s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -25.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 0.783, 'XGBoost_BAG_L2': 0.087, 'LightGBM_BAG_L2': 0.043, 'RandomForestGini_BAG_L2': 0.043, 'ExtraTreesEntr_BAG_L2': 0.043}\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.9406\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t7.39s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m AutoGluon training complete, total runtime = 4526.66s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1211.5 rows/s (15634 batch size)\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241102_083542/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(_dystack pid=171)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0            XGBoost_BAG_L2       0.943137   0.940407    accuracy       29.332349      31.373481  3114.993421                 1.851104                0.752754         153.978955            2       True         23\n",
      "1       WeightedEnsemble_L3       0.942561   0.940647    accuracy       34.936135      44.815767  3362.577531                 0.008865                0.013760           7.392114            3       True         25\n",
      "2           LightGBM_BAG_L2       0.942497   0.940024    accuracy       27.808587      30.835318  3014.711206                 0.327342                0.214592          53.696740            2       True         16\n",
      "3   RandomForestGini_BAG_L2       0.942433   0.939928    accuracy       29.575184      36.939705  3027.995495                 2.093939                6.318979          66.981029            2       True         17\n",
      "4           CatBoost_BAG_L2       0.942113   0.940535    accuracy       27.748396      30.737179  3054.296932                 0.267151                0.116453          93.282466            2       True         19\n",
      "5   RandomForestEntr_BAG_L2       0.941921   0.939928    accuracy       29.176707      36.767030  3030.201054                 1.695462                6.146304          69.186588            2       True         18\n",
      "6     ExtraTreesGini_BAG_L2       0.941921   0.939384    accuracy       30.593084      37.638333  2987.638204                 3.111839                7.017606          26.623738            2       True         20\n",
      "7           CatBoost_BAG_L1       0.941857   0.939960    accuracy        1.413673       0.314621   532.920192                 1.413673                0.314621         532.920192            1       True          7\n",
      "8       WeightedEnsemble_L2       0.941857   0.939960    accuracy        1.417118       0.328041   537.151593                 0.003445                0.013420           4.231401            2       True         14\n",
      "9         LightGBMXT_BAG_L2       0.941666   0.940503    accuracy       27.984069      30.926640  3019.330967                 0.502823                0.305914          58.316502            2       True         15\n",
      "10   NeuralNetFastAI_BAG_L2       0.941666   0.940120    accuracy       32.724035      33.882097  3746.106628                 5.242790                3.261370         785.092162            2       True         22\n",
      "11    ExtraTreesEntr_BAG_L2       0.941602   0.940064    accuracy       30.387736      37.399229  2987.246227                 2.906490                6.778502          26.231761            2       True         21\n",
      "12   NeuralNetFastAI_BAG_L1       0.941282   0.938688    accuracy        6.893536       3.371612  1448.079346                 6.893536                3.371612        1448.079346            1       True         10\n",
      "13          LightGBM_BAG_L1       0.940962   0.938960    accuracy        1.009403       0.610834    67.236745                 1.009403                0.610834          67.236745            1       True          4\n",
      "14           XGBoost_BAG_L1       0.940834   0.939608    accuracy        1.509213       0.852563   312.568955                 1.509213                0.852563         312.568955            1       True         11\n",
      "15    NeuralNetTorch_BAG_L1       0.940770   0.938353    accuracy        1.048528       0.967708   357.670121                 1.048528                0.967708         357.670121            1       True         12\n",
      "16        LightGBMXT_BAG_L1       0.940770   0.939856    accuracy        2.178588       0.610829    66.369349                 2.178588                0.610829          66.369349            1       True          3\n",
      "17    NeuralNetTorch_BAG_L2       0.940386   0.938544    accuracy       30.962072      32.102507  3074.870829                 3.480827                1.481781         113.856364            2       True         24\n",
      "18    ExtraTreesEntr_BAG_L1       0.938979   0.935466    accuracy        2.007923       5.447907    19.530939                 2.007923                5.447907          19.530939            1       True          9\n",
      "19     LightGBMLarge_BAG_L1       0.938787   0.937881    accuracy        0.834743       0.533350    77.846177                 0.834743                0.533350          77.846177            1       True         13\n",
      "20  RandomForestGini_BAG_L1       0.938467   0.936106    accuracy        3.851916       4.956590    29.739407                 3.851916                4.956590          29.739407            1       True          5\n",
      "21  RandomForestEntr_BAG_L1       0.938020   0.936234    accuracy        3.397142       4.754690    28.069170                 3.397142                4.754690          28.069170            1       True          6\n",
      "22    ExtraTreesGini_BAG_L1       0.937572   0.935474    accuracy        2.838846       5.425415    19.702597                 2.838846                5.425415          19.702597            1       True          8\n",
      "23    KNeighborsUnif_BAG_L1       0.913394   0.909192    accuracy        0.276395       1.287959     1.039897                 0.276395                1.287959           1.039897            1       True          1\n",
      "24    KNeighborsDist_BAG_L1       0.902264   0.902491    accuracy        0.221339       1.486649     0.241570                 0.221339                1.486649           0.241570            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t4586s\t = DyStack   runtime |\t13414s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 13414s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241102_083542\"\n",
      "Train Data Rows:    140700\n",
      "Train Data Columns: 18\n",
      "Label Column:       Depression\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11232.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 94.04 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t('object', []) : 10 | ['Name', 'Gender', 'City', 'Working Professional or Student', 'Profession', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['Name', 'City', 'Profession', 'Sleep Duration', 'Dietary Habits', ...]\n",
      "\t\t('float', [])     : 8 | ['Age', 'Academic Pressure', 'Work Pressure', 'CGPA', 'Study Satisfaction', ...]\n",
      "\t\t('int', ['bool']) : 4 | ['Gender', 'Working Professional or Student', 'Have you ever had suicidal thoughts ?', 'Family History of Mental Illness']\n",
      "\t1.9s = Fit runtime\n",
      "\t18 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 8938.75s of the 13411.46s of remaining time.\n",
      "\t0.9098\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 8933.03s of the 13405.74s of remaining time.\n",
      "\t0.9029\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 8931.18s of the 13403.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.25%)\n",
      "\t0.9396\t = Validation score   (accuracy)\n",
      "\t71.24s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 8856.91s of the 13329.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.25%)\n",
      "\t0.9391\t = Validation score   (accuracy)\n",
      "\t74.98s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 8778.89s of the 13251.6s of remaining time.\n",
      "\t0.9372\t = Validation score   (accuracy)\n",
      "\t35.73s\t = Training   runtime\n",
      "\t6.34s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 8734.95s of the 13207.65s of remaining time.\n",
      "\t0.9368\t = Validation score   (accuracy)\n",
      "\t34.39s\t = Training   runtime\n",
      "\t6.4s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 8692.78s of the 13165.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.26%)\n",
      "\t0.9397\t = Validation score   (accuracy)\n",
      "\t581.39s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 8108.39s of the 12581.1s of remaining time.\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t25.5s\t = Training   runtime\n",
      "\t6.97s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 8072.77s of the 12545.48s of remaining time.\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t25.94s\t = Training   runtime\n",
      "\t7.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8036.02s of the 12508.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.42%)\n",
      "\t0.939\t = Validation score   (accuracy)\n",
      "\t1762.47s\t = Training   runtime\n",
      "\t3.82s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 6269.85s of the 10742.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.35%)\n",
      "\t0.9398\t = Validation score   (accuracy)\n",
      "\t398.19s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 5868.3s of the 10341.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.9386\t = Validation score   (accuracy)\n",
      "\t848.38s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 5016.95s of the 9489.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.30%)\n",
      "\t0.9388\t = Validation score   (accuracy)\n",
      "\t142.76s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 4871.16s of the 9343.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.27%)\n",
      "\t0.94\t = Validation score   (accuracy)\n",
      "\t503.84s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 4364.39s of the 8837.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.9393\t = Validation score   (accuracy)\n",
      "\t1199.61s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 3161.69s of the 7634.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.27%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t39.1s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 3119.47s of the 7592.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.42%)\n",
      "\t0.94\t = Validation score   (accuracy)\n",
      "\t2516.12s\t = Training   runtime\n",
      "\t5.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 599.57s of the 5072.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.34%)\n",
      "\t0.939\t = Validation score   (accuracy)\n",
      "\t303.44s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 292.83s of the 4765.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.26%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t35.26s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 254.55s of the 4727.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.938\t = Validation score   (accuracy)\n",
      "\t220.14s\t = Training   runtime\n",
      "\t1.59s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 31.26s of the 4503.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.51%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t46.04s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 893.87s of the 4454.57s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r191_BAG_L1': 0.4, 'CatBoost_r177_BAG_L1': 0.16, 'XGBoost_BAG_L1': 0.12, 'RandomForestGini_BAG_L1': 0.08, 'NeuralNetTorch_BAG_L1': 0.08, 'LightGBMXT_BAG_L1': 0.04, 'CatBoost_BAG_L1': 0.04, 'NeuralNetFastAI_BAG_L1': 0.04, 'NeuralNetTorch_r79_BAG_L1': 0.04}\n",
      "\t0.9409\t = Validation score   (accuracy)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 4447.13s of the 4446.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.52%)\n",
      "\t0.9405\t = Validation score   (accuracy)\n",
      "\t63.2s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 4380.64s of the 4380.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.52%)\n",
      "\t0.9406\t = Validation score   (accuracy)\n",
      "\t62.67s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 4314.66s of the 4314.46s of remaining time.\n",
      "\t0.9405\t = Validation score   (accuracy)\n",
      "\t109.95s\t = Training   runtime\n",
      "\t8.26s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 4195.4s of the 4195.21s of remaining time.\n",
      "\t0.9401\t = Validation score   (accuracy)\n",
      "\t110.35s\t = Training   runtime\n",
      "\t8.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4075.49s of the 4075.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.54%)\n",
      "\t0.9408\t = Validation score   (accuracy)\n",
      "\t125.54s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 3946.93s of the 3946.74s of remaining time.\n",
      "\t0.9404\t = Validation score   (accuracy)\n",
      "\t35.09s\t = Training   runtime\n",
      "\t8.87s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 3900.95s of the 3900.76s of remaining time.\n",
      "\t0.9399\t = Validation score   (accuracy)\n",
      "\t36.04s\t = Training   runtime\n",
      "\t8.86s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 3853.91s of the 3853.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.84%)\n",
      "\t0.9406\t = Validation score   (accuracy)\n",
      "\t1727.84s\t = Training   runtime\n",
      "\t3.95s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 2122.22s of the 2122.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.71%)\n",
      "\t0.9406\t = Validation score   (accuracy)\n",
      "\t237.68s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 1880.97s of the 1880.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.46%)\n",
      "\t0.9395\t = Validation score   (accuracy)\n",
      "\t869.68s\t = Training   runtime\n",
      "\t2.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 1007.83s of the 1007.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.60%)\n",
      "\t0.9402\t = Validation score   (accuracy)\n",
      "\t127.92s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 876.49s of the 876.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.54%)\n",
      "\t0.9406\t = Validation score   (accuracy)\n",
      "\t90.18s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 782.97s of the 782.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.46%)\n",
      "\t0.9402\t = Validation score   (accuracy)\n",
      "\t646.12s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 133.32s of the 133.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.54%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t44.63s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 85.4s of the 85.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.84%)\n",
      "\t0.9385\t = Validation score   (accuracy)\n",
      "\t167.55s\t = Training   runtime\n",
      "\t5.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 444.71s of the -87.58s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
      "\t0.9408\t = Validation score   (accuracy)\n",
      "\t9.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13510.43s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1182.1 rows/s (17588 batch size)\n",
      "Deleting model KNeighborsUnif_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/KNeighborsUnif_BAG_L1 will be removed.\n",
      "Deleting model KNeighborsDist_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/KNeighborsDist_BAG_L1 will be removed.\n",
      "Deleting model LightGBM_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_BAG_L1 will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/RandomForestEntr_BAG_L1 will be removed.\n",
      "Deleting model ExtraTreesGini_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/ExtraTreesGini_BAG_L1 will be removed.\n",
      "Deleting model ExtraTreesEntr_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/ExtraTreesEntr_BAG_L1 will be removed.\n",
      "Deleting model LightGBMLarge_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/LightGBMLarge_BAG_L1 will be removed.\n",
      "Deleting model LightGBM_r131_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r131_BAG_L1 will be removed.\n",
      "Deleting model CatBoost_r9_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_r9_BAG_L1 will be removed.\n",
      "Deleting model LightGBM_r96_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r96_BAG_L1 will be removed.\n",
      "Deleting model NeuralNetTorch_r22_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_r22_BAG_L1 will be removed.\n",
      "Deleting model XGBoost_r33_BAG_L1. All files under AutogluonModels/ag-20241102_083542/models/XGBoost_r33_BAG_L1 will be removed.\n",
      "Deleting model LightGBMXT_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/LightGBMXT_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_BAG_L2 will be removed.\n",
      "Deleting model RandomForestGini_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/RandomForestGini_BAG_L2 will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/RandomForestEntr_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_BAG_L2 will be removed.\n",
      "Deleting model ExtraTreesGini_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/ExtraTreesGini_BAG_L2 will be removed.\n",
      "Deleting model ExtraTreesEntr_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/ExtraTreesEntr_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetFastAI_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetFastAI_BAG_L2 will be removed.\n",
      "Deleting model XGBoost_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/XGBoost_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetTorch_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_BAG_L2 will be removed.\n",
      "Deleting model LightGBMLarge_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/LightGBMLarge_BAG_L2 will be removed.\n",
      "Deleting model CatBoost_r177_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_r177_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetTorch_r79_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_r79_BAG_L2 will be removed.\n",
      "Deleting model LightGBM_r131_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r131_BAG_L2 will be removed.\n",
      "Deleting model NeuralNetFastAI_r191_BAG_L2. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetFastAI_r191_BAG_L2 will be removed.\n",
      "Deleting model WeightedEnsemble_L3. All files under AutogluonModels/ag-20241102_083542/models/WeightedEnsemble_L3 will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241102_083542\")\n",
      "Fitting predictor using the provided pseudolabeled examples as extra training data...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1_PSEUDO ... Training model for up to 18000.0s of the 17999.97s of remaining time.\n",
      "\t0.9103\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t1.63s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_PSEUDO ... Training model for up to 17997.99s of the 17997.96s of remaining time.\n",
      "\t0.9026\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1_PSEUDO ... Training model for up to 17996.12s of the 17996.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.26%)\n",
      "\t0.9397\t = Validation score   (accuracy)\n",
      "\t74.44s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1_PSEUDO ... Training model for up to 17918.56s of the 17918.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.26%)\n",
      "\t0.9392\t = Validation score   (accuracy)\n",
      "\t73.82s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_PSEUDO ... Training model for up to 17841.57s of the 17841.55s of remaining time.\n",
      "\t0.9367\t = Validation score   (accuracy)\n",
      "\t37.41s\t = Training   runtime\n",
      "\t6.81s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_PSEUDO ... Training model for up to 17795.55s of the 17795.53s of remaining time.\n",
      "\t0.937\t = Validation score   (accuracy)\n",
      "\t36.64s\t = Training   runtime\n",
      "\t6.3s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1_PSEUDO ... Training model for up to 17751.01s of the 17750.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.27%)\n",
      "\t0.94\t = Validation score   (accuracy)\n",
      "\t503.49s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_PSEUDO ... Training model for up to 17244.68s of the 17244.65s of remaining time.\n",
      "\t0.9365\t = Validation score   (accuracy)\n",
      "\t25.92s\t = Training   runtime\n",
      "\t6.98s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_PSEUDO ... Training model for up to 17208.98s of the 17208.95s of remaining time.\n",
      "\t0.9364\t = Validation score   (accuracy)\n",
      "\t31.12s\t = Training   runtime\n",
      "\t9.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_PSEUDO ... Training model for up to 17165.05s of the 17165.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.43%)\n",
      "\t0.939\t = Validation score   (accuracy)\n",
      "\t1726.85s\t = Training   runtime\n",
      "\t3.65s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1_PSEUDO ... Training model for up to 15434.71s of the 15434.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.36%)\n",
      "\t0.9399\t = Validation score   (accuracy)\n",
      "\t458.14s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1_PSEUDO ... Training model for up to 14973.25s of the 14973.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.9384\t = Validation score   (accuracy)\n",
      "\t910.48s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1_PSEUDO ... Training model for up to 14059.71s of the 14059.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.30%)\n",
      "\t0.9392\t = Validation score   (accuracy)\n",
      "\t156.91s\t = Training   runtime\n",
      "\t1.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1_PSEUDO ... Training model for up to 13899.65s of the 13899.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.27%)\n",
      "\t0.9401\t = Validation score   (accuracy)\n",
      "\t461.28s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1_PSEUDO ... Training model for up to 13435.24s of the 13435.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.24%)\n",
      "\t0.9393\t = Validation score   (accuracy)\n",
      "\t1217.79s\t = Training   runtime\n",
      "\t1.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1_PSEUDO ... Training model for up to 12214.36s of the 12214.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.27%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t39.52s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_PSEUDO ... Training model for up to 12171.73s of the 12171.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.42%)\n",
      "\t0.9397\t = Validation score   (accuracy)\n",
      "\t3323.12s\t = Training   runtime\n",
      "\t5.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1_PSEUDO ... Training model for up to 8844.81s of the 8844.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.34%)\n",
      "\t0.9392\t = Validation score   (accuracy)\n",
      "\t382.55s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1_PSEUDO ... Training model for up to 8459.12s of the 8459.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.26%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t36.24s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1_PSEUDO ... Training model for up to 8419.89s of the 8419.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.939\t = Validation score   (accuracy)\n",
      "\t1460.45s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: XGBoost_r33_BAG_L1_PSEUDO ... Training model for up to 6956.27s of the 6956.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.51%)\n",
      "\t0.8183\t = Validation score   (accuracy)\n",
      "\t94.33s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1_PSEUDO ... Training model for up to 6858.79s of the 6858.77s of remaining time.\n",
      "\t0.9357\t = Validation score   (accuracy)\n",
      "\t49.64s\t = Training   runtime\n",
      "\t6.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1_PSEUDO ... Training model for up to 6800.56s of the 6800.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.26%)\n",
      "\t0.94\t = Validation score   (accuracy)\n",
      "\t517.19s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1_PSEUDO ... Training model for up to 6280.6s of the 6280.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.43%)\n",
      "\t0.938\t = Validation score   (accuracy)\n",
      "\t457.07s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1_PSEUDO ... Training model for up to 5820.3s of the 5820.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.34%)\n",
      "\t0.9401\t = Validation score   (accuracy)\n",
      "\t1195.5s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1_PSEUDO ... Training model for up to 4621.48s of the 4621.45s of remaining time.\n",
      "\t0.9351\t = Validation score   (accuracy)\n",
      "\t85.28s\t = Training   runtime\n",
      "\t6.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1_PSEUDO ... Training model for up to 4529.48s of the 4529.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.30%)\n",
      "\t0.94\t = Validation score   (accuracy)\n",
      "\t158.21s\t = Training   runtime\n",
      "\t1.66s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1_PSEUDO ... Training model for up to 4367.84s of the 4367.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.42%)\n",
      "\t0.9399\t = Validation score   (accuracy)\n",
      "\t3427.31s\t = Training   runtime\n",
      "\t7.92s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1_PSEUDO ... Training model for up to 936.0s of the 935.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.35%)\n",
      "\t0.9397\t = Validation score   (accuracy)\n",
      "\t495.15s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1_PSEUDO ... Training model for up to 437.73s of the 437.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.23%)\n",
      "\t0.9392\t = Validation score   (accuracy)\n",
      "\t380.25s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_r130_BAG_L1_PSEUDO ... Training model for up to 54.37s of the 54.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=0.29%)\n",
      "\t0.939\t = Validation score   (accuracy)\n",
      "\t73.25s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_PSEUDO ... Training model for up to 1800.0s of the -22.32s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r191_BAG_L1_PSEUDO': 0.278, 'CatBoost_BAG_L1_PSEUDO': 0.167, 'NeuralNetFastAI_BAG_L1_PSEUDO': 0.167, 'CatBoost_r177_BAG_L1_PSEUDO': 0.111, 'RandomForestGini_BAG_L1_PSEUDO': 0.056, 'XGBoost_BAG_L1_PSEUDO': 0.056, 'CatBoost_r137_BAG_L1_PSEUDO': 0.056, 'CatBoost_r13_BAG_L1_PSEUDO': 0.056, 'NeuralNetFastAI_r145_BAG_L1_PSEUDO': 0.056}\n",
      "\t0.9408\t = Validation score   (accuracy)\n",
      "\t8.77s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Deleting model KNeighborsUnif_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/KNeighborsUnif_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model KNeighborsDist_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/KNeighborsDist_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBMXT_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBMXT_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBM_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model RandomForestGini_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/RandomForestGini_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model RandomForestEntr_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/RandomForestEntr_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model CatBoost_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model ExtraTreesGini_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/ExtraTreesGini_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model ExtraTreesEntr_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/ExtraTreesEntr_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetFastAI_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetFastAI_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model XGBoost_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/XGBoost_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetTorch_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBMLarge_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBMLarge_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model CatBoost_r177_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_r177_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetTorch_r79_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_r79_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBM_r131_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r131_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetFastAI_r191_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetFastAI_r191_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model CatBoost_r9_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_r9_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBM_r96_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r96_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetTorch_r22_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_r22_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model XGBoost_r33_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/XGBoost_r33_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model ExtraTrees_r42_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/ExtraTrees_r42_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model CatBoost_r137_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_r137_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetFastAI_r102_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetFastAI_r102_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model CatBoost_r13_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/CatBoost_r13_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model RandomForest_r195_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/RandomForest_r195_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBM_r188_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r188_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetFastAI_r145_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetFastAI_r145_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model XGBoost_r89_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/XGBoost_r89_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model NeuralNetTorch_r30_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/NeuralNetTorch_r30_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model LightGBM_r130_BAG_L1_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/LightGBM_r130_BAG_L1_PSEUDO will be removed.\n",
      "Deleting model WeightedEnsemble_L2_PSEUDO. All files under AutogluonModels/ag-20241102_083542/models/WeightedEnsemble_L2_PSEUDO will be removed.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241102_083542\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x798a9722f7c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_pseudolabel(\n",
    "    train_data=train,\n",
    "    pseudo_data=original,\n",
    "    time_limit=CFG.time_limit,\n",
    "    keep_only_best=True,\n",
    "    presets='best_quality',\n",
    "    ag_args_fit={\n",
    "#         'num_gpus': 1, \n",
    "        'num_cpus': 4\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32cc9344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T18:37:54.253742Z",
     "iopub.status.busy": "2024-11-02T18:37:54.251576Z",
     "iopub.status.idle": "2024-11-02T18:37:54.393905Z",
     "shell.execute_reply": "2024-11-02T18:37:54.392649Z"
    },
    "papermill": {
     "duration": 0.207471,
     "end_time": "2024-11-02T18:37:54.396908",
     "exception": false,
     "start_time": "2024-11-02T18:37:54.189437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c1a10_row0_col1 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_c1a10_row1_col1 {\n",
       "  background-color: #7fc866;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row2_col1 {\n",
       "  background-color: #82c966;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row3_col1 {\n",
       "  background-color: #a5d86a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row4_col1 {\n",
       "  background-color: #b7e075;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row5_col1 {\n",
       "  background-color: #bbe278;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row6_col1 {\n",
       "  background-color: #e2f397;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row7_col1 {\n",
       "  background-color: #fffebe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row8_col1 {\n",
       "  background-color: #fed27f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_c1a10_row9_col1 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c1a10\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c1a10_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_c1a10_level0_col1\" class=\"col_heading level0 col1\" >score_val</th>\n",
       "      <th id=\"T_c1a10_level0_col2\" class=\"col_heading level0 col2\" >eval_metric</th>\n",
       "      <th id=\"T_c1a10_level0_col3\" class=\"col_heading level0 col3\" >pred_time_val</th>\n",
       "      <th id=\"T_c1a10_level0_col4\" class=\"col_heading level0 col4\" >fit_time</th>\n",
       "      <th id=\"T_c1a10_level0_col5\" class=\"col_heading level0 col5\" >pred_time_val_marginal</th>\n",
       "      <th id=\"T_c1a10_level0_col6\" class=\"col_heading level0 col6\" >fit_time_marginal</th>\n",
       "      <th id=\"T_c1a10_level0_col7\" class=\"col_heading level0 col7\" >stack_level</th>\n",
       "      <th id=\"T_c1a10_level0_col8\" class=\"col_heading level0 col8\" >can_infer</th>\n",
       "      <th id=\"T_c1a10_level0_col9\" class=\"col_heading level0 col9\" >fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c1a10_row0_col0\" class=\"data row0 col0\" >WeightedEnsemble_L2</td>\n",
       "      <td id=\"T_c1a10_row0_col1\" class=\"data row0 col1\" >0.940924</td>\n",
       "      <td id=\"T_c1a10_row0_col2\" class=\"data row0 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row0_col3\" class=\"data row0 col3\" >20.438312</td>\n",
       "      <td id=\"T_c1a10_row0_col4\" class=\"data row0 col4\" >7924.355096</td>\n",
       "      <td id=\"T_c1a10_row0_col5\" class=\"data row0 col5\" >0.014924</td>\n",
       "      <td id=\"T_c1a10_row0_col6\" class=\"data row0 col6\" >7.383153</td>\n",
       "      <td id=\"T_c1a10_row0_col7\" class=\"data row0 col7\" >2</td>\n",
       "      <td id=\"T_c1a10_row0_col8\" class=\"data row0 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row0_col9\" class=\"data row0 col9\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c1a10_row1_col0\" class=\"data row1 col0\" >CatBoost_r177_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row1_col1\" class=\"data row1 col1\" >0.940028</td>\n",
       "      <td id=\"T_c1a10_row1_col2\" class=\"data row1 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row1_col3\" class=\"data row1 col3\" >0.363356</td>\n",
       "      <td id=\"T_c1a10_row1_col4\" class=\"data row1 col4\" >503.840276</td>\n",
       "      <td id=\"T_c1a10_row1_col5\" class=\"data row1 col5\" >0.363356</td>\n",
       "      <td id=\"T_c1a10_row1_col6\" class=\"data row1 col6\" >503.840276</td>\n",
       "      <td id=\"T_c1a10_row1_col7\" class=\"data row1 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row1_col8\" class=\"data row1 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row1_col9\" class=\"data row1 col9\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c1a10_row2_col0\" class=\"data row2 col0\" >NeuralNetFastAI_r191_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row2_col1\" class=\"data row2 col1\" >0.940014</td>\n",
       "      <td id=\"T_c1a10_row2_col2\" class=\"data row2 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row2_col3\" class=\"data row2 col3\" >5.347926</td>\n",
       "      <td id=\"T_c1a10_row2_col4\" class=\"data row2 col4\" >2516.121604</td>\n",
       "      <td id=\"T_c1a10_row2_col5\" class=\"data row2 col5\" >5.347926</td>\n",
       "      <td id=\"T_c1a10_row2_col6\" class=\"data row2 col6\" >2516.121604</td>\n",
       "      <td id=\"T_c1a10_row2_col7\" class=\"data row2 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row2_col8\" class=\"data row2 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row2_col9\" class=\"data row2 col9\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c1a10_row3_col0\" class=\"data row3 col0\" >XGBoost_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row3_col1\" class=\"data row3 col1\" >0.939801</td>\n",
       "      <td id=\"T_c1a10_row3_col2\" class=\"data row3 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row3_col3\" class=\"data row3 col3\" >1.025445</td>\n",
       "      <td id=\"T_c1a10_row3_col4\" class=\"data row3 col4\" >398.187296</td>\n",
       "      <td id=\"T_c1a10_row3_col5\" class=\"data row3 col5\" >1.025445</td>\n",
       "      <td id=\"T_c1a10_row3_col6\" class=\"data row3 col6\" >398.187296</td>\n",
       "      <td id=\"T_c1a10_row3_col7\" class=\"data row3 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row3_col8\" class=\"data row3 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row3_col9\" class=\"data row3 col9\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c1a10_row4_col0\" class=\"data row4 col0\" >CatBoost_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row4_col1\" class=\"data row4 col1\" >0.939680</td>\n",
       "      <td id=\"T_c1a10_row4_col2\" class=\"data row4 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row4_col3\" class=\"data row4 col3\" >0.370881</td>\n",
       "      <td id=\"T_c1a10_row4_col4\" class=\"data row4 col4\" >581.392864</td>\n",
       "      <td id=\"T_c1a10_row4_col5\" class=\"data row4 col5\" >0.370881</td>\n",
       "      <td id=\"T_c1a10_row4_col6\" class=\"data row4 col6\" >581.392864</td>\n",
       "      <td id=\"T_c1a10_row4_col7\" class=\"data row4 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row4_col8\" class=\"data row4 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row4_col9\" class=\"data row4 col9\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c1a10_row5_col0\" class=\"data row5 col0\" >LightGBMXT_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row5_col1\" class=\"data row5 col1\" >0.939645</td>\n",
       "      <td id=\"T_c1a10_row5_col2\" class=\"data row5 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row5_col3\" class=\"data row5 col3\" >0.808687</td>\n",
       "      <td id=\"T_c1a10_row5_col4\" class=\"data row5 col4\" >71.244358</td>\n",
       "      <td id=\"T_c1a10_row5_col5\" class=\"data row5 col5\" >0.808687</td>\n",
       "      <td id=\"T_c1a10_row5_col6\" class=\"data row5 col6\" >71.244358</td>\n",
       "      <td id=\"T_c1a10_row5_col7\" class=\"data row5 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row5_col8\" class=\"data row5 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row5_col9\" class=\"data row5 col9\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c1a10_row6_col0\" class=\"data row6 col0\" >NeuralNetTorch_r79_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row6_col1\" class=\"data row6 col1\" >0.939339</td>\n",
       "      <td id=\"T_c1a10_row6_col2\" class=\"data row6 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row6_col3\" class=\"data row6 col3\" >1.256872</td>\n",
       "      <td id=\"T_c1a10_row6_col4\" class=\"data row6 col4\" >1199.607165</td>\n",
       "      <td id=\"T_c1a10_row6_col5\" class=\"data row6 col5\" >1.256872</td>\n",
       "      <td id=\"T_c1a10_row6_col6\" class=\"data row6 col6\" >1199.607165</td>\n",
       "      <td id=\"T_c1a10_row6_col7\" class=\"data row6 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row6_col8\" class=\"data row6 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row6_col9\" class=\"data row6 col9\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c1a10_row7_col0\" class=\"data row7 col0\" >NeuralNetFastAI_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row7_col1\" class=\"data row7 col1\" >0.939048</td>\n",
       "      <td id=\"T_c1a10_row7_col2\" class=\"data row7 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row7_col3\" class=\"data row7 col3\" >3.815850</td>\n",
       "      <td id=\"T_c1a10_row7_col4\" class=\"data row7 col4\" >1762.468336</td>\n",
       "      <td id=\"T_c1a10_row7_col5\" class=\"data row7 col5\" >3.815850</td>\n",
       "      <td id=\"T_c1a10_row7_col6\" class=\"data row7 col6\" >1762.468336</td>\n",
       "      <td id=\"T_c1a10_row7_col7\" class=\"data row7 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row7_col8\" class=\"data row7 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row7_col9\" class=\"data row7 col9\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c1a10_row8_col0\" class=\"data row8 col0\" >NeuralNetTorch_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row8_col1\" class=\"data row8 col1\" >0.938571</td>\n",
       "      <td id=\"T_c1a10_row8_col2\" class=\"data row8 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row8_col3\" class=\"data row8 col3\" >1.095546</td>\n",
       "      <td id=\"T_c1a10_row8_col4\" class=\"data row8 col4\" >848.375237</td>\n",
       "      <td id=\"T_c1a10_row8_col5\" class=\"data row8 col5\" >1.095546</td>\n",
       "      <td id=\"T_c1a10_row8_col6\" class=\"data row8 col6\" >848.375237</td>\n",
       "      <td id=\"T_c1a10_row8_col7\" class=\"data row8 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row8_col8\" class=\"data row8 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row8_col9\" class=\"data row8 col9\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c1a10_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c1a10_row9_col0\" class=\"data row9 col0\" >RandomForestGini_BAG_L1</td>\n",
       "      <td id=\"T_c1a10_row9_col1\" class=\"data row9 col1\" >0.937178</td>\n",
       "      <td id=\"T_c1a10_row9_col2\" class=\"data row9 col2\" >accuracy</td>\n",
       "      <td id=\"T_c1a10_row9_col3\" class=\"data row9 col3\" >6.338826</td>\n",
       "      <td id=\"T_c1a10_row9_col4\" class=\"data row9 col4\" >35.734806</td>\n",
       "      <td id=\"T_c1a10_row9_col5\" class=\"data row9 col5\" >6.338826</td>\n",
       "      <td id=\"T_c1a10_row9_col6\" class=\"data row9 col6\" >35.734806</td>\n",
       "      <td id=\"T_c1a10_row9_col7\" class=\"data row9 col7\" >1</td>\n",
       "      <td id=\"T_c1a10_row9_col8\" class=\"data row9 col8\" >True</td>\n",
       "      <td id=\"T_c1a10_row9_col9\" class=\"data row9 col9\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x798ab5b8c040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent=True).style.background_gradient(subset=['score_val'], cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed28aa",
   "metadata": {
    "papermill": {
     "duration": 0.060081,
     "end_time": "2024-11-02T18:37:54.516073",
     "exception": false,
     "start_time": "2024-11-02T18:37:54.455992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bce0b5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T18:37:54.638632Z",
     "iopub.status.busy": "2024-11-02T18:37:54.637646Z",
     "iopub.status.idle": "2024-11-02T18:39:16.934829Z",
     "shell.execute_reply": "2024-11-02T18:39:16.933714Z"
    },
    "papermill": {
     "duration": 82.420145,
     "end_time": "2024-11-02T18:39:16.997078",
     "exception": false,
     "start_time": "2024-11-02T18:37:54.576933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93795</th>\n",
       "      <td>234495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93796</th>\n",
       "      <td>234496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93797</th>\n",
       "      <td>234497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93798</th>\n",
       "      <td>234498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93799</th>\n",
       "      <td>234499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Depression\n",
       "0      140700           0\n",
       "1      140701           0\n",
       "2      140702           0\n",
       "3      140703           1\n",
       "4      140704           0\n",
       "...       ...         ...\n",
       "93795  234495           0\n",
       "93796  234496           1\n",
       "93797  234497           0\n",
       "93798  234498           1\n",
       "93799  234499           0\n",
       "\n",
       "[93800 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(CFG.sample_sub_path)\n",
    "sub[CFG.target] = predictor.predict(test).values\n",
    "sub.to_csv('sub_autogluon.csv', index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30bf5093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T18:39:17.391500Z",
     "iopub.status.busy": "2024-11-02T18:39:17.391024Z",
     "iopub.status.idle": "2024-11-02T18:39:17.493512Z",
     "shell.execute_reply": "2024-11-02T18:39:17.492162Z"
    },
    "papermill": {
     "duration": 0.16874,
     "end_time": "2024-11-02T18:39:17.496918",
     "exception": false,
     "start_time": "2024-11-02T18:39:17.328178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"AutogluonModels\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10008389,
     "sourceId": 84895,
     "sourceType": "competition"
    },
    {
     "datasetId": 5868381,
     "sourceId": 9616093,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36284.321416,
   "end_time": "2024-11-02T18:39:22.789649",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-02T08:34:38.468233",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
