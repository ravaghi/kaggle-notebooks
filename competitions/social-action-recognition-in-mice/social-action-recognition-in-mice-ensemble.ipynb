{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158b9bd8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.009196,
     "end_time": "2025-11-16T09:11:51.244933",
     "exception": false,
     "start_time": "2025-11-16T09:11:51.235737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**References**\n",
    "- [MABe Nearest Neighbors: The Original ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/code/ambrosm/mabe-nearest-neighbors-the-original)\n",
    "- [MABe EDA which makes sense ⭐️⭐️⭐️⭐️⭐️](https://www.kaggle.com/code/ambrosm/mabe-eda-which-makes-sense)\n",
    "- [MABe Validated baseline without machine learning](https://www.kaggle.com/code/ambrosm/mabe-validated-baseline-without-machine-learning)\n",
    "- [Squeeze GBT](https://www.kaggle.com/code/cody11null/squeeze-gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db38176",
   "metadata": {
    "papermill": {
     "duration": 0.006856,
     "end_time": "2025-11-16T09:11:51.259510",
     "exception": false,
     "start_time": "2025-11-16T09:11:51.252654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ad450e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-11-16T09:11:51.275096Z",
     "iopub.status.busy": "2025-11-16T09:11:51.274654Z",
     "iopub.status.idle": "2025-11-16T09:11:54.118592Z",
     "shell.execute_reply": "2025-11-16T09:11:54.117526Z"
    },
    "papermill": {
     "duration": 2.854335,
     "end_time": "2025-11-16T09:11:54.120376",
     "exception": false,
     "start_time": "2025-11-16T09:11:51.266041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"F Beta customized for the data format of the MABe challenge.\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels))\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                continue\n",
    "\n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "\n",
    "    tps = defaultdict(int)\n",
    "    fns = defaultdict(int)\n",
    "    fps = defaultdict(int)\n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    Doctests:\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 0, 'stop_frame': 10}, # Wrong action\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    0.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
    "    ... ])\n",
    "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
    "    '0.500000000000'\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
    "    ... ])\n",
    "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
    "    '0.250000000000'\n",
    "\n",
    "    >>> # Overlapping solution events, one prediction matching both.\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 10, 'stop_frame': 20, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 20},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 30, 'stop_frame': 40, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 40},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    0.6666666666666666\n",
    "    \"\"\"\n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F1 score for the MABe Challenge\n",
    "    \"\"\"\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa655c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:11:54.135850Z",
     "iopub.status.busy": "2025-11-16T09:11:54.135340Z",
     "iopub.status.idle": "2025-11-16T09:11:56.808159Z",
     "shell.execute_reply": "2025-11-16T09:11:56.806664Z"
    },
    "papermill": {
     "duration": 2.682902,
     "end_time": "2025-11-16T09:11:56.810321",
     "exception": false,
     "start_time": "2025-11-16T09:11:54.127419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.base import clone\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "from koolbox import Trainer\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "import optuna\n",
    "import joblib\n",
    "import glob\n",
    "import gc\n",
    "import os\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a90f4a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:11:56.825992Z",
     "iopub.status.busy": "2025-11-16T09:11:56.825543Z",
     "iopub.status.idle": "2025-11-16T09:11:56.830917Z",
     "shell.execute_reply": "2025-11-16T09:11:56.830054Z"
    },
    "papermill": {
     "duration": 0.015282,
     "end_time": "2025-11-16T09:11:56.832677",
     "exception": false,
     "start_time": "2025-11-16T09:11:56.817395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    train_path = \"/kaggle/input/MABe-mouse-behavior-detection/train.csv\"\n",
    "    test_path = \"/kaggle/input/MABe-mouse-behavior-detection/test.csv\"\n",
    "    train_annotation_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_annotation\"\n",
    "    train_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_tracking\"\n",
    "    test_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/test_tracking\"\n",
    "\n",
    "    model_path = \"/kaggle/input/social-action-recognition-in-mice-xgb-catboost\"\n",
    "    \n",
    "    mode = \"validate\"\n",
    "    # mode = \"submit\"\n",
    "    \n",
    "    n_splits = 3\n",
    "    cv = StratifiedGroupKFold(n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade380d0",
   "metadata": {
    "papermill": {
     "duration": 0.006553,
     "end_time": "2025-11-16T09:11:56.845935",
     "exception": false,
     "start_time": "2025-11-16T09:11:56.839382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1734bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:11:56.861761Z",
     "iopub.status.busy": "2025-11-16T09:11:56.861011Z",
     "iopub.status.idle": "2025-11-16T09:11:57.202675Z",
     "shell.execute_reply": "2025-11-16T09:11:57.201278Z"
    },
    "papermill": {
     "duration": 0.352263,
     "end_time": "2025-11-16T09:11:57.205051",
     "exception": false,
     "start_time": "2025-11-16T09:11:56.852788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(CFG.train_path)\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "train_without_mabe22 = train.query(\"~lab_id.str.startswith('MABe22_')\")\n",
    "\n",
    "test = pd.read_csv(CFG.test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf15316f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:11:57.222501Z",
     "iopub.status.busy": "2025-11-16T09:11:57.221765Z",
     "iopub.status.idle": "2025-11-16T09:11:57.231129Z",
     "shell.execute_reply": "2025-11-16T09:11:57.230091Z"
    },
    "papermill": {
     "duration": 0.020225,
     "end_time": "2025-11-16T09:11:57.232889",
     "exception": false,
     "start_time": "2025-11-16T09:11:57.212664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8926a",
   "metadata": {
    "papermill": {
     "duration": 0.007445,
     "end_time": "2025-11-16T09:11:57.248198",
     "exception": false,
     "start_time": "2025-11-16T09:11:57.240753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating solution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b0678a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:11:57.263424Z",
     "iopub.status.busy": "2025-11-16T09:11:57.263084Z",
     "iopub.status.idle": "2025-11-16T09:12:10.762686Z",
     "shell.execute_reply": "2025-11-16T09:12:10.761602Z"
    },
    "papermill": {
     "duration": 13.509756,
     "end_time": "2025-11-16T09:12:10.764755",
     "exception": false,
     "start_time": "2025-11-16T09:11:57.254999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254b19634b694817962031e5a60113c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_solution_df(dataset):\n",
    "    solution = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "    \n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'): \n",
    "            continue\n",
    "        \n",
    "        video_id = row['video_id']\n",
    "        path = f\"{CFG.train_annotation_path}/{lab_id}/{video_id}.parquet\"\n",
    "        try:\n",
    "            annot = pd.read_parquet(path)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    \n",
    "        annot['lab_id'] = lab_id\n",
    "        annot['video_id'] = video_id\n",
    "        annot['behaviors_labeled'] = row['behaviors_labeled']\n",
    "        annot['target_id'] = np.where(annot.target_id != annot.agent_id, annot['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n",
    "        annot['agent_id'] = annot['agent_id'].apply(lambda s: f\"mouse{s}\")\n",
    "        solution.append(annot)\n",
    "    \n",
    "    solution = pd.concat(solution)\n",
    "    \n",
    "    return solution\n",
    "\n",
    "if CFG.mode == 'validate':\n",
    "    solution = create_solution_df(train_without_mabe22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a899da6",
   "metadata": {
    "papermill": {
     "duration": 0.007002,
     "end_time": "2025-11-16T09:12:10.778899",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.771897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3b58be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:10.795780Z",
     "iopub.status.busy": "2025-11-16T09:12:10.795332Z",
     "iopub.status.idle": "2025-11-16T09:12:10.812906Z",
     "shell.execute_reply": "2025-11-16T09:12:10.811796Z"
    },
    "papermill": {
     "duration": 0.02876,
     "end_time": "2025-11-16T09:12:10.814635",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.785875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_body_parts =  [\n",
    "    'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "    'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n",
    "    'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
    "]\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "        \n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id = row.lab_id\n",
    "        if lab_id.startswith('MABe22') or type(row.behaviors_labeled) != str: \n",
    "            continue\n",
    "        \n",
    "        video_id = row.video_id\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "        \n",
    "        del vid\n",
    "        gc.collect()\n",
    "        \n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "        pvid /= row.pix_per_cm_approx\n",
    "\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "        \n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n",
    "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id]\n",
    "                    assert len(single_mouse) == len(pvid)\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2): # int8\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n",
    "                    assert len(mouse_pair) == len(pvid)\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b77e97",
   "metadata": {
    "papermill": {
     "duration": 0.006851,
     "end_time": "2025-11-16T09:12:10.828712",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.821861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transforming coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed33eca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:10.845171Z",
     "iopub.status.busy": "2025-11-16T09:12:10.844732Z",
     "iopub.status.idle": "2025-11-16T09:12:10.872885Z",
     "shell.execute_reply": "2025-11-16T09:12:10.871848Z"
    },
    "papermill": {
     "duration": 0.038296,
     "end_time": "2025-11-16T09:12:10.874481",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.836185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_rolling(series, window, func, min_periods=None):\n",
    "    if min_periods is None:\n",
    "        min_periods = max(1, window // 4)\n",
    "    return series.rolling(window, min_periods=min_periods, center=True).apply(func, raw=True)\n",
    "\n",
    "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
    "    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n",
    "\n",
    "def _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n",
    "    if n_frames_at_30fps == 0:\n",
    "        return 0\n",
    "    s = 1 if n_frames_at_30fps > 0 else -1\n",
    "    mag = max(1, int(round(abs(n_frames_at_30fps) * float(fps) / ref)))\n",
    "    return s * mag\n",
    "\n",
    "def _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n",
    "    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n",
    "        return float(meta_df['frames_per_second'].iloc[0])\n",
    "    vid = meta_df['video_id'].iloc[0]\n",
    "    return float(fallback_lookup.get(vid, default_fps))\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y, fps):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "\n",
    "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
    "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n",
    "\n",
    "    for w in [25, 50, 75]:\n",
    "        ws = _scale(w, fps)\n",
    "        X[f'curv_mean_{w}'] = curvature.rolling(ws, min_periods=max(1, ws // 5)).mean()\n",
    "\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "\n",
    "    scales = [20, 40, 60, 80]\n",
    "    for scale in scales:\n",
    "        ws = _scale(scale, fps)\n",
    "        if len(speed) >= ws:\n",
    "            X[f'sp_m{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).mean()\n",
    "            X[f'sp_s{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).std()\n",
    "\n",
    "    if len(scales) >= 2 and f'sp_m{scales[0]}' in X.columns and f'sp_m{scales[-1]}' in X.columns:\n",
    "        X['sp_ratio'] = X[f'sp_m{scales[0]}'] / (X[f'sp_m{scales[-1]}'] + 1e-6)\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "    w_ma = _scale(15, fps)\n",
    "    speed_ma = speed.rolling(w_ma, min_periods=max(1, w_ma // 3)).mean()\n",
    "\n",
    "    try:\n",
    "        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n",
    "        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "        for window in [20, 40, 60, 80]:\n",
    "            ws = _scale(window, fps)\n",
    "            if len(speed_states) >= ws:\n",
    "                for state in [0, 1, 2, 3]:\n",
    "                    X[f's{state}_{window}'] = (\n",
    "                        (speed_states == state).astype(float)\n",
    "                        .rolling(ws, min_periods=max(1, ws // 5)).mean()\n",
    "                    )\n",
    "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "                X[f'trans_{window}'] = state_changes.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y, fps):\n",
    "    for window in [30, 60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(center_x) >= ws:\n",
    "            X[f'x_ml{window}'] = center_x.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "            X[f'y_ml{window}'] = center_y.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "\n",
    "    for span in [30, 60, 120]:\n",
    "        s = _scale(span, fps)\n",
    "        X[f'x_e{span}'] = center_x.ewm(span=s, min_periods=1).mean()\n",
    "        X[f'y_e{span}'] = center_y.ewm(span=s, min_periods=1).mean()\n",
    "\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)  # cm/s\n",
    "    for window in [30, 60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(speed) >= ws:\n",
    "            X[f'sp_pct{window}'] = speed.rolling(ws, min_periods=max(5, ws // 6)).rank(pct=True)\n",
    "\n",
    "    return X\n",
    "\n",
    "def add_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "\n",
    "    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n",
    "    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n",
    "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
    "\n",
    "    A_vx = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vy = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vx = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vy = mouse_pair['B']['body_center']['y'].diff()\n",
    "\n",
    "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
    "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
    "\n",
    "    for window in [30, 60]:\n",
    "        ws = _scale(window, fps)\n",
    "        X[f'A_ld{window}'] = A_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "        X[f'B_ld{window}'] = B_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "\n",
    "    approach = -rel_dist.diff()\n",
    "    chase = approach * B_lead\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'chase_{w}'] = chase.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "\n",
    "    for window in [60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        A_sp = np.sqrt(A_vx**2 + A_vy**2)\n",
    "        B_sp = np.sqrt(B_vx**2 + B_vy**2)\n",
    "        X[f'sp_cor{window}'] = A_sp.rolling(ws, min_periods=max(1, ws // 6)).corr(B_sp)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4067ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:10.891334Z",
     "iopub.status.busy": "2025-11-16T09:12:10.890941Z",
     "iopub.status.idle": "2025-11-16T09:12:10.931741Z",
     "shell.execute_reply": "2025-11-16T09:12:10.930696Z"
    },
    "papermill": {
     "duration": 0.051543,
     "end_time": "2025-11-16T09:12:10.933600",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.882057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_single(single_mouse, body_parts_tracked, fps):\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "        lag = _scale(10, fps)\n",
    "        shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_lf': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "            'sp_rt': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "            'sp_lf2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            'sp_rt2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
    "\n",
    "    if 'body_center' in available_body_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n",
    "            X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n",
    "            X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n",
    "            X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n",
    "            X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n",
    "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).sum()**2 +\n",
    "                                     cy.diff().rolling(ws, min_periods=1).sum()**2)\n",
    "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).var() +\n",
    "                                   cy.diff().rolling(ws, min_periods=1).var())\n",
    "\n",
    "        X = add_curvature_features(X, cx, cy, fps)\n",
    "        X = add_multiscale_features(X, cx, cy, fps)\n",
    "        X = add_state_features(X, cx, cy, fps)\n",
    "        X = add_longrange_features(X, cx, cy, fps)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                          (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nt_lg{lag}'] = nt_dist.shift(l)\n",
    "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "        for off in [-30, -20, -10, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-o)\n",
    "        w = _scale(30, fps)\n",
    "        X['ear_con'] = ear_d.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked, fps):\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        lag = _scale(10, fps)\n",
    "        shA = mouse_pair['A']['ear_left'].shift(lag)\n",
    "        shB = mouse_pair['B']['ear_left'].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_A': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "            'sp_AB': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "            'sp_B': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
    "\n",
    "    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "        lag = _scale(10, fps)\n",
    "        shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "        shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "        past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "        X['appr'] = cur - past\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                     (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        X['v_cls'] = (cd < 5.0).astype(float)\n",
    "        X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n",
    "        X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
    "        X['far']   = (cd >= 30.0).astype(float)\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n",
    "            X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n",
    "            X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n",
    "            X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n",
    "\n",
    "            d_var = cd_full.rolling(ws, **roll).var()\n",
    "            X[f'int{w}'] = 1 / (1 + d_var)\n",
    "\n",
    "            Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "            Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "            Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "            Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n",
    "            X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n",
    "\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                     (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nn_lg{lag}']  = nn.shift(l)\n",
    "            X[f'nn_ch{lag}']  = nn - nn.shift(l)\n",
    "            is_cl = (nn < 10.0).astype(float)\n",
    "            X[f'cl_ps{lag}']  = is_cl.rolling(l, min_periods=1).mean()\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        Avx = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Avy = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bvx = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Bvy = mouse_pair['B']['body_center']['y'].diff()\n",
    "        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n",
    "\n",
    "        for off in [-30, -20, -10, 0, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'va_{off}'] = val.shift(-o)\n",
    "\n",
    "        w = _scale(30, fps)\n",
    "        X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f6f5a",
   "metadata": {
    "papermill": {
     "duration": 0.007004,
     "end_time": "2025-11-16T09:12:10.947861",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.940857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training, validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af24d12",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:10.963990Z",
     "iopub.status.busy": "2025-11-16T09:12:10.963669Z",
     "iopub.status.idle": "2025-11-16T09:12:10.977221Z",
     "shell.execute_reply": "2025-11-16T09:12:10.975939Z"
    },
    "papermill": {
     "duration": 0.024119,
     "end_time": "2025-11-16T09:12:10.978963",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.954844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def robustify(submission, dataset, traintest, traintest_directory=None):\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "\n",
    "    old_submission = submission.copy()\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped frames with start >= stop\")\n",
    "    \n",
    "    old_submission = submission.copy()\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop_frame = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row['start_frame'] < last_stop_frame:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop_frame = row['stop_frame']\n",
    "        group_list.append(group[mask])\n",
    "        \n",
    "    submission = pd.concat(group_list)\n",
    "    \n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped duplicate frames\")\n",
    "        \n",
    "    s_list = []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        \n",
    "        video_id = row['video_id']\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue\n",
    "        \n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            continue\n",
    "\n",
    "        print(f\"Video {video_id} has no predictions.\")\n",
    "        \n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "    \n",
    "        vid_behaviors = json.loads(row['behaviors_labeled'])\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "    \n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "    \n",
    "        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
    "            batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_length\n",
    "                batch_stop = min(batch_start + batch_length, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "    if len(s_list) > 0:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
    "        ])\n",
    "        print(\"ERROR: Filled empty videos\")\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9ea24d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:10.994880Z",
     "iopub.status.busy": "2025-11-16T09:12:10.994576Z",
     "iopub.status.idle": "2025-11-16T09:12:11.005595Z",
     "shell.execute_reply": "2025-11-16T09:12:11.004213Z"
    },
    "papermill": {
     "duration": 0.020952,
     "end_time": "2025-11-16T09:12:11.007360",
     "exception": false,
     "start_time": "2025-11-16T09:12:10.986408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_multiclass(pred, meta, thresholds):\n",
    "    ama = np.argmax(pred.values, axis=1)\n",
    "    max_proba = pred.max(axis=1).values\n",
    "\n",
    "    threshold_array = np.array([thresholds.get(col, 0.27) for col in pred.columns])\n",
    "    action_thresholds = threshold_array[ama]\n",
    "\n",
    "    ama = np.where(max_proba >= action_thresholds, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame)\n",
    "    \n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    \n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "    \n",
    "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
    "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
    "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
    "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "\n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb00178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:11.023733Z",
     "iopub.status.busy": "2025-11-16T09:12:11.022866Z",
     "iopub.status.idle": "2025-11-16T09:12:11.031183Z",
     "shell.execute_reply": "2025-11-16T09:12:11.030133Z"
    },
    "papermill": {
     "duration": 0.018363,
     "end_time": "2025-11-16T09:12:11.032943",
     "exception": false,
     "start_time": "2025-11-16T09:12:11.014580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_ensemble_predictions(oof_pred_probs, y_action):\n",
    "    def objective(trial):\n",
    "        weights = [trial.suggest_float(model, -1, 1) for model in oof_pred_probs.keys()]\n",
    "        weights /= np.sum(weights)\n",
    "    \n",
    "        pred_probs = np.zeros((oof_pred_probs[list(oof_pred_probs.keys())[0]].shape[0], ))\n",
    "        for model, weight in zip(oof_pred_probs.keys(), weights):\n",
    "            pred_probs += oof_pred_probs[model] * weight\n",
    "        \n",
    "        threshold = trial.suggest_float(\"threshold\", 0, 1)\n",
    "        return f1_score(y_action, pred_probs >= threshold, zero_division=0)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=1000, n_jobs=-1)\n",
    "\n",
    "    best_weights = [study.best_params[model] for model in oof_pred_probs.keys()]\n",
    "    best_weights /= np.sum(best_weights)\n",
    "    \n",
    "    return {\n",
    "        \"threshold\": study.best_params[\"threshold\"],\n",
    "        \"weight\": best_weights\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263eef41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:11.048934Z",
     "iopub.status.busy": "2025-11-16T09:12:11.048633Z",
     "iopub.status.idle": "2025-11-16T09:12:11.061224Z",
     "shell.execute_reply": "2025-11-16T09:12:11.060122Z"
    },
    "papermill": {
     "duration": 0.022664,
     "end_time": "2025-11-16T09:12:11.062986",
     "exception": false,
     "start_time": "2025-11-16T09:12:11.040322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate_classifier(X, label, meta, body_parts_tracked_str, section):\n",
    "    oof = pd.DataFrame(index=meta.video_frame)\n",
    "    \n",
    "    f1_list = []\n",
    "    submission_list = []\n",
    "    thresholds = {}\n",
    "    weights = {}\n",
    "    \n",
    "    for action in label.columns:\n",
    "        action_mask = ~ label[action].isna().values\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        X_action = X[action_mask]\n",
    "        groups_action = meta.video_id[action_mask]\n",
    "        \n",
    "        if len(np.unique(groups_action)) < CFG.n_splits:\n",
    "            continue\n",
    "\n",
    "        if not (y_action == 0).all():\n",
    "            try:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "                    \n",
    "                    model_names = [\n",
    "                        \"catboost\",\n",
    "                        \"xgboost\",\n",
    "                        \"xgboost-2\",\n",
    "                    ]\n",
    "                    \n",
    "                    oof_pred_probs = {}\n",
    "                    for model_name in model_names:\n",
    "                        oof_pred_probs[model_name] = joblib.load(f\"{CFG.model_path}/{model_name}/{section}/{action}/oof_pred_probs.pkl\")\n",
    "                    \n",
    "                    res = optimize_ensemble_predictions(oof_pred_probs, y_action)\n",
    "                    \n",
    "                    oof_action = np.zeros((oof_pred_probs[list(oof_pred_probs.keys())[0]].shape[0], ))\n",
    "                    for model, weight in zip(oof_pred_probs.keys(), res[\"weight\"]):\n",
    "                        oof_action += oof_pred_probs[model] * weight\n",
    "\n",
    "                    threshold = res[\"threshold\"]\n",
    "                    weights[action] = res[\"weight\"]\n",
    "                    thresholds[action] = threshold\n",
    "            \n",
    "                    f1 = f1_score(y_action, (oof_action >= threshold), zero_division=0)\n",
    "                    f1_list.append((body_parts_tracked_str, action, f1))\n",
    "                    \n",
    "                    print(f\"\\tF1: {f1:.4f} ({threshold:.2f}) Section: {section} Action: {action}\")\n",
    "    \n",
    "                    del oof_pred_probs, res, threshold\n",
    "                    gc.collect()\n",
    "\n",
    "            except Exception as e:\n",
    "                oof_action = np.zeros(len(y_action))\n",
    "                print(f\"\\tF1: 0.0000 (0.00) Section: {section} Action: {action}\")\n",
    "        \n",
    "        else:\n",
    "            oof_action = np.zeros(len(y_action))\n",
    "            print(f\"\\tF1: 0.0000 (0.00) Section: {section} Action: {action}\")\n",
    "        \n",
    "        oof_column = np.zeros(len(label))\n",
    "        oof_column[action_mask] = oof_action\n",
    "        oof[action] = oof_column\n",
    "\n",
    "        del oof_action, action_mask, X_action, y_action, groups_action\n",
    "        gc.collect()\n",
    "\n",
    "    submission_part = predict_multiclass(oof, meta, thresholds)\n",
    "    submission_list.append(submission_part)\n",
    "    \n",
    "    return submission_list, f1_list, thresholds, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9335f5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:11.079612Z",
     "iopub.status.busy": "2025-11-16T09:12:11.079276Z",
     "iopub.status.idle": "2025-11-16T09:12:11.090876Z",
     "shell.execute_reply": "2025-11-16T09:12:11.089816Z"
    },
    "papermill": {
     "duration": 0.02226,
     "end_time": "2025-11-16T09:12:11.092668",
     "exception": false,
     "start_time": "2025-11-16T09:12:11.070408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(body_parts_tracked_str, switch_tr, section, thresholds, weights):    \n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "        \n",
    "    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "    generator = generate_mouse_data(\n",
    "        test_subset, \n",
    "        'test',\n",
    "        generate_single=(switch_tr == 'single'), \n",
    "        generate_pair=(switch_tr == 'pair')\n",
    "    )\n",
    "\n",
    "    fps_lookup = (\n",
    "        test_subset[['video_id', 'frames_per_second']]\n",
    "        .drop_duplicates('video_id')\n",
    "        .set_index('video_id')['frames_per_second']\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    submission_list = []\n",
    "    for switch_te, data_te, meta_te, actions_te in generator:\n",
    "        assert switch_te == switch_tr\n",
    "        try:\n",
    "            fps_i = _fps_from_meta(meta_te, fps_lookup, default_fps=30.0)\n",
    "            \n",
    "            if switch_te == 'single':\n",
    "                X_te = transform_single(data_te, body_parts_tracked, fps_i)\n",
    "            else:\n",
    "                X_te = transform_pair(data_te, body_parts_tracked, fps_i)\n",
    "            del data_te\n",
    "            gc.collect()\n",
    "    \n",
    "            pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "            for action in actions_te:\n",
    "                cb_trainer_filenames = glob.glob(f\"{CFG.model_path}/catboost/{section}/{action}/*_trainer_*.pkl\")\n",
    "                xgb_trainer_filenames = glob.glob(f\"{CFG.model_path}/xgboost/{section}/{action}/*_trainer_*.pkl\")\n",
    "                xgb2_trainer_filenames = glob.glob(f\"{CFG.model_path}/xgboost-2/{section}/{action}/*_trainer_*.pkl\")\n",
    "\n",
    "                if len(xgb_trainer_filenames) == 1:\n",
    "                    cb_trainer = joblib.load(cb_trainer_filenames[0])\n",
    "                    xgb_trainer = joblib.load(xgb_trainer_filenames[0])\n",
    "                    xgb2_trainer = joblib.load(xgb2_trainer_filenames[0])\n",
    "\n",
    "                    temp_preds = np.zeros((X_te.shape[0], ))\n",
    "                    temp_preds += cb_trainer.predict(X_te) * weights[action][0]\n",
    "                    temp_preds += xgb_trainer.predict(X_te) * weights[action][1]\n",
    "                    temp_preds += xgb2_trainer.predict(X_te) * weights[action][2]\n",
    "                        \n",
    "                    pred[action] = temp_preds\n",
    "                \n",
    "                    del cb_trainer, xgb_trainer, xgb2_trainer\n",
    "                    gc.collect()\n",
    "                \n",
    "            del X_te\n",
    "            gc.collect()\n",
    "\n",
    "            if pred.shape[1] != 0:\n",
    "                submission_part = predict_multiclass(pred, meta_te, thresholds)\n",
    "                submission_list.append(submission_part)\n",
    "                \n",
    "        except KeyError:\n",
    "            del data_te\n",
    "            gc.collect()\n",
    "            \n",
    "    return submission_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab8b356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:11.108939Z",
     "iopub.status.busy": "2025-11-16T09:12:11.108599Z",
     "iopub.status.idle": "2025-11-16T09:12:11.114927Z",
     "shell.execute_reply": "2025-11-16T09:12:11.113652Z"
    },
    "papermill": {
     "duration": 0.016667,
     "end_time": "2025-11-16T09:12:11.116807",
     "exception": false,
     "start_time": "2025-11-16T09:12:11.100140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.mode == \"validate\":\n",
    "    thresholds = {\n",
    "        \"single\": {},\n",
    "        \"pair\": {}\n",
    "    }\n",
    "    weights = {\n",
    "        \"single\": {},\n",
    "        \"pair\": {}\n",
    "    }\n",
    "else:\n",
    "    thresholds = joblib.load(f\"{CFG.model_path}/ensemble/thresholds.pkl\")\n",
    "    weights = joblib.load(f\"{CFG.model_path}/ensemble/weights.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d856bd56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T09:12:11.133457Z",
     "iopub.status.busy": "2025-11-16T09:12:11.133133Z",
     "iopub.status.idle": "2025-11-16T13:00:47.693153Z",
     "shell.execute_reply": "2025-11-16T13:00:47.692070Z"
    },
    "papermill": {
     "duration": 13716.572236,
     "end_time": "2025-11-16T13:00:47.696594",
     "exception": false,
     "start_time": "2025-11-16T09:12:11.124358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', 'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "\tF1: 0.5232 (0.21) Section: 1 Action: rear\n",
      "\tF1: 0.3886 (0.11) Section: 1 Action: approach\n",
      "\tF1: 0.4293 (0.06) Section: 1 Action: attack\n",
      "\tF1: 0.4526 (0.19) Section: 1 Action: avoid\n",
      "\tF1: 0.4905 (0.09) Section: 1 Action: chase\n",
      "\tF1: 0.5204 (0.13) Section: 1 Action: chaseattack\n",
      "\tF1: 0.1722 (0.03) Section: 1 Action: submit\n",
      "\n",
      "2/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'hip_left', 'hip_right', 'lateral_left', 'lateral_right', 'nose', 'spine_1', 'spine_2', 'tail_base', 'tail_middle_1', 'tail_middle_2', 'tail_tip']\n",
      "\n",
      "\tF1: 0.6687 (0.19) Section: 2 Action: huddle\n",
      "\tF1: 0.0000 (0.00) Section: 2 Action: rear\n",
      "\tF1: 0.0000 (0.00) Section: 2 Action: selfgroom\n",
      "\tF1: 0.6168 (0.27) Section: 2 Action: reciprocalsniff\n",
      "\tF1: 0.0000 (0.00) Section: 2 Action: sniff\n",
      "\tF1: 0.5334 (0.28) Section: 2 Action: sniffgenital\n",
      "\tF1: 0.0000 (0.00) Section: 2 Action: intromit\n",
      "\tF1: 0.0000 (0.00) Section: 2 Action: mount\n",
      "\n",
      "3/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "\tF1: 0.4792 (0.15) Section: 3 Action: rear\n",
      "\tF1: 0.2019 (0.09) Section: 3 Action: approach\n",
      "\tF1: 0.1777 (0.06) Section: 3 Action: attack\n",
      "\tF1: 0.1881 (0.05) Section: 3 Action: avoid\n",
      "\tF1: 0.0344 (0.02) Section: 3 Action: chase\n",
      "\tF1: 0.0638 (0.02) Section: 3 Action: chaseattack\n",
      "\tF1: 0.1487 (0.03) Section: 3 Action: submit\n",
      "\n",
      "4/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "\tF1: 0.3542 (0.12) Section: 4 Action: attack\n",
      "\tF1: 0.6473 (0.17) Section: 4 Action: dominance\n",
      "\tF1: 0.4866 (0.13) Section: 4 Action: sniff\n",
      "\tF1: 0.1363 (0.02) Section: 4 Action: chase\n",
      "\tF1: 0.1807 (0.04) Section: 4 Action: escape\n",
      "\tF1: 0.7164 (0.35) Section: 4 Action: follow\n",
      "\n",
      "5/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base']\n",
      "\n",
      "\tF1: 0.7364 (0.38) Section: 5 Action: attack\n",
      "\tF1: 0.8860 (0.40) Section: 5 Action: sniff\n",
      "\tF1: 0.5805 (0.35) Section: 5 Action: defend\n",
      "\tF1: 0.7250 (0.32) Section: 5 Action: escape\n",
      "\tF1: 0.8396 (0.25) Section: 5 Action: mount\n",
      "\n",
      "6/9 Processing videos with: ['body_center', 'ear_left', 'ear_right', 'nose', 'tail_base']\n",
      "\n",
      "\tF1: 0.0852 (0.02) Section: 6 Action: biteobject\n",
      "\tF1: 0.5441 (0.16) Section: 6 Action: climb\n",
      "\tF1: 0.5725 (0.21) Section: 6 Action: dig\n",
      "\tF1: 0.1174 (0.03) Section: 6 Action: exploreobject\n",
      "\tF1: 0.3510 (0.14) Section: 6 Action: rear\n",
      "\tF1: 0.4681 (0.18) Section: 6 Action: selfgroom\n",
      "\tF1: 0.6020 (0.22) Section: 6 Action: shepherd\n",
      "\tF1: 0.5210 (0.21) Section: 6 Action: approach\n",
      "\tF1: 0.5882 (0.23) Section: 6 Action: attack\n",
      "\tF1: 0.6308 (0.17) Section: 6 Action: chase\n",
      "\tF1: 0.4415 (0.20) Section: 6 Action: defend\n",
      "\tF1: 0.6566 (0.29) Section: 6 Action: escape\n",
      "\tF1: 0.0730 (0.05) Section: 6 Action: flinch\n",
      "\tF1: 0.4311 (0.10) Section: 6 Action: follow\n",
      "\tF1: 0.4985 (0.27) Section: 6 Action: sniff\n",
      "\tF1: 0.6567 (0.25) Section: 6 Action: sniffface\n",
      "\tF1: 0.3026 (0.06) Section: 6 Action: sniffgenital\n",
      "\tF1: 0.3242 (0.01) Section: 6 Action: tussle\n",
      "\n",
      "7/9 Processing videos with: ['ear_left', 'ear_right', 'head', 'tail_base']\n",
      "\n",
      "\tF1: 0.5844 (0.28) Section: 7 Action: rear\n",
      "\tF1: 0.5951 (0.23) Section: 7 Action: rest\n",
      "\tF1: 0.3155 (0.17) Section: 7 Action: selfgroom\n",
      "\tF1: 0.2843 (0.13) Section: 7 Action: climb\n",
      "\tF1: 0.3595 (0.19) Section: 7 Action: dig\n",
      "\tF1: 0.1354 (0.04) Section: 7 Action: run\n",
      "\tF1: 0.0000 (0.00) Section: 7 Action: intromit\n",
      "\tF1: 0.0000 (0.00) Section: 7 Action: mount\n",
      "\tF1: 0.6757 (0.34) Section: 7 Action: sniff\n",
      "\tF1: 0.5639 (0.29) Section: 7 Action: sniffgenital\n",
      "\tF1: 0.4351 (0.22) Section: 7 Action: approach\n",
      "\tF1: 0.1247 (0.06) Section: 7 Action: defend\n",
      "\tF1: 0.2491 (0.13) Section: 7 Action: escape\n",
      "\tF1: 0.2878 (0.03) Section: 7 Action: attemptmount\n",
      "\n",
      "8/9 Processing videos with: ['ear_left', 'ear_right', 'hip_left', 'hip_right', 'neck', 'nose', 'tail_base']\n",
      "\n",
      "\tF1: 0.2844 (0.12) Section: 8 Action: rear\n",
      "\tF1: 0.2717 (0.11) Section: 8 Action: selfgroom\n",
      "\tF1: 0.6938 (0.27) Section: 8 Action: genitalgroom\n",
      "\tF1: 0.1705 (0.09) Section: 8 Action: dig\n",
      "\tF1: 0.4935 (0.24) Section: 8 Action: approach\n",
      "\tF1: 0.6747 (0.33) Section: 8 Action: attack\n",
      "\tF1: 0.4974 (0.24) Section: 8 Action: disengage\n",
      "\tF1: 0.5591 (0.32) Section: 8 Action: mount\n",
      "\tF1: 0.6743 (0.34) Section: 8 Action: sniff\n",
      "\tF1: 0.5065 (0.26) Section: 8 Action: sniffgenital\n",
      "\tF1: 0.4845 (0.22) Section: 8 Action: dominancemount\n",
      "\tF1: 0.5854 (0.28) Section: 8 Action: sniffbody\n",
      "\tF1: 0.6886 (0.31) Section: 8 Action: sniffface\n",
      "\tF1: 0.1936 (0.07) Section: 8 Action: attemptmount\n",
      "\tF1: 0.8355 (0.43) Section: 8 Action: intromit\n",
      "\tF1: 0.1519 (0.05) Section: 8 Action: chase\n",
      "\tF1: 0.5462 (0.19) Section: 8 Action: escape\n",
      "\tF1: 0.7671 (0.41) Section: 8 Action: reciprocalsniff\n",
      "\tF1: 0.1725 (0.11) Section: 8 Action: allogroom\n",
      "\tF1: 0.2353 (0.67) Section: 8 Action: ejaculate\n",
      "\tF1: 0.1337 (0.08) Section: 8 Action: dominancegroom\n",
      "\n",
      "9/9 Processing videos with: ['ear_left', 'ear_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "\tF1: 0.4209 (0.14) Section: 9 Action: freeze\n",
      "\tF1: 0.4239 (0.11) Section: 9 Action: rear\n",
      "\tF1: 0.2224 (0.09) Section: 9 Action: approach\n",
      "\tF1: 0.7329 (0.43) Section: 9 Action: attack\n",
      "\tF1: 0.5736 (0.24) Section: 9 Action: defend\n",
      "\tF1: 0.7089 (0.44) Section: 9 Action: escape\n",
      "\tF1: 0.6833 (0.15) Section: 9 Action: sniff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_list = []\n",
    "submission_list = []\n",
    "\n",
    "for section in range(1, len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}/{len(body_parts_tracked_list)-1} Processing videos with: {body_parts_tracked}\\n\")\n",
    "        \n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "    \n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "        _fps_lookup = (\n",
    "            train_subset[['video_id', 'frames_per_second']]\n",
    "            .drop_duplicates('video_id')\n",
    "            .set_index('video_id')['frames_per_second']\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "        single_mouse_list = []\n",
    "        single_mouse_label_list = []\n",
    "        single_mouse_meta_list = []\n",
    "        \n",
    "        mouse_pair_list = []\n",
    "        mouse_pair_label_list = []\n",
    "        mouse_pair_meta_list = []\n",
    "    \n",
    "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "            if switch == 'single':\n",
    "                single_mouse_list.append(data)\n",
    "                single_mouse_meta_list.append(meta)\n",
    "                single_mouse_label_list.append(label)\n",
    "            else:\n",
    "                mouse_pair_list.append(data)\n",
    "                mouse_pair_meta_list.append(meta)\n",
    "                mouse_pair_label_list.append(label)\n",
    "            \n",
    "            del data, meta, label\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "        if len(single_mouse_list) > 0:\n",
    "            single_feats_parts = []\n",
    "            for data_i, meta_i in zip(single_mouse_list, single_mouse_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                X_i = transform_single(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                single_feats_parts.append(X_i)\n",
    "                del X_i, fps_i\n",
    "            gc.collect()\n",
    "\n",
    "            X_tr = pd.concat(single_feats_parts, axis=0, ignore_index=True)\n",
    "            single_mouse_label = pd.concat(single_mouse_label_list, axis=0, ignore_index=True)\n",
    "            single_mouse_meta = pd.concat(single_mouse_meta_list, axis=0, ignore_index=True)\n",
    "            \n",
    "            del single_feats_parts, single_mouse_list, single_mouse_label_list, single_mouse_meta_list\n",
    "            gc.collect()\n",
    "\n",
    "            if CFG.mode == 'validate':\n",
    "                temp_submission_list, temp_f1_list, temp_thresholds, temp_weights = cross_validate_classifier(X_tr, single_mouse_label, single_mouse_meta, body_parts_tracked_str, section)\n",
    "                \n",
    "                if f\"{section}\" not in thresholds[\"single\"].keys():\n",
    "                    thresholds[\"single\"][f\"{section}\"] = {}\n",
    "                for k, v in temp_thresholds.items():\n",
    "                    thresholds[\"single\"][f\"{section}\"][k] = v         \n",
    "                    \n",
    "                if f\"{section}\" not in weights[\"single\"].keys():\n",
    "                    weights[\"single\"][f\"{section}\"] = {}\n",
    "                for k, v in temp_weights.items():\n",
    "                    weights[\"single\"][f\"{section}\"][k] = v\n",
    "                \n",
    "                f1_list.extend(temp_f1_list)\n",
    "                submission_list.extend(temp_submission_list)\n",
    "                \n",
    "                del temp_submission_list, temp_f1_list, temp_thresholds, temp_weights, X_tr\n",
    "                gc.collect()\n",
    "            else:\n",
    "                temp_submission_list = submit(body_parts_tracked_str, 'single', section, thresholds[\"single\"][f\"{section}\"], weights[\"single\"][f\"{section}\"])\n",
    "                submission_list.extend(temp_submission_list)\n",
    "                \n",
    "                del temp_submission_list, X_tr\n",
    "                gc.collect()\n",
    "                \n",
    "        if len(mouse_pair_list) > 0:\n",
    "            pair_feats_parts = []\n",
    "            for data_i, meta_i in zip(mouse_pair_list, mouse_pair_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                X_i = transform_pair(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                pair_feats_parts.append(X_i)\n",
    "                del X_i, fps_i\n",
    "            gc.collect()\n",
    "\n",
    "            X_tr = pd.concat(pair_feats_parts, axis=0, ignore_index=True)\n",
    "            mouse_pair_label = pd.concat(mouse_pair_label_list, axis=0, ignore_index=True)\n",
    "            mouse_pair_meta = pd.concat(mouse_pair_meta_list, axis=0, ignore_index=True)\n",
    "            \n",
    "            del pair_feats_parts, mouse_pair_list, mouse_pair_label_list, mouse_pair_meta_list\n",
    "            gc.collect()\n",
    "\n",
    "            if CFG.mode == 'validate':\n",
    "                temp_submission_list, temp_f1_list, temp_thresholds, temp_weights = cross_validate_classifier(X_tr, mouse_pair_label, mouse_pair_meta, body_parts_tracked_str, section)\n",
    "\n",
    "                if f\"{section}\" not in thresholds[\"pair\"].keys():\n",
    "                    thresholds[\"pair\"][f\"{section}\"] = {}\n",
    "                for k, v in temp_thresholds.items():\n",
    "                    thresholds[\"pair\"][f\"{section}\"][k] = v  \n",
    "                    \n",
    "                if f\"{section}\" not in weights[\"pair\"].keys():\n",
    "                    weights[\"pair\"][f\"{section}\"] = {}\n",
    "                for k, v in temp_weights.items():\n",
    "                    weights[\"pair\"][f\"{section}\"][k] = v\n",
    "                    \n",
    "                f1_list.extend(temp_f1_list)\n",
    "                submission_list.extend(temp_submission_list)\n",
    "                \n",
    "                del temp_submission_list, temp_f1_list, temp_thresholds, temp_weights, X_tr\n",
    "                gc.collect()\n",
    "            else:\n",
    "                temp_submission_list = submit(body_parts_tracked_str, 'pair', section, thresholds[\"pair\"][f\"{section}\"], weights[\"pair\"][f\"{section}\"])\n",
    "                \n",
    "                submission_list.extend(temp_submission_list)\n",
    "                del temp_submission_list, X_tr\n",
    "                gc.collect()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\t{e}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75bcb8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T13:00:47.728199Z",
     "iopub.status.busy": "2025-11-16T13:00:47.727794Z",
     "iopub.status.idle": "2025-11-16T13:01:25.756289Z",
     "shell.execute_reply": "2025-11-16T13:01:25.754779Z"
    },
    "papermill": {
     "duration": 38.047237,
     "end_time": "2025-11-16T13:01:25.758193",
     "exception": false,
     "start_time": "2025-11-16T13:00:47.710956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 1375833299 has no predictions.\n",
      "ERROR: Filled empty videos\n",
      "Competition metric: 0.4728\n",
      "Mean F1:            0.4446\n"
     ]
    }
   ],
   "source": [
    "if CFG.mode == 'validate':  \n",
    "    submission = pd.concat(submission_list)\n",
    "    submission_robust = robustify(submission, train, 'train')\n",
    "    print(f\"Competition metric: {score(solution, submission_robust, ''):.4f}\")\n",
    "\n",
    "    f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
    "    print(f\"Mean F1:            {f1_df['binary F1 score'].mean():.4f}\")\n",
    "\n",
    "    os.makedirs(\"ensemble\", exist_ok=True)\n",
    "    joblib.dump(thresholds, f\"ensemble/thresholds.pkl\")\n",
    "    joblib.dump(weights, f\"ensemble/weights.pkl\")\n",
    "    joblib.dump(f1_df, f\"ensemble/scores.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6b52e",
   "metadata": {
    "papermill": {
     "duration": 0.012791,
     "end_time": "2025-11-16T13:01:25.784303",
     "exception": false,
     "start_time": "2025-11-16T13:01:25.771512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a6c93af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-16T13:01:25.813140Z",
     "iopub.status.busy": "2025-11-16T13:01:25.812737Z",
     "iopub.status.idle": "2025-11-16T13:01:25.819684Z",
     "shell.execute_reply": "2025-11-16T13:01:25.818731Z"
    },
    "papermill": {
     "duration": 0.024019,
     "end_time": "2025-11-16T13:01:25.821495",
     "exception": false,
     "start_time": "2025-11-16T13:01:25.797476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.mode == 'submit':\n",
    "    if len(submission_list) > 0:\n",
    "        submission = pd.concat(submission_list)\n",
    "    else:\n",
    "        submission = pd.DataFrame(\n",
    "            dict(\n",
    "                video_id=438887472,\n",
    "                agent_id='mouse1',\n",
    "                target_id='self',\n",
    "                action='rear',\n",
    "                start_frame='278',\n",
    "                stop_frame='500'\n",
    "            ), index=[44])\n",
    "        \n",
    "    submission_robust = robustify(submission, test, 'test')\n",
    "    submission_robust.index.name = 'row_id'\n",
    "    submission_robust.to_csv('submission.csv')\n",
    "    submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    },
    {
     "datasetId": 8619229,
     "sourceId": 13607639,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13782.209475,
   "end_time": "2025-11-16T13:01:28.117360",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-16T09:11:45.907885",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1fc0d13fc4064e84928c6f01ff3571b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f10c7cb4a9274b4aa58a1428d05a997a",
       "placeholder": "​",
       "style": "IPY_MODEL_3955ea302d1148d9a864f40e9e34bd1d",
       "tabbable": null,
       "tooltip": null,
       "value": " 863/863 [00:13&lt;00:00, 77.63it/s]"
      }
     },
     "254b19634b694817962031e5a60113c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f72b1f18aa4642be852952047a3d0c87",
        "IPY_MODEL_df8099473b8042b2a4ac9ddf07531cc5",
        "IPY_MODEL_1fc0d13fc4064e84928c6f01ff3571b0"
       ],
       "layout": "IPY_MODEL_e74be56becee4b70ab09fbb6c88ea7ce",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2c549157a3f446999deb5ea856bb3a64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3955ea302d1148d9a864f40e9e34bd1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4a06835dabea4ea8be09700eff480904": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7db9031d3063406d8da47fe035013e68": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa1bc8ca9a3e4f5e90ff24656596ec1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "df8099473b8042b2a4ac9ddf07531cc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a06835dabea4ea8be09700eff480904",
       "max": 863.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2c549157a3f446999deb5ea856bb3a64",
       "tabbable": null,
       "tooltip": null,
       "value": 863.0
      }
     },
     "e74be56becee4b70ab09fbb6c88ea7ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f10c7cb4a9274b4aa58a1428d05a997a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f72b1f18aa4642be852952047a3d0c87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aa1bc8ca9a3e4f5e90ff24656596ec1c",
       "placeholder": "​",
       "style": "IPY_MODEL_7db9031d3063406d8da47fe035013e68",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
