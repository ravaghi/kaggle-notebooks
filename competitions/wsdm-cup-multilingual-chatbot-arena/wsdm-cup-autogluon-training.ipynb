{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ravaghi/wsdm-cup-autogluon-training?scriptVersionId=220752804\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e252316c","metadata":{"papermill":{"duration":0.005047,"end_time":"2025-02-04T11:17:46.890162","exception":false,"start_time":"2025-02-04T11:17:46.885115","status":"completed"},"tags":[]},"source":["- Inference notebook: https://www.kaggle.com/code/ravaghi/wsdm-cup-gemma-2-9b-4-bit-qlora-autogluon"]},{"cell_type":"markdown","id":"de28adb2","metadata":{"papermill":{"duration":0.003656,"end_time":"2025-02-04T11:17:46.898281","exception":false,"start_time":"2025-02-04T11:17:46.894625","status":"completed"},"tags":[]},"source":["# Imports and configs"]},{"cell_type":"code","execution_count":1,"id":"981e99e5","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-02-04T11:17:46.907744Z","iopub.status.busy":"2025-02-04T11:17:46.907337Z","iopub.status.idle":"2025-02-04T11:18:12.795455Z","shell.execute_reply":"2025-02-04T11:18:12.793913Z"},"papermill":{"duration":25.895614,"end_time":"2025-02-04T11:18:12.798004","exception":false,"start_time":"2025-02-04T11:17:46.90239","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h"]}],"source":["!pip install -q autogluon.tabular ray==2.10.0"]},{"cell_type":"code","execution_count":2,"id":"010ab6bf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-02-04T11:18:12.812192Z","iopub.status.busy":"2025-02-04T11:18:12.811793Z","iopub.status.idle":"2025-02-04T11:18:15.8717Z","shell.execute_reply":"2025-02-04T11:18:15.870431Z"},"papermill":{"duration":3.069375,"end_time":"2025-02-04T11:18:15.874039","exception":false,"start_time":"2025-02-04T11:18:12.804664","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from autogluon.tabular import TabularPredictor\n","import pandas as pd\n","import warnings\n","import joblib\n","import shutil\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"id":"8d2dc364","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:15.887479Z","iopub.status.busy":"2025-02-04T11:18:15.886709Z","iopub.status.idle":"2025-02-04T11:18:15.893554Z","shell.execute_reply":"2025-02-04T11:18:15.892441Z"},"papermill":{"duration":0.015899,"end_time":"2025-02-04T11:18:15.895783","exception":false,"start_time":"2025-02-04T11:18:15.879884","status":"completed"},"tags":[]},"outputs":[],"source":["class CFG:\n","    train_path = '/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet'\n","    test_path = '/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet'\n","    sample_sub_path = '/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv'\n","\n","    data_path = '/kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora'\n","\n","    target = 'winner'\n","    n_folds = 5\n","    seed = 42\n","\n","    char_vectorizer_params = {\n","        'analyzer': \"char\",\n","        \"lowercase\": False,\n","        \"max_df\": 0.605,\n","        \"max_features\": 331,\n","        \"min_df\": 0.075,\n","        \"ngram_range\": (1, 3),\n","        \"strip_accents\": \"unicode\"\n","    }\n","\n","    word_vectorizer_params = {\n","        \"analyzer\": \"word\",\n","        \"lowercase\": True,\n","        \"max_df\": 0.985,\n","        \"max_features\": 769,\n","        \"min_df\": 0.01,\n","        \"ngram_range\": (1, 2),\n","        \"strip_accents\": \"unicode\"\n","    }"]},{"cell_type":"markdown","id":"4817d6ae","metadata":{"papermill":{"duration":0.005384,"end_time":"2025-02-04T11:18:15.907178","exception":false,"start_time":"2025-02-04T11:18:15.901794","status":"completed"},"tags":[]},"source":["# Loading and processing data"]},{"cell_type":"code","execution_count":4,"id":"9291da78","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:15.920048Z","iopub.status.busy":"2025-02-04T11:18:15.919556Z","iopub.status.idle":"2025-02-04T11:18:15.932458Z","shell.execute_reply":"2025-02-04T11:18:15.930535Z"},"papermill":{"duration":0.021529,"end_time":"2025-02-04T11:18:15.934416","exception":false,"start_time":"2025-02-04T11:18:15.912887","status":"completed"},"tags":[]},"outputs":[],"source":["def reduce_mem_usage(dataframe):\n","    print('--- Reducing memory usage')\n","    initial_mem_usage = dataframe.memory_usage().sum() / 1024**2\n","    \n","    for col in dataframe.columns:\n","        col_type = dataframe[col].dtype\n","\n","        if col_type.name in ['category', 'object']:\n","            continue\n","\n","        c_min = dataframe[col].min()\n","        c_max = dataframe[col].max()\n","        if str(col_type)[:3] == 'int':\n","            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                dataframe[col] = dataframe[col].astype(np.int8)\n","            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                dataframe[col] = dataframe[col].astype(np.int16)\n","            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                dataframe[col] = dataframe[col].astype(np.int32)\n","            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                dataframe[col] = dataframe[col].astype(np.int64)\n","        else:\n","            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                dataframe[col] = dataframe[col].astype(np.float16)\n","            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                dataframe[col] = dataframe[col].astype(np.float32)\n","            else:\n","                dataframe[col] = dataframe[col].astype(np.float64)\n","\n","    final_mem_usage = dataframe.memory_usage().sum() / 1024**2\n","    print('------ Memory usage before: {:.2f} MB'.format(initial_mem_usage))\n","    print('------ Memory usage after: {:.2f} MB'.format(final_mem_usage))\n","    print('------ Decreased memory usage by {:.1f}%'.format(100 * (initial_mem_usage - final_mem_usage) / initial_mem_usage))\n","\n","    return dataframe"]},{"cell_type":"code","execution_count":5,"id":"23de08a4","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:15.94746Z","iopub.status.busy":"2025-02-04T11:18:15.947068Z","iopub.status.idle":"2025-02-04T11:18:15.973813Z","shell.execute_reply":"2025-02-04T11:18:15.972438Z"},"papermill":{"duration":0.035721,"end_time":"2025-02-04T11:18:15.976031","exception":false,"start_time":"2025-02-04T11:18:15.94031","status":"completed"},"tags":[]},"outputs":[],"source":["def add_word_features(df, column):\n","    # Basic word counts\n","    df[f'{column}_word_count'] = df[column].apply(lambda x: len(x.split()))\n","    df[f'{column}_unique_word_count'] = df[column].apply(lambda x: len(set(x.lower().split())))\n","    \n","    # Word length statistics\n","    def safe_word_stats(text):\n","        words = str(text).split()\n","        if not words:\n","            return 0, 0  # avg_length, max_length for empty text\n","        word_lengths = [len(word) for word in words]\n","        return np.mean(word_lengths), max(word_lengths)\n","    \n","    word_stats = df[column].apply(safe_word_stats)\n","    df[f'{column}_avg_word_length'] = word_stats.apply(lambda x: x[0])\n","    df[f'{column}_max_word_length'] = word_stats.apply(lambda x: x[1])\n","    \n","    # Lexical diversity (unique words / total words)\n","    df[f'{column}_lexical_diversity'] = df.apply(\n","        lambda x: x[f'{column}_unique_word_count'] / x[f'{column}_word_count'] \n","        if x[f'{column}_word_count'] > 0 else 0, axis=1\n","    )\n","    \n","    # Count specific word types\n","    df[f'{column}_uppercase_word_count'] = df[column].apply(lambda x: sum(1 for word in x.split() if word.isupper()))\n","    df[f'{column}_title_case_word_count'] = df[column].apply(lambda x: sum(1 for word in x.split() if word.istitle()))\n","    \n","    return df\n","\n","def add_char_features(df, column):\n","    # Basic character counts\n","    df[f'{column}_char_count'] = df[column].str.len()\n","    df[f'{column}_letter_count'] = df[column].apply(lambda x: sum(c.isalpha() for c in x))\n","    df[f'{column}_digit_count'] = df[column].apply(lambda x: sum(c.isdigit() for c in x))\n","    df[f'{column}_whitespace_count'] = df[column].apply(lambda x: sum(c.isspace() for c in x))\n","    \n","    # Punctuation counts\n","    df[f'{column}_punctuation_count'] = df[column].apply(lambda x: sum(c in '.,!?;:' for c in x))\n","    df[f'{column}_special_char_count'] = df[column].apply(lambda x: sum(not (c.isalnum() or c.isspace()) for c in x))\n","    \n","    # Character ratios with safe division\n","    df[f'{column}_uppercase_ratio'] = df[column].apply(lambda x: sum(c.isupper() for c in x) / max(len(x), 1))\n","    df[f'{column}_lowercase_ratio'] = df[column].apply(lambda x: sum(c.islower() for c in x) / max(len(x), 1))\n","    \n","    return df\n","\n","def add_sentence_features(df, column):\n","    # Sentence counts\n","    df[f'{column}_sentence_count'] = df[column].apply(lambda x: len(sent_tokenize(x)))\n","    \n","    # Average sentence length with safe division\n","    df[f'{column}_avg_sentence_length'] = df[column].apply(\n","        lambda x: np.mean([len(sent.split()) for sent in sent_tokenize(x)])\n","        if len(sent_tokenize(x)) > 0 else 0\n","    )\n","    \n","    # Sentence length variation with safe handling\n","    df[f'{column}_sentence_length_std'] = df[column].apply(\n","        lambda x: np.std([len(sent.split()) for sent in sent_tokenize(x)]) \n","        if len(sent_tokenize(x)) > 1 else 0\n","    )\n","    \n","    # Question and exclamation counts\n","    df[f'{column}_question_count'] = df[column].str.count('\\?')\n","    df[f'{column}_exclamation_count'] = df[column].str.count('!')\n","    \n","    return df\n","\n","def add_stats_features(df, column):\n","    # Readability metrics (simplified Flesch Reading Ease)\n","    def calculate_readability(text):\n","        sentences = sent_tokenize(text)\n","        words = text.split()\n","        if not words or not sentences:\n","            return 0\n","        avg_sentence_length = len(words) / len(sentences)\n","        avg_syllables_per_word = sum(count_syllables(word) for word in words) / len(words)\n","        return 206.835 - (1.015 * avg_sentence_length) - (84.6 * avg_syllables_per_word)\n","    \n","    def count_syllables(word):\n","        word = word.lower()\n","        count = 0\n","        vowels = 'aeiouy'\n","        if word[0] in vowels:\n","            count += 1\n","        for index in range(1, len(word)):\n","            if word[index] in vowels and word[index-1] not in vowels:\n","                count += 1\n","        if word.endswith('e'):\n","            count -= 1\n","        if count == 0:\n","            count = 1\n","        return count\n","    \n","    df[f'{column}_readability_score'] = df[column].apply(calculate_readability)\n","    \n","    # Text complexity features with safe division\n","    df[f'{column}_avg_word_per_sentence'] = df.apply(\n","        lambda x: x[f'{column}_word_count'] / x[f'{column}_sentence_count']\n","        if x[f'{column}_sentence_count'] > 0 else 0, axis=1\n","    )\n","    \n","    df[f'{column}_char_per_word'] = df.apply(\n","        lambda x: x[f'{column}_char_count'] / x[f'{column}_word_count']\n","        if x[f'{column}_word_count'] > 0 else 0, axis=1\n","    )\n","    \n","    return df\n","\n","def get_text_similarity(text1, text2):\n","    text1, text2 = str(text1), str(text2)\n","    \n","    chars1, chars2 = set(text1.lower()), set(text2.lower())\n","    char_similarity = len(chars1 & chars2) / max(len(chars1 | chars2), 1)\n","    \n","    words1 = set(text1.lower().split())\n","    words2 = set(text2.lower().split())\n","    word_similarity = len(words1 & words2) / max(len(words1 | words2), 1)\n","    \n","    length_ratio = len(text1) / max(len(text2), 1)\n","    \n","    return char_similarity, word_similarity, length_ratio\n","\n","def add_features(df, is_train):\n","    if is_train:\n","        features = joblib.load(f'{CFG.data_path}/features/train_features.pkl')\n","        df = df.merge(features, on='id', how='left')\n","        return df\n","    \n","    for column in ['prompt', 'response_a', 'response_b']:\n","        df = add_word_features(df, column)\n","        df = add_char_features(df, column)\n","        df = add_sentence_features(df, column)\n","        df = add_stats_features(df, column)\n","        \n","    # Add text similarity features between prompt and response_a/response_b\n","    similarities_a = df.apply(lambda row: get_text_similarity(row['prompt'], row['response_a']), axis=1)\n","    similarities_b = df.apply(lambda row: get_text_similarity(row['prompt'], row['response_b']), axis=1)\n","    df['prompt_response_a_char_sim'], df['prompt_response_a_word_sim'], df['prompt_response_a_length_ratio'] = zip(*similarities_a)\n","    df['prompt_response_b_char_sim'], df['prompt_response_b_word_sim'], df['prompt_response_b_length_ratio'] = zip(*similarities_b)\n","        \n","    # Add comparative features between response_a and response_b with safe division\n","    for feature in df.columns:\n","        if feature.startswith('response_a_'):\n","            corresponding_b = feature.replace('response_a_', 'response_b_')\n","            if corresponding_b in df.columns:\n","                df[f'diff_{feature.replace(\"response_a_\", \"\")}'] = df[feature] - df[corresponding_b]\n","                df[f'ratio_{feature.replace(\"response_a_\", \"\")}'] = df.apply(\n","                    lambda x: x[feature] / x[corresponding_b] \n","                    if x[corresponding_b] != 0 else 0, axis=1\n","                )\n","    \n","    return df"]},{"cell_type":"code","execution_count":6,"id":"79f69f86","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:15.989055Z","iopub.status.busy":"2025-02-04T11:18:15.988673Z","iopub.status.idle":"2025-02-04T11:18:15.995146Z","shell.execute_reply":"2025-02-04T11:18:15.994059Z"},"papermill":{"duration":0.015212,"end_time":"2025-02-04T11:18:15.997145","exception":false,"start_time":"2025-02-04T11:18:15.981933","status":"completed"},"tags":[]},"outputs":[],"source":["def add_tfidf_features(df, is_train):\n","    if is_train:\n","        tfidf_features = joblib.load(f'{CFG.data_path}/features/train_tfidf_features.pkl')\n","        df = df.merge(tfidf_features, on='id', how='left')\n","        return df\n","\n","    for column in ['prompt', 'response_a', 'response_b']:\n","        for params in [CFG.char_vectorizer_params, CFG.word_vectorizer_params]:\n","            \n","            tfidf_vectorizer = joblib.load(f'{column}_{params[\"analyzer\"]}_tfidf_vectorizer.pkl')\n","            tfidf_matrix = tfidf_vectorizer.transform(df[column].fillna(''))\n","            tfidf_dense = tfidf_matrix.toarray()\n","            \n","            feature_names = tfidf_vectorizer.get_feature_names_out()\n","            for i in range(len(feature_names)):\n","                df[f'{column}_{params[\"analyzer\"]}_tfidf_{i}'] = tfidf_dense[:, i]\n","            \n","            del tfidf_vectorizer, tfidf_matrix, tfidf_dense\n","            \n","            gc.collect()\n","            \n","    return df"]},{"cell_type":"code","execution_count":7,"id":"e70fe317","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:16.013008Z","iopub.status.busy":"2025-02-04T11:18:16.012582Z","iopub.status.idle":"2025-02-04T11:18:19.327954Z","shell.execute_reply":"2025-02-04T11:18:19.326755Z"},"papermill":{"duration":3.326183,"end_time":"2025-02-04T11:18:19.330188","exception":false,"start_time":"2025-02-04T11:18:16.004005","status":"completed"},"tags":[]},"outputs":[],"source":["train = pd.read_parquet(CFG.train_path)\n","\n","train[CFG.target] = train[CFG.target].map({\"model_a\": 0, \"model_b\": 1})\n","\n","train = train.drop(columns=['model_a', 'model_b', 'language'])"]},{"cell_type":"code","execution_count":8,"id":"3a5ebbda","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:19.343273Z","iopub.status.busy":"2025-02-04T11:18:19.342786Z","iopub.status.idle":"2025-02-04T11:18:25.395417Z","shell.execute_reply":"2025-02-04T11:18:25.394145Z"},"papermill":{"duration":6.061886,"end_time":"2025-02-04T11:18:25.397919","exception":false,"start_time":"2025-02-04T11:18:19.336033","status":"completed"},"tags":[]},"outputs":[],"source":["train = add_features(train, is_train=True)\n","train = add_tfidf_features(train, is_train=True)"]},{"cell_type":"code","execution_count":9,"id":"6508d9ab","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:25.410937Z","iopub.status.busy":"2025-02-04T11:18:25.410483Z","iopub.status.idle":"2025-02-04T11:18:25.432381Z","shell.execute_reply":"2025-02-04T11:18:25.43112Z"},"papermill":{"duration":0.031052,"end_time":"2025-02-04T11:18:25.434734","exception":false,"start_time":"2025-02-04T11:18:25.403682","status":"completed"},"tags":[]},"outputs":[],"source":["train['tta_oof'] = joblib.load(f'{CFG.data_path}/features/tta_oof_pred_probs_acc_0.683437.pkl')"]},{"cell_type":"code","execution_count":10,"id":"b6da4858","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:25.448705Z","iopub.status.busy":"2025-02-04T11:18:25.448286Z","iopub.status.idle":"2025-02-04T11:18:25.768659Z","shell.execute_reply":"2025-02-04T11:18:25.767488Z"},"papermill":{"duration":0.330415,"end_time":"2025-02-04T11:18:25.77145","exception":false,"start_time":"2025-02-04T11:18:25.441035","status":"completed"},"tags":[]},"outputs":[],"source":["train = train.drop(columns=['id', 'prompt', 'response_a', 'response_b'])"]},{"cell_type":"markdown","id":"90ec77bc","metadata":{"papermill":{"duration":0.009551,"end_time":"2025-02-04T11:18:25.792093","exception":false,"start_time":"2025-02-04T11:18:25.782542","status":"completed"},"tags":[]},"source":["# Training"]},{"cell_type":"code","execution_count":11,"id":"21ca18d6","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:18:25.811976Z","iopub.status.busy":"2025-02-04T11:18:25.811533Z","iopub.status.idle":"2025-02-04T11:18:25.838242Z","shell.execute_reply":"2025-02-04T11:18:25.837034Z"},"papermill":{"duration":0.04207,"end_time":"2025-02-04T11:18:25.840347","exception":false,"start_time":"2025-02-04T11:18:25.798277","status":"completed"},"tags":[]},"outputs":[],"source":["kf = StratifiedKFold(n_splits=CFG.n_folds, random_state=CFG.seed, shuffle=True)\n","split = kf.split(train, train[CFG.target])\n","for i, (train_index, val_index) in enumerate(split):\n","    train.loc[val_index, 'fold'] = i"]},{"cell_type":"code","execution_count":12,"id":"1cf85412","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-02-04T11:18:25.853631Z","iopub.status.busy":"2025-02-04T11:18:25.853276Z","iopub.status.idle":"2025-02-04T11:18:25.865643Z","shell.execute_reply":"2025-02-04T11:18:25.864322Z"},"papermill":{"duration":0.021332,"end_time":"2025-02-04T11:18:25.867806","exception":false,"start_time":"2025-02-04T11:18:25.846474","status":"completed"},"tags":[]},"outputs":[],"source":["predictor = TabularPredictor(\n","    path=\"/AutoGluonModels\",\n","    problem_type='binary',\n","    eval_metric='accuracy',\n","    label=CFG.target,\n","    groups='fold',\n","    verbosity=2\n",")"]},{"cell_type":"code","execution_count":13,"id":"ac006182","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2025-02-04T11:18:25.883968Z","iopub.status.busy":"2025-02-04T11:18:25.883331Z","iopub.status.idle":"2025-02-04T11:24:45.243143Z","shell.execute_reply":"2025-02-04T11:24:45.241546Z"},"papermill":{"duration":379.369748,"end_time":"2025-02-04T11:24:45.245426","exception":false,"start_time":"2025-02-04T11:18:25.875678","status":"completed"},"scrolled":true,"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Verbosity: 2 (Standard Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.2\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Nov 10 10:07:59 UTC 2024\n","CPU Count:          4\n","Memory Avail:       29.20 GB / 31.35 GB (93.1%)\n","Disk Space Avail:   1966.10 GB / 8062.39 GB (24.4%)\n","===================================================\n","Presets specified: ['best_quality']\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2025-02-04 11:18:29,107\tINFO worker.py:1752 -- Started a local Ray instance.\n","\t\tContext path: \"/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=169)\u001b[0m Running DyStack sub-fit ...\n","\u001b[36m(_dystack pid=169)\u001b[0m Values in column 'fold' used as split folds instead of being automatically set. Bagged models will have 5 splits.\n","\u001b[36m(_dystack pid=169)\u001b[0m Beginning AutoGluon training ... Time limit = 70s\n","\u001b[36m(_dystack pid=169)\u001b[0m AutoGluon will save models to \"/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n","\u001b[36m(_dystack pid=169)\u001b[0m Train Data Rows:    43056\n","\u001b[36m(_dystack pid=169)\u001b[0m Train Data Columns: 3371\n","\u001b[36m(_dystack pid=169)\u001b[0m Label Column:       winner\n","\u001b[36m(_dystack pid=169)\u001b[0m Problem Type:       binary\n","\u001b[36m(_dystack pid=169)\u001b[0m Preprocessing data ...\n","\u001b[36m(_dystack pid=169)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","\u001b[36m(_dystack pid=169)\u001b[0m Using Feature Generators to preprocess the data ...\n","\u001b[36m(_dystack pid=169)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n","\u001b[36m(_dystack pid=169)\u001b[0m \tAvailable Memory:                    28857.09 MB\n","\u001b[36m(_dystack pid=169)\u001b[0m \tTrain Data (Original)  Memory Usage: 277.41 MB (1.0% of available memory)\n","\u001b[36m(_dystack pid=169)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\u001b[36m(_dystack pid=169)\u001b[0m \tStage 1 Generators:\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n","\u001b[36m(_dystack pid=169)\u001b[0m \tStage 2 Generators:\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n","\u001b[36m(_dystack pid=169)\u001b[0m \tStage 3 Generators:\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n","\u001b[36m(_dystack pid=169)\u001b[0m \tStage 4 Generators:\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n","\u001b[36m(_dystack pid=169)\u001b[0m \tStage 5 Generators:\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n","\u001b[36m(_dystack pid=169)\u001b[0m /usr/local/lib/python3.10/dist-packages/autogluon/features/generators/drop_duplicates.py:111: RuntimeWarning: overflow encountered in multiply\n","\u001b[36m(_dystack pid=169)\u001b[0m   feature_sum_map[round(X[feature].sum(), 2)].append(feature)\n","\u001b[36m(_dystack pid=169)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\t('float', []) : 3314 | ['prompt_avg_word_length', 'prompt_lexical_diversity', 'prompt_uppercase_ratio', 'prompt_lowercase_ratio', 'prompt_avg_sentence_length', ...]\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\t('int', [])   :   56 | ['prompt_word_count', 'prompt_unique_word_count', 'prompt_max_word_length', 'prompt_uppercase_word_count', 'prompt_title_case_word_count', ...]\n","\u001b[36m(_dystack pid=169)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\t('float', []) : 3314 | ['prompt_avg_word_length', 'prompt_lexical_diversity', 'prompt_uppercase_ratio', 'prompt_lowercase_ratio', 'prompt_avg_sentence_length', ...]\n","\u001b[36m(_dystack pid=169)\u001b[0m \t\t('int', [])   :   56 | ['prompt_word_count', 'prompt_unique_word_count', 'prompt_max_word_length', 'prompt_uppercase_word_count', 'prompt_title_case_word_count', ...]\n","\u001b[36m(_dystack pid=169)\u001b[0m \t49.6s = Fit runtime\n","\u001b[36m(_dystack pid=169)\u001b[0m \t3370 features in original data used to generate 3370 features in processed data.\n","\u001b[36m(_dystack pid=169)\u001b[0m \tTrain Data (Processed) Memory Usage: 277.41 MB (1.0% of available memory)\n","\u001b[36m(_dystack pid=169)\u001b[0m Data preprocessing and feature engineering runtime = 52.56s ...\n","\u001b[36m(_dystack pid=169)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\u001b[36m(_dystack pid=169)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n","\u001b[36m(_dystack pid=169)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","\u001b[36m(_dystack pid=169)\u001b[0m User-specified model hyperparameters to be fit:\n","\u001b[36m(_dystack pid=169)\u001b[0m {\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","\u001b[36m(_dystack pid=169)\u001b[0m }\n","\u001b[36m(_dystack pid=169)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n","\u001b[36m(_dystack pid=169)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","\u001b[36m(_dystack pid=169)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n","\u001b[36m(_dystack pid=169)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 11.35s of the 17.02s of remaining time.\n","\u001b[36m(_dystack pid=169)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=8.52%)\n","\u001b[36m(_dystack pid=169)\u001b[0m \tTime limit exceeded... Skipping LightGBMXT_BAG_L1.\n","\u001b[36m(_dystack pid=169)\u001b[0m No base models to train on, skipping auxiliary stack level 2...\n","\u001b[36m(_dystack pid=169)\u001b[0m No base models to train on, skipping stack level 2...\n","\u001b[36m(_dystack pid=169)\u001b[0m No base models to train on, skipping auxiliary stack level 3...\n","\u001b[36m(_dystack pid=169)\u001b[0m Warning: AutoGluon did not successfully train any models\n","\u001b[36m(_dystack pid=169)\u001b[0m AutoGluon training complete, total runtime = 66.33s ... Best model: None\n","Warning: Exception encountered during DyStack sub-fit:\n","\tNo models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\n","\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n","\t77s\t = DyStack   runtime |\t223s\t = Remaining runtime\n","Starting main fit with num_stack_levels=1.\n","\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n","Values in column 'fold' used as split folds instead of being automatically set. Bagged models will have 5 splits.\n","Beginning AutoGluon training ... Time limit = 223s\n","AutoGluon will save models to \"/AutoGluonModels\"\n","Train Data Rows:    48439\n","Train Data Columns: 3371\n","Label Column:       winner\n","Problem Type:       binary\n","Preprocessing data ...\n","Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n","Using Feature Generators to preprocess the data ...\n","Fitting AutoMLPipelineFeatureGenerator...\n","\tAvailable Memory:                    29022.90 MB\n","\tTrain Data (Original)  Memory Usage: 312.09 MB (1.1% of available memory)\n","\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n","\tStage 1 Generators:\n","\t\tFitting AsTypeFeatureGenerator...\n","\tStage 2 Generators:\n","\t\tFitting FillNaFeatureGenerator...\n","\tStage 3 Generators:\n","\t\tFitting IdentityFeatureGenerator...\n","\tStage 4 Generators:\n","\t\tFitting DropUniqueFeatureGenerator...\n","\tStage 5 Generators:\n","\t\tFitting DropDuplicatesFeatureGenerator...\n","\tTypes of features in original data (raw dtype, special dtypes):\n","\t\t('float', []) : 3314 | ['prompt_avg_word_length', 'prompt_lexical_diversity', 'prompt_uppercase_ratio', 'prompt_lowercase_ratio', 'prompt_avg_sentence_length', ...]\n","\t\t('int', [])   :   56 | ['prompt_word_count', 'prompt_unique_word_count', 'prompt_max_word_length', 'prompt_uppercase_word_count', 'prompt_title_case_word_count', ...]\n","\tTypes of features in processed data (raw dtype, special dtypes):\n","\t\t('float', []) : 3314 | ['prompt_avg_word_length', 'prompt_lexical_diversity', 'prompt_uppercase_ratio', 'prompt_lowercase_ratio', 'prompt_avg_sentence_length', ...]\n","\t\t('int', [])   :   56 | ['prompt_word_count', 'prompt_unique_word_count', 'prompt_max_word_length', 'prompt_uppercase_word_count', 'prompt_title_case_word_count', ...]\n","\t48.3s = Fit runtime\n","\t3370 features in original data used to generate 3370 features in processed data.\n","\tTrain Data (Processed) Memory Usage: 312.09 MB (1.1% of available memory)\n","Data preprocessing and feature engineering runtime = 51.05s ...\n","AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n","\tTo change this, specify the eval_metric parameter of Predictor()\n","Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n","User-specified model hyperparameters to be fit:\n","{\n","\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n","\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n","\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n","\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n","\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n","\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n","\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n","}\n","AutoGluon will fit 2 stack levels (L1 to L2) ...\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 114.37s of the 171.59s of remaining time.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=9.21%)\n","\t0.6558\t = Validation score   (accuracy)\n","\t114.9s\t = Training   runtime\n","\t4.48s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L2 ... Training model for up to 171.60s of the 40.80s of remaining time.\n","\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n","\t0.6558\t = Validation score   (accuracy)\n","\t0.01s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n","Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n","Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 40.76s of the 40.51s of remaining time.\n","\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=9.34%)\n","\t0.6595\t = Validation score   (accuracy)\n","\t104.39s\t = Training   runtime\n","\t4.93s\t = Validation runtime\n","Fitting model: WeightedEnsemble_L3 ... Training model for up to 171.60s of the -77.31s of remaining time.\n","\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.688, 'LightGBMXT_BAG_L1': 0.312}\n","\t0.6673\t = Validation score   (accuracy)\n","\t0.28s\t = Training   runtime\n","\t0.01s\t = Validation runtime\n","AutoGluon training complete, total runtime = 301.12s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1029.8 rows/s (9688 batch size)\n","Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n","Calibrating decision threshold to optimize metric accuracy | Checking 51 thresholds...\n","Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n","\tBase Threshold: 0.500\t| val: 0.6673\n","\tBest Threshold: 0.504\t| val: 0.6795\n","Updating predictor.decision_threshold from 0.5 -> 0.504\n","\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n","\tPrediction probabilities of the positive class >0.504 will be predicted as the positive class (1). This can significantly impact metric scores.\n","\tYou can update this value via `predictor.set_decision_threshold`.\n","\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n","TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/AutoGluonModels\")\n"]},{"data":{"text/plain":["<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7c2a4279f0a0>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["predictor.fit(\n","    train_data=train,\n","    time_limit=300,\n","    presets='best_quality',\n","    excluded_model_types=['KNN'],\n","    save_space=True\n",")"]},{"cell_type":"code","execution_count":14,"id":"003e16e4","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:24:45.27246Z","iopub.status.busy":"2025-02-04T11:24:45.271574Z","iopub.status.idle":"2025-02-04T11:24:45.3689Z","shell.execute_reply":"2025-02-04T11:24:45.367622Z"},"papermill":{"duration":0.113049,"end_time":"2025-02-04T11:24:45.370973","exception":false,"start_time":"2025-02-04T11:24:45.257924","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_c0e80_row0_col1 {\n","  background-color: #006837;\n","  color: #f1f1f1;\n","}\n","#T_c0e80_row1_col1 {\n","  background-color: #fdbb6c;\n","  color: #000000;\n","}\n","#T_c0e80_row2_col1, #T_c0e80_row3_col1 {\n","  background-color: #a50026;\n","  color: #f1f1f1;\n","}\n","</style>\n","<table id=\"T_c0e80\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_c0e80_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n","      <th id=\"T_c0e80_level0_col1\" class=\"col_heading level0 col1\" >score_val</th>\n","      <th id=\"T_c0e80_level0_col2\" class=\"col_heading level0 col2\" >eval_metric</th>\n","      <th id=\"T_c0e80_level0_col3\" class=\"col_heading level0 col3\" >pred_time_val</th>\n","      <th id=\"T_c0e80_level0_col4\" class=\"col_heading level0 col4\" >fit_time</th>\n","      <th id=\"T_c0e80_level0_col5\" class=\"col_heading level0 col5\" >pred_time_val_marginal</th>\n","      <th id=\"T_c0e80_level0_col6\" class=\"col_heading level0 col6\" >fit_time_marginal</th>\n","      <th id=\"T_c0e80_level0_col7\" class=\"col_heading level0 col7\" >stack_level</th>\n","      <th id=\"T_c0e80_level0_col8\" class=\"col_heading level0 col8\" >can_infer</th>\n","      <th id=\"T_c0e80_level0_col9\" class=\"col_heading level0 col9\" >fit_order</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_c0e80_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n","      <td id=\"T_c0e80_row0_col0\" class=\"data row0 col0\" >WeightedEnsemble_L3</td>\n","      <td id=\"T_c0e80_row0_col1\" class=\"data row0 col1\" >0.667334</td>\n","      <td id=\"T_c0e80_row0_col2\" class=\"data row0 col2\" >accuracy</td>\n","      <td id=\"T_c0e80_row0_col3\" class=\"data row0 col3\" >9.411990</td>\n","      <td id=\"T_c0e80_row0_col4\" class=\"data row0 col4\" >219.564252</td>\n","      <td id=\"T_c0e80_row0_col5\" class=\"data row0 col5\" >0.005841</td>\n","      <td id=\"T_c0e80_row0_col6\" class=\"data row0 col6\" >0.281484</td>\n","      <td id=\"T_c0e80_row0_col7\" class=\"data row0 col7\" >3</td>\n","      <td id=\"T_c0e80_row0_col8\" class=\"data row0 col8\" >True</td>\n","      <td id=\"T_c0e80_row0_col9\" class=\"data row0 col9\" >4</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c0e80_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n","      <td id=\"T_c0e80_row1_col0\" class=\"data row1 col0\" >LightGBMXT_BAG_L2</td>\n","      <td id=\"T_c0e80_row1_col1\" class=\"data row1 col1\" >0.659531</td>\n","      <td id=\"T_c0e80_row1_col2\" class=\"data row1 col2\" >accuracy</td>\n","      <td id=\"T_c0e80_row1_col3\" class=\"data row1 col3\" >9.406149</td>\n","      <td id=\"T_c0e80_row1_col4\" class=\"data row1 col4\" >219.282768</td>\n","      <td id=\"T_c0e80_row1_col5\" class=\"data row1 col5\" >4.929582</td>\n","      <td id=\"T_c0e80_row1_col6\" class=\"data row1 col6\" >104.387477</td>\n","      <td id=\"T_c0e80_row1_col7\" class=\"data row1 col7\" >2</td>\n","      <td id=\"T_c0e80_row1_col8\" class=\"data row1 col8\" >True</td>\n","      <td id=\"T_c0e80_row1_col9\" class=\"data row1 col9\" >3</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c0e80_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n","      <td id=\"T_c0e80_row2_col0\" class=\"data row2 col0\" >LightGBMXT_BAG_L1</td>\n","      <td id=\"T_c0e80_row2_col1\" class=\"data row2 col1\" >0.655753</td>\n","      <td id=\"T_c0e80_row2_col2\" class=\"data row2 col2\" >accuracy</td>\n","      <td id=\"T_c0e80_row2_col3\" class=\"data row2 col3\" >4.476568</td>\n","      <td id=\"T_c0e80_row2_col4\" class=\"data row2 col4\" >114.895291</td>\n","      <td id=\"T_c0e80_row2_col5\" class=\"data row2 col5\" >4.476568</td>\n","      <td id=\"T_c0e80_row2_col6\" class=\"data row2 col6\" >114.895291</td>\n","      <td id=\"T_c0e80_row2_col7\" class=\"data row2 col7\" >1</td>\n","      <td id=\"T_c0e80_row2_col8\" class=\"data row2 col8\" >True</td>\n","      <td id=\"T_c0e80_row2_col9\" class=\"data row2 col9\" >1</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c0e80_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n","      <td id=\"T_c0e80_row3_col0\" class=\"data row3 col0\" >WeightedEnsemble_L2</td>\n","      <td id=\"T_c0e80_row3_col1\" class=\"data row3 col1\" >0.655753</td>\n","      <td id=\"T_c0e80_row3_col2\" class=\"data row3 col2\" >accuracy</td>\n","      <td id=\"T_c0e80_row3_col3\" class=\"data row3 col3\" >4.483434</td>\n","      <td id=\"T_c0e80_row3_col4\" class=\"data row3 col4\" >114.908567</td>\n","      <td id=\"T_c0e80_row3_col5\" class=\"data row3 col5\" >0.006866</td>\n","      <td id=\"T_c0e80_row3_col6\" class=\"data row3 col6\" >0.013276</td>\n","      <td id=\"T_c0e80_row3_col7\" class=\"data row3 col7\" >2</td>\n","      <td id=\"T_c0e80_row3_col8\" class=\"data row3 col8\" >True</td>\n","      <td id=\"T_c0e80_row3_col9\" class=\"data row3 col9\" >2</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x7c2a4279dc00>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["predictor.leaderboard(silent=True).style.background_gradient(subset=['score_val'], cmap='RdYlGn')"]},{"cell_type":"markdown","id":"8849e906","metadata":{"papermill":{"duration":0.012762,"end_time":"2025-02-04T11:24:45.397164","exception":false,"start_time":"2025-02-04T11:24:45.384402","status":"completed"},"tags":[]},"source":["# Saving the predictor"]},{"cell_type":"code","execution_count":15,"id":"27bbe532","metadata":{"execution":{"iopub.execute_input":"2025-02-04T11:24:45.424247Z","iopub.status.busy":"2025-02-04T11:24:45.42351Z","iopub.status.idle":"2025-02-04T11:24:45.615783Z","shell.execute_reply":"2025-02-04T11:24:45.614492Z"},"papermill":{"duration":0.208003,"end_time":"2025-02-04T11:24:45.617825","exception":false,"start_time":"2025-02-04T11:24:45.409822","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'/kaggle/working/autogluon.zip'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["shutil.make_archive(\n","    \"/kaggle/working/autogluon\", \n","    \"zip\", \n","    \"/AutoGluonModels\"\n",")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":10131489,"sourceId":86946,"sourceType":"competition"},{"datasetId":6447806,"sourceId":10601275,"sourceType":"datasetVersion"}],"dockerImageVersionId":30822,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":424.524363,"end_time":"2025-02-04T11:24:48.454457","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-04T11:17:43.930094","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}