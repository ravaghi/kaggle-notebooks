{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd069df1",
   "metadata": {
    "papermill": {
     "duration": 0.003277,
     "end_time": "2025-01-14T13:55:46.748419",
     "exception": false,
     "start_time": "2025-01-14T13:55:46.745142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f1dd6b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-14T13:55:46.754635Z",
     "iopub.status.busy": "2025-01-14T13:55:46.754413Z",
     "iopub.status.idle": "2025-01-14T13:55:54.254206Z",
     "shell.execute_reply": "2025-01-14T13:55:54.253065Z"
    },
    "papermill": {
     "duration": 7.504517,
     "end_time": "2025-01-14T13:55:54.255826",
     "exception": false,
     "start_time": "2025-01-14T13:55:46.751309",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/packages\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\r\n",
      "Processing /kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/packages/peft-0.14.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\r\n",
      "Processing /kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/packages/bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\r\n",
      "Processing /kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/packages/huggingface_hub-0.27.1-py3-none-any.whl (from transformers)\r\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\r\n",
      "Installing collected packages: huggingface-hub, bitsandbytes, peft\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.24.7\r\n",
      "    Uninstalling huggingface-hub-0.24.7:\r\n",
      "      Successfully uninstalled huggingface-hub-0.24.7\r\n",
      "Successfully installed bitsandbytes-0.45.0 huggingface-hub-0.27.1 peft-0.14.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers peft accelerate bitsandbytes --no-index --find-links=/kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab01239",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:55:54.263729Z",
     "iopub.status.busy": "2025-01-14T13:55:54.263464Z",
     "iopub.status.idle": "2025-01-14T13:56:10.686088Z",
     "shell.execute_reply": "2025-01-14T13:56:10.685356Z"
    },
    "papermill": {
     "duration": 16.428234,
     "end_time": "2025-01-14T13:56:10.687730",
     "exception": false,
     "start_time": "2025-01-14T13:55:54.259496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from peft import PeftModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2488f81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:56:10.695570Z",
     "iopub.status.busy": "2025-01-14T13:56:10.695053Z",
     "iopub.status.idle": "2025-01-14T13:56:10.698851Z",
     "shell.execute_reply": "2025-01-14T13:56:10.698034Z"
    },
    "papermill": {
     "duration": 0.00867,
     "end_time": "2025-01-14T13:56:10.699948",
     "exception": false,
     "start_time": "2025-01-14T13:56:10.691278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    test_path = \"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\"\n",
    "    \n",
    "    gemma_dir = \"/kaggle/input/gemma-2-9b-it-bnb-4bit-unsloth/transformers/default/1\"\n",
    "    lora_dir = \"/kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/fold 0/gemma2-9b-4bit-2048-2-16-fold0/checkpoint-12000\"\n",
    "    \n",
    "    max_length = 2048\n",
    "    batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8df252",
   "metadata": {
    "papermill": {
     "duration": 0.003001,
     "end_time": "2025-01-14T13:56:10.706181",
     "exception": false,
     "start_time": "2025-01-14T13:56:10.703180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc2fc29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:56:10.713249Z",
     "iopub.status.busy": "2025-01-14T13:56:10.713010Z",
     "iopub.status.idle": "2025-01-14T13:56:10.868273Z",
     "shell.execute_reply": "2025-01-14T13:56:10.867623Z"
    },
    "papermill": {
     "duration": 0.160358,
     "end_time": "2025-01-14T13:56:10.869724",
     "exception": false,
     "start_time": "2025-01-14T13:56:10.709366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(CFG.test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de394c11",
   "metadata": {
    "papermill": {
     "duration": 0.003258,
     "end_time": "2025-01-14T13:56:10.876513",
     "exception": false,
     "start_time": "2025-01-14T13:56:10.873255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5b9c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:56:10.883935Z",
     "iopub.status.busy": "2025-01-14T13:56:10.883717Z",
     "iopub.status.idle": "2025-01-14T13:56:10.888243Z",
     "shell.execute_reply": "2025-01-14T13:56:10.887622Z"
    },
    "papermill": {
     "duration": 0.00963,
     "end_time": "2025-01-14T13:56:10.889399",
     "exception": false,
     "start_time": "2025-01-14T13:56:10.879769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, prompt, response_a, response_b, max_length=CFG.max_length):\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
    "    \n",
    "    text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "    tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "    \n",
    "    input_ids = tokenized.input_ids\n",
    "    attention_mask = tokenized.attention_mask\n",
    "    \n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf274a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:56:10.896533Z",
     "iopub.status.busy": "2025-01-14T13:56:10.896322Z",
     "iopub.status.idle": "2025-01-14T13:56:11.878797Z",
     "shell.execute_reply": "2025-01-14T13:56:11.877841Z"
    },
    "papermill": {
     "duration": 0.987778,
     "end_time": "2025-01-14T13:56:11.880430",
     "exception": false,
     "start_time": "2025-01-14T13:56:10.892652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = GemmaTokenizerFast.from_pretrained(CFG.gemma_dir)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3146d96d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:56:11.888434Z",
     "iopub.status.busy": "2025-01-14T13:56:11.888143Z",
     "iopub.status.idle": "2025-01-14T13:56:11.916102Z",
     "shell.execute_reply": "2025-01-14T13:56:11.915193Z"
    },
    "papermill": {
     "duration": 0.033277,
     "end_time": "2025-01-14T13:56:11.917306",
     "exception": false,
     "start_time": "2025-01-14T13:56:11.884029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "aug_data[\"input_ids\"], aug_data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9034903c",
   "metadata": {
    "papermill": {
     "duration": 0.003058,
     "end_time": "2025-01-14T13:56:11.923668",
     "exception": false,
     "start_time": "2025-01-14T13:56:11.920610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce4c01c4",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-14T13:56:11.931099Z",
     "iopub.status.busy": "2025-01-14T13:56:11.930877Z",
     "iopub.status.idle": "2025-01-14T13:57:02.971769Z",
     "shell.execute_reply": "2025-01-14T13:57:02.970859Z"
    },
    "papermill": {
     "duration": 51.046373,
     "end_time": "2025-01-14T13:57:02.973330",
     "exception": false,
     "start_time": "2025-01-14T13:56:11.926957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma-2-9b-it-bnb-4bit-unsloth/transformers/default/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma-2-9b-it-bnb-4bit-unsloth/transformers/default/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    CFG.gemma_dir,\n",
    "    device_map=torch.device(\"cuda:0\"),\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    CFG.gemma_dir,\n",
    "    device_map=torch.device(\"cuda:1\"),\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31b4a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:57:02.982952Z",
     "iopub.status.busy": "2025-01-14T13:57:02.982640Z",
     "iopub.status.idle": "2025-01-14T13:57:04.109462Z",
     "shell.execute_reply": "2025-01-14T13:57:04.108740Z"
    },
    "papermill": {
     "duration": 1.132933,
     "end_time": "2025-01-14T13:57:04.111035",
     "exception": false,
     "start_time": "2025-01-14T13:57:02.978102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_0 = PeftModel.from_pretrained(model_0, CFG.lora_dir)\n",
    "model_1 = PeftModel.from_pretrained(model_1, CFG.lora_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad980549",
   "metadata": {
    "papermill": {
     "duration": 0.003638,
     "end_time": "2025-01-14T13:57:04.118670",
     "exception": false,
     "start_time": "2025-01-14T13:57:04.115032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4dd9ac1",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-14T13:57:04.126533Z",
     "iopub.status.busy": "2025-01-14T13:57:04.126260Z",
     "iopub.status.idle": "2025-01-14T13:57:04.132478Z",
     "shell.execute_reply": "2025-01-14T13:57:04.131676Z"
    },
    "papermill": {
     "duration": 0.011603,
     "end_time": "2025-01-14T13:57:04.133740",
     "exception": false,
     "start_time": "2025-01-14T13:57:04.122137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7bb6f4852d9d>:2: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size=CFG.batch_size):\n",
    "    p_a, p_b = [], []\n",
    "\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        \n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        \n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        outputs = model(**inputs.to(device))\n",
    "        tmp_y_pred_probs = outputs.logits.softmax(-1).cpu()\n",
    "\n",
    "        p_a.extend(tmp_y_pred_probs[:, 0].tolist())\n",
    "        p_b.extend(tmp_y_pred_probs[:, 1].tolist())\n",
    "        \n",
    "    df[\"p_a\"], df[\"p_b\"] = p_a, p_b\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6557b750",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-01-14T13:57:04.141938Z",
     "iopub.status.busy": "2025-01-14T13:57:04.141736Z",
     "iopub.status.idle": "2025-01-14T13:57:08.222087Z",
     "shell.execute_reply": "2025-01-14T13:57:08.221353Z"
    },
    "papermill": {
     "duration": 4.085938,
     "end_time": "2025-01-14T13:57:08.223546",
     "exception": false,
     "start_time": "2025-01-14T13:57:04.137608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.sort_values(\"length\", ascending=False)\n",
    "\n",
    "sub_1 = data.iloc[0::2].copy()\n",
    "sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(\n",
    "        inference, \n",
    "        (sub_1, sub_2), \n",
    "        (model_0, model_1), \n",
    "        (torch.device(\"cuda:0\"), torch.device(\"cuda:1\"))\n",
    "    )\n",
    "\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "y_pred_probs = result_df[[\"p_a\", \"p_b\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22810ef1",
   "metadata": {
    "papermill": {
     "duration": 0.003906,
     "end_time": "2025-01-14T13:57:08.231883",
     "exception": false,
     "start_time": "2025-01-14T13:57:08.227977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f3423fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-14T13:57:08.240361Z",
     "iopub.status.busy": "2025-01-14T13:57:08.240117Z",
     "iopub.status.idle": "2025-01-14T13:57:08.257443Z",
     "shell.execute_reply": "2025-01-14T13:57:08.256646Z"
    },
    "papermill": {
     "duration": 0.022842,
     "end_time": "2025-01-14T13:57:08.258744",
     "exception": false,
     "start_time": "2025-01-14T13:57:08.235902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327228</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139415</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235630</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   winner\n",
       "0   327228  model_b\n",
       "1  1139415  model_a\n",
       "2  1235630  model_b"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = result_df[[\"id\", \"p_a\", \"p_b\"]].copy()\n",
    "\n",
    "sub[\"winner\"] = np.where(sub[\"p_a\"] > 0.5, \"model_a\", \"model_b\")\n",
    "sub = sub.drop(columns=[\"p_a\", \"p_b\"], axis=1)\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "datasetId": 6447806,
     "sourceId": 10467210,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 114668,
     "modelInstanceId": 90450,
     "sourceId": 107993,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 86.904268,
   "end_time": "2025-01-14T13:57:11.148053",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-14T13:55:44.243785",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
