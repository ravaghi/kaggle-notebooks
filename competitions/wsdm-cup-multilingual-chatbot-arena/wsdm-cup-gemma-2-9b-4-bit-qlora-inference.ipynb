{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81845dc",
   "metadata": {
    "papermill": {
     "duration": 0.004785,
     "end_time": "2025-02-04T11:31:15.882124",
     "exception": false,
     "start_time": "2025-02-04T11:31:15.877339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Training notebook: https://www.kaggle.com/code/ravaghi/wsdm-cup-autogluon-training?scriptVersionId=220752804"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe5dd0",
   "metadata": {
    "papermill": {
     "duration": 0.003875,
     "end_time": "2025-02-04T11:31:15.890305",
     "exception": false,
     "start_time": "2025-02-04T11:31:15.886430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9bdc64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:15.899085Z",
     "iopub.status.busy": "2025-02-04T11:31:15.898868Z",
     "iopub.status.idle": "2025-02-04T11:31:29.954936Z",
     "shell.execute_reply": "2025-02-04T11:31:29.954237Z"
    },
    "papermill": {
     "duration": 14.062164,
     "end_time": "2025-02-04T11:31:29.956457",
     "exception": false,
     "start_time": "2025-02-04T11:31:15.894293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from timeit import default_timer as timer\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0ffb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:29.966144Z",
     "iopub.status.busy": "2025-02-04T11:31:29.965712Z",
     "iopub.status.idle": "2025-02-04T11:31:29.969151Z",
     "shell.execute_reply": "2025-02-04T11:31:29.968527Z"
    },
    "papermill": {
     "duration": 0.00936,
     "end_time": "2025-02-04T11:31:29.970411",
     "exception": false,
     "start_time": "2025-02-04T11:31:29.961051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    test_path = \"/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\"\n",
    "    \n",
    "    gemma_dir = \"/kaggle/input/gemma-2-9b-4bit-it-unsloth/transformers/default/1/gemma-2-9b-it-4bit-unsloth_old\"\n",
    "    lora_dir = \"/kaggle/input/wsdm-cup-gemma-2-9b-4-bit-qlora/gemma2-9b-4bit/fold-4/gemma-2-9b-it-bnb-4bit-3072-8-f4/checkpoint-2900\"\n",
    "    \n",
    "    max_length = 3072\n",
    "    batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724bf50b",
   "metadata": {
    "papermill": {
     "duration": 0.003854,
     "end_time": "2025-02-04T11:31:29.978391",
     "exception": false,
     "start_time": "2025-02-04T11:31:29.974537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784af097",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:29.987168Z",
     "iopub.status.busy": "2025-02-04T11:31:29.986953Z",
     "iopub.status.idle": "2025-02-04T11:31:30.117143Z",
     "shell.execute_reply": "2025-02-04T11:31:30.116504Z"
    },
    "papermill": {
     "duration": 0.135984,
     "end_time": "2025-02-04T11:31:30.118456",
     "exception": false,
     "start_time": "2025-02-04T11:31:29.982472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(CFG.test_path).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f947f9d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:30.128018Z",
     "iopub.status.busy": "2025-02-04T11:31:30.127799Z",
     "iopub.status.idle": "2025-02-04T11:31:30.130839Z",
     "shell.execute_reply": "2025-02-04T11:31:30.130259Z"
    },
    "papermill": {
     "duration": 0.009042,
     "end_time": "2025-02-04T11:31:30.131929",
     "exception": false,
     "start_time": "2025-02-04T11:31:30.122887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(test) > 10_000:\n",
    "    time_limit = int(3600 * 12) \n",
    "else:\n",
    "    time_limit = int(3600 * 4.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3fa86",
   "metadata": {
    "papermill": {
     "duration": 0.004294,
     "end_time": "2025-02-04T11:31:30.140494",
     "exception": false,
     "start_time": "2025-02-04T11:31:30.136200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b635f867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:30.149512Z",
     "iopub.status.busy": "2025-02-04T11:31:30.149283Z",
     "iopub.status.idle": "2025-02-04T11:31:30.152976Z",
     "shell.execute_reply": "2025-02-04T11:31:30.152443Z"
    },
    "papermill": {
     "duration": 0.009487,
     "end_time": "2025-02-04T11:31:30.154176",
     "exception": false,
     "start_time": "2025-02-04T11:31:30.144689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, prompt, response_a, response_b, max_length=CFG.max_length):\n",
    "    prompt = [\"<prompt>: \" + t for t in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + t for t in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + t for t in response_b]\n",
    "    \n",
    "    texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "    tokenized = tokenizer(texts, max_length=max_length, truncation=True)\n",
    "    \n",
    "    return tokenized['input_ids'], tokenized['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ae6548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:30.163334Z",
     "iopub.status.busy": "2025-02-04T11:31:30.163112Z",
     "iopub.status.idle": "2025-02-04T11:31:31.270025Z",
     "shell.execute_reply": "2025-02-04T11:31:31.269330Z"
    },
    "papermill": {
     "duration": 1.113193,
     "end_time": "2025-02-04T11:31:31.271606",
     "exception": false,
     "start_time": "2025-02-04T11:31:30.158413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = GemmaTokenizerFast.from_pretrained(CFG.gemma_dir)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb742ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:31.281262Z",
     "iopub.status.busy": "2025-02-04T11:31:31.280990Z",
     "iopub.status.idle": "2025-02-04T11:31:31.313602Z",
     "shell.execute_reply": "2025-02-04T11:31:31.312862Z"
    },
    "papermill": {
     "duration": 0.038646,
     "end_time": "2025-02-04T11:31:31.314844",
     "exception": false,
     "start_time": "2025-02-04T11:31:31.276198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 850.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 811.02it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 695.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    test[col] = test[col].fillna('')\n",
    "    text_list = []\n",
    "    if col == \"prompt\":\n",
    "        max_no = 512\n",
    "        s_no = 255\n",
    "        e_no = -256\n",
    "    else:\n",
    "        max_no = 3072\n",
    "        s_no = 1535\n",
    "        e_no = -1536\n",
    "    for text in tqdm(test[col]):\n",
    "        encoded = tokenizer(text, return_offsets_mapping=True)\n",
    "        if len(encoded['input_ids']) > max_no:\n",
    "            start_idx, end_idx = encoded['offset_mapping'][s_no]\n",
    "            new_text = text[:end_idx]\n",
    "            start_idx, end_idx = encoded['offset_mapping'][e_no]\n",
    "            new_text = new_text + \"\\n(snip)\\n\" + text[start_idx:]\n",
    "            text = new_text\n",
    "        text_list.append(text)\n",
    "    test[col] = text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac36dff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:31.325099Z",
     "iopub.status.busy": "2025-02-04T11:31:31.324867Z",
     "iopub.status.idle": "2025-02-04T11:31:31.341130Z",
     "shell.execute_reply": "2025-02-04T11:31:31.340337Z"
    },
    "papermill": {
     "duration": 0.02276,
     "end_time": "2025-02-04T11:31:31.342479",
     "exception": false,
     "start_time": "2025-02-04T11:31:31.319719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b40f6de",
   "metadata": {
    "papermill": {
     "duration": 0.004855,
     "end_time": "2025-02-04T11:31:31.352238",
     "exception": false,
     "start_time": "2025-02-04T11:31:31.347383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d7ad489",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-02-04T11:31:31.362649Z",
     "iopub.status.busy": "2025-02-04T11:31:31.362418Z",
     "iopub.status.idle": "2025-02-04T11:32:17.755660Z",
     "shell.execute_reply": "2025-02-04T11:32:17.754962Z"
    },
    "papermill": {
     "duration": 46.400028,
     "end_time": "2025-02-04T11:32:17.757201",
     "exception": false,
     "start_time": "2025-02-04T11:31:31.357173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma-2-9b-4bit-it-unsloth/transformers/default/1/gemma-2-9b-it-4bit-unsloth_old and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma-2-9b-4bit-it-unsloth/transformers/default/1/gemma-2-9b-it-4bit-unsloth_old and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    CFG.gemma_dir,\n",
    "    device_map=torch.device(\"cuda:0\"),\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    CFG.gemma_dir,\n",
    "    device_map=torch.device(\"cuda:1\"),\n",
    "    use_cache=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f5857a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:17.769144Z",
     "iopub.status.busy": "2025-02-04T11:32:17.768916Z",
     "iopub.status.idle": "2025-02-04T11:32:18.987738Z",
     "shell.execute_reply": "2025-02-04T11:32:18.987006Z"
    },
    "papermill": {
     "duration": 1.226278,
     "end_time": "2025-02-04T11:32:18.989193",
     "exception": false,
     "start_time": "2025-02-04T11:32:17.762915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_0 = PeftModel.from_pretrained(model_0, CFG.lora_dir)\n",
    "model_1 = PeftModel.from_pretrained(model_1, CFG.lora_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99977258",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:19.000658Z",
     "iopub.status.busy": "2025-02-04T11:32:19.000412Z",
     "iopub.status.idle": "2025-02-04T11:32:19.020174Z",
     "shell.execute_reply": "2025-02-04T11:32:19.019399Z"
    },
    "papermill": {
     "duration": 0.026751,
     "end_time": "2025-02-04T11:32:19.021530",
     "exception": false,
     "start_time": "2025-02-04T11:32:18.994779",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForSequenceClassification(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2SdpaAttention(\n",
       "              (q_proj): Linear4bit(in_features=3584, out_features=4096, bias=False)\n",
       "              (k_proj): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "              (v_proj): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=3584, bias=False)\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=3584, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "          (16-41): 26 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2SdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3584, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=3584, bias=False)\n",
       "              (rotary_emb): Gemma2RotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=3584, bias=False)\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=3584, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=3584, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.eval()\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99013aa",
   "metadata": {
    "papermill": {
     "duration": 0.005092,
     "end_time": "2025-02-04T11:32:19.032003",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.026911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081386d9",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:19.042931Z",
     "iopub.status.busy": "2025-02-04T11:32:19.042722Z",
     "iopub.status.idle": "2025-02-04T11:32:19.048296Z",
     "shell.execute_reply": "2025-02-04T11:32:19.047443Z"
    },
    "papermill": {
     "duration": 0.012432,
     "end_time": "2025-02-04T11:32:19.049566",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.037134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-aeb673b51808>:2: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size, max_length=CFG.max_length):\n",
    "    winners = []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()\n",
    "        \n",
    "        winners.extend(proba[:, 1].tolist())\n",
    "    \n",
    "    df['winner'] = winners\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0e6f5",
   "metadata": {
    "papermill": {
     "duration": 0.005003,
     "end_time": "2025-02-04T11:32:19.059869",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.054866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## No TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9958b515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:19.071103Z",
     "iopub.status.busy": "2025-02-04T11:32:19.070897Z",
     "iopub.status.idle": "2025-02-04T11:32:19.073917Z",
     "shell.execute_reply": "2025-02-04T11:32:19.073285Z"
    },
    "papermill": {
     "duration": 0.009929,
     "end_time": "2025-02-04T11:32:19.075030",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.065101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_timer = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e585ad0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:19.086422Z",
     "iopub.status.busy": "2025-02-04T11:32:19.086174Z",
     "iopub.status.idle": "2025-02-04T11:32:19.096951Z",
     "shell.execute_reply": "2025-02-04T11:32:19.096383Z"
    },
    "papermill": {
     "duration": 0.017612,
     "end_time": "2025-02-04T11:32:19.098056",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.080444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['index'] = np.arange(len(data), dtype=np.int32)\n",
    "data = data.sort_values(\"length\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf442dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:19.109563Z",
     "iopub.status.busy": "2025-02-04T11:32:19.109342Z",
     "iopub.status.idle": "2025-02-04T11:32:19.114706Z",
     "shell.execute_reply": "2025-02-04T11:32:19.113905Z"
    },
    "papermill": {
     "duration": 0.012323,
     "end_time": "2025-02-04T11:32:19.115917",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.103594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "data_dict[0] = data[data[\"length\"] > 1024].reset_index(drop=True)\n",
    "data_dict[1] = data[data[\"length\"] <= 1024].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daa8b164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:19.127639Z",
     "iopub.status.busy": "2025-02-04T11:32:19.127428Z",
     "iopub.status.idle": "2025-02-04T11:32:22.519942Z",
     "shell.execute_reply": "2025-02-04T11:32:22.519006Z"
    },
    "papermill": {
     "duration": 3.400437,
     "end_time": "2025-02-04T11:32:22.521848",
     "exception": false,
     "start_time": "2025-02-04T11:32:19.121411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = []\n",
    "for i, batch_size in enumerate([CFG.batch_size, CFG.batch_size]):\n",
    "    if len(data_dict[i]) == 0:\n",
    "        continue\n",
    "        \n",
    "    sub_1 = data_dict[i].iloc[0::2].copy()\n",
    "    sub_2 = data_dict[i].iloc[1::2].copy()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(\n",
    "            inference, \n",
    "            (sub_1, sub_2), \n",
    "            (model_0, model_1), \n",
    "            (torch.device(\"cuda:0\"), torch.device(\"cuda:1\")), \n",
    "            (batch_size, batch_size)\n",
    "        )\n",
    "        \n",
    "    result_df.append(pd.concat(list(results), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9806f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:22.535070Z",
     "iopub.status.busy": "2025-02-04T11:32:22.534814Z",
     "iopub.status.idle": "2025-02-04T11:32:22.540292Z",
     "shell.execute_reply": "2025-02-04T11:32:22.539535Z"
    },
    "papermill": {
     "duration": 0.01295,
     "end_time": "2025-02-04T11:32:22.541744",
     "exception": false,
     "start_time": "2025-02-04T11:32:22.528794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.concat(result_df).sort_values('index').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdc65b",
   "metadata": {
    "papermill": {
     "duration": 0.006857,
     "end_time": "2025-02-04T11:32:22.559277",
     "exception": false,
     "start_time": "2025-02-04T11:32:22.552420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062bbd80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:22.571338Z",
     "iopub.status.busy": "2025-02-04T11:32:22.571050Z",
     "iopub.status.idle": "2025-02-04T11:32:22.576189Z",
     "shell.execute_reply": "2025-02-04T11:32:22.575419Z"
    },
    "papermill": {
     "duration": 0.012977,
     "end_time": "2025-02-04T11:32:22.577765",
     "exception": false,
     "start_time": "2025-02-04T11:32:22.564788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_data['index'] = np.arange(len(aug_data), dtype=np.int32)\n",
    "aug_data = aug_data.sort_values(\"length\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e21ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:22.599580Z",
     "iopub.status.busy": "2025-02-04T11:32:22.599259Z",
     "iopub.status.idle": "2025-02-04T11:32:22.609668Z",
     "shell.execute_reply": "2025-02-04T11:32:22.608882Z"
    },
    "papermill": {
     "duration": 0.021715,
     "end_time": "2025-02-04T11:32:22.610885",
     "exception": false,
     "start_time": "2025-02-04T11:32:22.589170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.2\n",
    "not_confident_mask = abs(result_df['winner'] - 0.5) < CONFIDENCE_THRESHOLD\n",
    "\n",
    "aug_data = aug_data[aug_data['index'].isin(result_df[not_confident_mask]['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e24c7e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:22.623656Z",
     "iopub.status.busy": "2025-02-04T11:32:22.623326Z",
     "iopub.status.idle": "2025-02-04T11:32:22.629547Z",
     "shell.execute_reply": "2025-02-04T11:32:22.628759Z"
    },
    "papermill": {
     "duration": 0.013896,
     "end_time": "2025-02-04T11:32:22.630911",
     "exception": false,
     "start_time": "2025-02-04T11:32:22.617015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_data_dict = {}\n",
    "aug_data_dict[0] = aug_data[aug_data[\"length\"] > 1024].reset_index(drop=True)\n",
    "aug_data_dict[1] = aug_data[aug_data[\"length\"] <= 1024].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e4bb2e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:22.642866Z",
     "iopub.status.busy": "2025-02-04T11:32:22.642639Z",
     "iopub.status.idle": "2025-02-04T11:32:24.958684Z",
     "shell.execute_reply": "2025-02-04T11:32:24.957958Z"
    },
    "papermill": {
     "duration": 2.323785,
     "end_time": "2025-02-04T11:32:24.960342",
     "exception": false,
     "start_time": "2025-02-04T11:32:22.636557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aug_result_df = []\n",
    "for i, batch_size in enumerate([CFG.batch_size, CFG.batch_size]):\n",
    "    if len(aug_data_dict[i]) == 0:\n",
    "        continue\n",
    "\n",
    "    if timer() - global_timer > (time_limit - 300):\n",
    "        break\n",
    "        \n",
    "    sub_1 = aug_data_dict[i].iloc[0::2].copy()\n",
    "    sub_2 = aug_data_dict[i].iloc[1::2].copy()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(\n",
    "            inference, \n",
    "            (sub_1, sub_2), \n",
    "            (model_0, model_1), \n",
    "            (torch.device(\"cuda:0\"), torch.device(\"cuda:1\")), \n",
    "            (batch_size, batch_size)\n",
    "        )\n",
    "        \n",
    "    aug_result_df.append(pd.concat(list(results), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b00f3e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:24.973572Z",
     "iopub.status.busy": "2025-02-04T11:32:24.973285Z",
     "iopub.status.idle": "2025-02-04T11:32:24.977916Z",
     "shell.execute_reply": "2025-02-04T11:32:24.977172Z"
    },
    "papermill": {
     "duration": 0.012554,
     "end_time": "2025-02-04T11:32:24.979147",
     "exception": false,
     "start_time": "2025-02-04T11:32:24.966593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for 10_000 (max  4.5 hr):  5.5\n",
      "time for 25_000 (max 12.0 hr): 13.7\n"
     ]
    }
   ],
   "source": [
    "time_taken = timer() - global_timer\n",
    "\n",
    "print(f'time for 10_000 (max  4.5 hr): {10_000/3*time_taken/60/60:4.1f}')\n",
    "print(f'time for 25_000 (max 12.0 hr): {25_000/3*time_taken/60/60:4.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98d95b",
   "metadata": {
    "papermill": {
     "duration": 0.005723,
     "end_time": "2025-02-04T11:32:24.990865",
     "exception": false,
     "start_time": "2025-02-04T11:32:24.985142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Combining the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7978553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:25.003055Z",
     "iopub.status.busy": "2025-02-04T11:32:25.002833Z",
     "iopub.status.idle": "2025-02-04T11:32:25.021423Z",
     "shell.execute_reply": "2025-02-04T11:32:25.020705Z"
    },
    "papermill": {
     "duration": 0.026135,
     "end_time": "2025-02-04T11:32:25.022744",
     "exception": false,
     "start_time": "2025-02-04T11:32:24.996609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(aug_result_df) > 0:\n",
    "    aug_result_df = pd.concat(aug_result_df).sort_values('index').reset_index(drop=True)\n",
    "    aug_result_df[\"winner\"] = 1 - aug_result_df['winner']\n",
    "    \n",
    "    result_df = result_df.merge(\n",
    "        aug_result_df[['index', 'winner']], \n",
    "        on='index', \n",
    "        how='left', \n",
    "        suffixes=('', '_aug')\n",
    "    )\n",
    "    \n",
    "    mask = result_df['winner_aug'].notna()\n",
    "    result_df.loc[mask, 'winner'] = (result_df.loc[mask, 'winner'] + result_df.loc[mask, 'winner_aug']) / 2\n",
    "    \n",
    "    result_df = result_df.drop('winner_aug', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c26edb0",
   "metadata": {
    "papermill": {
     "duration": 0.005542,
     "end_time": "2025-02-04T11:32:25.034072",
     "exception": false,
     "start_time": "2025-02-04T11:32:25.028530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6dcd43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-04T11:32:25.046313Z",
     "iopub.status.busy": "2025-02-04T11:32:25.046108Z",
     "iopub.status.idle": "2025-02-04T11:32:25.058719Z",
     "shell.execute_reply": "2025-02-04T11:32:25.058037Z"
    },
    "papermill": {
     "duration": 0.020128,
     "end_time": "2025-02-04T11:32:25.059887",
     "exception": false,
     "start_time": "2025-02-04T11:32:25.039759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327228</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139415</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235630</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   winner\n",
       "0   327228  model_b\n",
       "1  1139415  model_a\n",
       "2  1235630  model_a"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = result_df[['id', 'winner']].copy()\n",
    "sub['winner'] = np.where(sub['winner'] < 0.5, 'model_a', 'model_b')\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "datasetId": 6447806,
     "sourceId": 10576723,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 193770,
     "modelInstanceId": 171453,
     "sourceId": 200971,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 74.755154,
   "end_time": "2025-02-04T11:32:28.464540",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-04T11:31:13.709386",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
